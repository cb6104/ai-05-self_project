,subreddit,body
0,MachineLearning,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|41-50|51-60|61-70|71-80|81-90|91-100|101-110|111-120|
|----|-----|-----|-----|-----|-----|-----|-----|-----|------|-------|-------|
|[Week 1](https://www.reddit.com/4qyjiq)|[Week 11](https://www.reddit.com/57xw56)|[Week 21](https://www.reddit.com/60ildf)|[Week 31](https://www.reddit.com/6s0k1u)|[Week 41](https://www.reddit.com/7tn2ax)|[Week 51](https://reddit.com/9s9el5)|[Week 61](https://reddit.com/bfsx4z)|[Week 71](https://reddit.com/d7vno3)|[Week 81](https://reddit.com/f1f0iq)|[Week 91](https://reddit.com/hlt38o)|[Week 101](https://reddit.com/k81ywb)|[Week 111](https://reddit.com/myg8sm)||||||||||
|[Week 2](https://www.reddit.com/4s2xqm)|[Week 12](https://www.reddit.com/5acb1t)|[Week 22](https://www.reddit.com/64jwde)|[Week 32](https://www.reddit.com/72ab5y)|[Week 42](https://www.reddit.com/7wvjfk)|[Week 52](https://reddit.com/a4opot)|[Week 62](https://reddit.com/bl29ov)|[Week 72](https://reddit.com/de8h48)|[Week 82](https://reddit.com/f8fs6z)|[Week 92](https://reddit.com/hu6zq9)|[Week 102](https://reddit.com/kh27nx)||
|[Week 3](https://www.reddit.com/4t7mqm)|[Week 13](https://www.reddit.com/5cwfb6)|[Week 23](https://www.reddit.com/674331)|[Week 33](https://www.reddit.com/75405d)|[Week 43](https://www.reddit.com/807ex4)|[Week 53](https://reddit.com/a8yaro)|[Week 63](https://reddit.com/bqlb3v)|[Week 73](https://reddit.com/dkox1s)|[Week 83](https://reddit.com/ffi41b)|[Week 93](https://reddit.com/iaz892)|[Week 103](https://reddit.com/kpsxtc)||
|[Week 4](https://www.reddit.com/4ub2kw)|[Week 14](https://www.reddit.com/5fc5mh)|[Week 24](https://www.reddit.com/68hhhb)|[Week 34](https://www.reddit.com/782js9)|[Week 44](https://reddit.com/8aluhs)|[Week 54](https://reddit.com/ad9ssz)|[Week 64](https://reddit.com/bw1jm7)|[Week 74](https://reddit.com/dr6nca)|[Week 84](https://reddit.com/fn62r1)|[Week 94](https://reddit.com/ijjcep)|[Week 104](https://reddit.com/kzevku)||
|[Week 5](https://www.reddit.com/4xomf7)|[Week 15](https://www.reddit.com/5hy4ur)|[Week 25](https://www.reddit.com/69teiz)|[Week 35](https://www.reddit.com/7b0av0)|[Week 45](https://reddit.com/8tnnez)|[Week 55](https://reddit.com/ai29gi)|[Week 65](https://reddit.com/c7itkk)|[Week 75](https://reddit.com/dxshkg)|[Week 85](https://reddit.com/fvk7j6)|[Week 95](https://reddit.com/is5hj9)|[Week 105](https://reddit.com/l9lvgs)||
|[Week 6](https://www.reddit.com/4zcyvk)|[Week 16](https://www.reddit.com/5kd6vd)|[Week 26](https://www.reddit.com/6d7nb1)|[Week 36](https://www.reddit.com/7e3fx6)|[Week 46](https://reddit.com/8x48oj)|[Week 56](https://reddit.com/ap8ctk)|[Week 66](https://reddit.com/cd7gko)|[Week 76](https://reddit.com/e4nmyk)|[Week 86](https://reddit.com/g4eavg)|[Week 96](https://reddit.com/j0xr24)|[Week 106](https://reddit.com/ljx92n)||
|[Week 7](https://www.reddit.com/52t6mo)|[Week 17](https://www.reddit.com/5ob7dx)|[Week 27](https://www.reddit.com/6gngwc)|[Week 37](https://www.reddit.com/7hcc2c)|[Week 47](https://reddit.com/910jmh)|[Week 57](https://reddit.com/auci7c)|[Week 67](https://reddit.com/cj0kyc)|[Week 77](https://reddit.com/eb4lxk)|[Week 87](https://reddit.com/gcx3uf)|[Week 97](https://reddit.com/j9cbfs)|[Week 107](https://reddit.com/luqbxl)||
|[Week 8](https://www.reddit.com/53heol)|[Week 18](https://www.reddit.com/5r14yd)|[Week 28](https://www.reddit.com/6jgdva)|[Week 38](https://www.reddit.com/7kgcqr)|[Week 48](https://reddit.com/94up0g)|[Week 58](https://reddit.com/azjoht)|[Week 68](https://reddit.com/cp1jex)|[Week 78](https://reddit.com/ehbfst)|[Week 88](https://reddit.com/glm6sv)|[Week 98](https://reddit.com/jhzz9v)|[Week 108](https://reddit.com/m52u5z)||
|[Week 9](https://www.reddit.com/54kvsu)|[Week 19](https://www.reddit.com/5tt9cz)|[Week 29](https://www.reddit.com/6m9l1v)|[Week 39](https://www.reddit.com/7nayri)|[Week 49](https://reddit.com/98n2rt)|[Week 59](https://reddit.com/b50r5y)|[Week 69](https://reddit.com/cvde5a)|[Week 79](https://reddit.com/entcxy)|[Week 89](https://reddit.com/gu5t0d)|[Week 99](https://reddit.com/jqjgo2)|[Week 109](https://reddit.com/mf8m6u)||
|[Week 10](https://www.reddit.com/56s2oa)|[Week 20](https://www.reddit.com/5wh2wb)|[Week 30](https://www.reddit.com/6p3ha7)|[Week 40](https://www.reddit.com/7qel9p)|[Week 50](https://reddit.com/9cf158)|[Week 60](https://reddit.com/bakew0)|[Week 70](https://reddit.com/d1g1k9)|[Week 80](https://reddit.com/euctyw)|[Week 90](https://reddit.com/hddf7j)|[Week 100](https://reddit.com/jz3evt)|[Week 110](https://reddit.com/moy40m)||

Most upvoted papers two weeks ago:

/u/kadisonsinger: [https://arxiv.org/abs/1802.05296](https://arxiv.org/abs/1802.05296)

/u/Z30G0D: [https://arxiv.org/pdf/2103.02667.pdf](https://arxiv.org/pdf/2103.02667.pdf)

/u/FakespotAnalysisBot: [Link to Fakespot Analysis](https://fakespot.com/product/make-art-with-artificial-intelligence-make-and-sell-your-art-with-ai-blockchain-and-nft-awesome-ai)

Besides that, there are no rules, have fun."
1,MachineLearning,"Project development presentation: [https://www.youtube.com/watch?v=spDbteQAlbE](https://www.youtube.com/watch?v=spDbteQAlbE)

This project aims to be particularly useful towards those, such as myself, who are interested in trading and investing in the stock market, but have little time to find or do their own research.

I am filtering out the most valuable posts from r/WallStreetBets by using supervised classification (naive-bayes) based on stock growths and text data in order to help any busy user quickly filter out what they want to read.

This is done in the goal of further democratizing stock trading by making the access to insightful stock research easier. Most people already know about the mainstream news outlets, this is why I chose this subreddit, where unique, unpopularized and insightful research are buried in a sea of quality memes.

More technical details on my GitHub: [https://github.com/Fryingpannn/WallStreetBets\_BigDataAnalysis](https://github.com/Fryingpannn/WallStreetBets_BigDataAnalysis)

Let me know what you think! :)"
2,MachineLearning,"&#x200B;

https://reddit.com/link/nds1x8/video/r975f497fiz61/player

**Usecase**

While digitalization is transforming our lives, 99% of musicians are still playing with physically printed scores. In contrast to printed books, this is not because they like them, they are quite a pain actually:

\- You must buy/print them and therefore you cannot just spontaneously try out a piece

\- If you play longer pieces you must interrupt your playing to flip the page or ask someone to do it for you

\- They often fall off or get blown away by the wind if you are outside

But sad truth is that there isn't really an alternative yet. Of course there are apps but there you must interrupt playing all the time to flip the page or preset a speed that is super-annoying, which is why musicians have always stuck to printed scores.

**Concept**

By flipping the pages via facial expression - e.g. by opening the mouth or turning the head rapidly (in the end there have to be several options to accommodate different instruments/preferences) - digital scores become super-handy and easy to use. All one needs is an app for smartphones and tablets that can recognize facial expressions via the front camera and flip the page. Building on that, one can implement lots of premium features (e.g. a pedal) to make the app profitable as well.

**Technical Solution**

I have already built a little Python prototype (--> video) with OpenCV facial landmarks where one flips pages by opening the mouth. Obviously, it's very vulnerable to changing light conditions and from what I could find out online, the process should be too tough on computing power for most smartphones/tablets. Therefore, I'm open to taking a different approach to the development of the actual product. One approach that came to my mind:

1. Take a dataset with e.g. 50 000 human faces and use Open CV (or something comparable) to label them according to the degree of mouth opened and later blinking/head turned etc. Label the ones where landmarks don't work manually and ideally check all the other ones as well.
2. Train a Neural Network on the labeled dataset \[assuming that running it later requires less computing power than landmarks\].
3. Implement the Neural Network in the mobile app. Assuming that Python wouldn't be efficient enough, I am thinking of PWA, for example, Xamarin or React Native.

**Context**

I'm myself a recent architecture graduate; therefore, my coding skills beyond Python and C# are slightly limited. I did the course on Machine Learning by Andrew Ng and did a few projects (like the prototype), still I wouldn't consider myself advanced in the field. Even worse, I haven't ever written a mobile app yet.

**I'm looking for**

1. Your feedback and your input - particularly on the Technical Solution.
2. **You**: I'd be more than happy to share this adventure; feel more than free to contact me!

Cheers,

Julian  


In case there's trouble with the vid: [https://www.youtube.com/watch?v=GZR9S1HFnUg&ab\_channel=JulianKlausTrummer](https://www.youtube.com/watch?v=GZR9S1HFnUg&ab_channel=JulianKlausTrummer)"
3,MachineLearning,"I created a repository of pretrained models in Flax that can be easily installed via pip.  
Github: [https://github.com/matthias-wright/flaxmodels](https://github.com/matthias-wright/flaxmodels)

**Current models**

* GPT2
* StyleGAN2
* ResNet{18, 34, 50, 101, 152}
* VGG{16, 19}

I will also add more models in the future.

**Here are some notebooks to play with on Colab**  
[GPT2](https://colab.research.google.com/drive/1j58Bnt1n-k4UJRQI9jnJAJIxME8ZDZjj?usp=sharing), [StyleGAN2](https://colab.research.google.com/drive/1klNP4LbrXK5P3KwFM9_PqCVx5MwwilCI?usp=sharing), [ResNet](https://colab.research.google.com/drive/1hjOV3_3OT5xz0iaj4fdCJurL7XWBJUWc?usp=sharing), [VGG](https://colab.research.google.com/drive/1wIzRnxlxJmrZNsUthtjKWPKULKzvacPD?usp=sharing)"
4,MachineLearning,"I have often seen the ""representor theorem"" mentioned in machine learning, but I have never been able to fully understand the application and relevance of this theorem in machine learning:

https://en.wikipedia.org/wiki/Representer_theorem

https://analyticsindiamag.com/what-is-representer-theorem-in-machine-learning/

Can someone please try to explain this in a simpler way? How is it different from mercer's theorem?

Thanks"
5,MachineLearning,"Hello, all!

I wanted to ask the community whether there are any recent good papers that concern general credit fraud or perhaps even financial fraud in general that you'd recommend. I'm aware there's a lot of content based on the famous credit card fraud dataset, however, I'm more interested in credit fraud that doesn't concern that specific dataset. I'm also open to hearing about machine learning applications that could be considered/adapted for such modelling.

Please feel free to plug in your own research too. Thanks in advance!"
6,MachineLearning,"Although BERT became really popular after its release, it did have some limitations. And there were certain limitations associated with autoregressive methods like ELMo and GPT as well. XLNet was introduced to get the best of both worlds while at the same time not include their weaknesses.

In continuation of my Paper Notes series, I have written an informative summary of the paper. Personally, reading the XLNet paper was a very fun experience. I was amazed at every step, how they were including stuff to make the whole model work so well. The paper contained many interesting concepts that I had to give time to understand. So don't worry if you don't get it on the first go. Check out the links below and happy reading! 

Paper Summary -  [XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://shreyansh26.github.io/post/2021-05-16_generalized_autoregressive_pretraining_xlnet/)

Annotated Paper -  [https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/XLNet.pdf](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/XLNet.pdf)"
7,MachineLearning,"I am currently trying to implement a paper which involves K Nearest Neighbours with ""Large Margin Nearest Neighbour"" for distance metric learning to improve KNN's performance. I have checked out the paper ""Distance Metric Learning for Large Margin Nearest Neighbor Classification \[[https://jmlr.csail.mit.edu/papers/volume10/weinberger09a/weinberger09a.pdf](https://jmlr.csail.mit.edu/papers/volume10/weinberger09a/weinberger09a.pdf)\]"" which had introduced the LMNN idea. While I am clear about the role of LMNN in KNN and other aspects, I am not clear about how the loss function for LMNN algorithm is optimized (authors have mentioned an algorithm for optimization but I am finding it complicated to understand). The project is actually an Android app (Java/Kotlin), so can't take advantage of the Python libs (also I would really like to learn the optimization algo so don't want to blindly use a lib too). So question is -- is anyone here aware of how the optimization works for LMNN or do you have any resources where this otpimization algo is explained in simpler way? Would really appreciate any help."
8,MachineLearning," Hello, i am an undergraduate student with a goal of getting into ML research and academia. Recently i was informed of the NAACL conference (which is conducted virtually) and it seems that i qualify for the Student fee which is 25$ however one must register for an ACL membership (for 50$) so in total it's 75$.

Im not cheap but to be honest im not financially doing very well currently, but if the benefits from attending the conference out weigh the costs for an aspiring researcher then i can register.

The question is, do the benefits out-weigh the costs?"
9,MachineLearning,"Recently Pytorch held an ecosystem day - event, that brings developers and practitioners together to share how they integrate their recent software/packages with Pytorch. Original post is [here](https://irregularadel.substack.com/p/highlights-of-pytorch-ecosystem-days).

[How one of the most popular DL frameworks builds the whole ecosystem of software and packages around itself.](https://preview.redd.it/7407gil77az61.png?width=1571&format=png&auto=webp&s=fe591337b0ff229cf8d5eb8c56a231cfdcb736ab)

When I first saw it, I registered straight away. But boy, I must say, the schedule and organizational part disappointed me. The info and schedule were in Google docs (and yes, Google develops a direct competitor framework), it was big, overloaded, and hard to understand. In comparison, Google created a simple, easy to use and fancyÂ [webpage](https://events.google.com/io/program/schedule?lng=en-US)Â with the schedule of their similar Google I/O event. As a Pytorch fan, I feel a bit ashamed.

Still, the event is full of content! Itâ€™s great that Pytorch and the Community support each other in better tools development.

To the content!

# Summary:

First of all, I see that products based on Pytorch are growing rapidly, and packages are becoming more and more domain-specific.

There are wrappers over PyTorch like Pytorch-lightning, Ignite, fastai, Catalyst - they meant to make high-level API with lots of SOTA features implemented.

The level of specification of pytorch ecosystem goes deeper each year - we now can find not only CV/NLP packages but also biomedical imaging, audio, time-series, reinforcement learning. 2D/3D Augmentation libraries, MLOps solutions. Some packages help to diagnose your models, like finding model drift, mitigate unfairness, compress them. I even saw a separate MLOps package for automated driving\*\*.\*\*

The whole ecosystem isÂ [here](https://pytorch.org/ecosystem/), and it quite interesting to dive into it. There are in total 60 (!) tools, libraries, and packages there. Soon, they will need an advanced filtering/categorization system.Â 

It is amazing, how fast this ecosystem grows, curious to see the next step of this evolution.

# Posters:

They are here - [https://pytorch.org/ecosystem/pted/2021](https://pytorch.org/ecosystem/pted/2021)

I decided to start from the posters. and not from the videos, since imo posters are more interesting.

There are posters for such wide-known products like huggingface, pytorch lightning, etc. - I wonâ€™t mention them. Below is the list of something new/interesting that I personally want to mention.

* [**PyTorch development in VS Code**](https://assets.pytorch.org/pted2021/posters/A4.png)Â **-**Â they have profiler and tensorboard integration. I am using PyChram right now, but thinking more and more about switching to VS code.
* [**Upcoming features in TorchScript**](https://assets.pytorch.org/pted2021/posters/A5.png)
* [**AI Model Efficiency Toolkit (AIMET)**](https://assets.pytorch.org/pted2021/posters/D4.png)\- about model compression
* [**Enabling PyTorch on AMD Instinctâ„¢ GPUs with the AMD ROCmâ„¢ Open Software Platform**](https://assets.pytorch.org/pted2021/posters/K8.png)Â **-**Â nice to see that AMD is catching up finally
* [**TorchStudio, a machine learning studio software based on PyTorch**](https://assets.pytorch.org/pted2021/posters/F4.png)Â **-**Â yes, Pytorch focused IDE. Product is not ready but looks interesting
* [**High-fidelity performance metrics for generative models in PyTorch**](https://assets.pytorch.org/pted2021/posters/K3.png)
* [**UPIT: A fastai Package for Unpaired Image-to-Image Translation**](https://assets.pytorch.org/pted2021/posters/A7.png)
* [**CompressAI: a research library and evaluation platform for end-to-end compression**](https://assets.pytorch.org/pted2021/posters/D6.png)
* [**pystiche: A Framework for Neural Style Transfer**](https://assets.pytorch.org/pted2021/posters/D7.png)

# Videos:

There are opening talk videos for EMEA and APAC.

* [Morning/EMEA Opening Talks](https://www.youtube.com/watch?v=MYE01-XaSZA)
* [Evening/APAC Opening Talks](https://www.youtube.com/watch?v=CjU_6OaYKpw)

They are more or less the same. To be honest, I would recommend skipping those and watch cuts from them instead.

[**My Journey to PyTorch by Piotr Bialecki @Nvidia**](https://www.youtube.com/watch?v=rZcWPG-7zA0)  
You probably know Piotr Bialecki if you are using pytorch - he is the guy who answers most of the questions in pytorch forum. Piotr is the Technical Lead of The PyTorch Team @ NVIDIA.He speaks about his path in ML/DL, how he started to use pytorch, he reflects on the past and looks forward.You should watch that, if you need a little inspiration.

[Youtube comment about Piotr](https://preview.redd.it/ts3bn1qv7az61.png?width=362&format=png&auto=webp&s=eba87e5982119e4d2aca7ef2766be4301e30d183)

[**PyTorch Release by Joe Spisak**](https://www.youtube.com/watch?v=BLG4o7RCqTg)  
You should watch this video, If you want to learn more about latest pytorch release features from PyTorch Product Lead u/Facebook AI. Joe speaks about

* python code transformations with FX (it is a toolkit for pass writers to facilitate Python-to-Python transformation of nn.Module instances - not sure everyone will need this)
* torch.linalg - provides NumPy-ish linear algebra operations support
* torch.fft that cover discrete Fourier transforms and related functions
* pytoch native profiler (yay!) with tensorboard plugin
* distributed training (including support of AMDÂ *(sic!)*Â GPUs)

[**PyTorch Partner Collaborations by Geeta Chauhan**](https://www.youtube.com/watch?v=Ff4o9xX98eY)  
Geeta leads AI Partnership Engineering at Facebook AI. Nice lecture for the ones who want to know recent collaboration features. She talks about:

* more details onÂ **profiler,**Â with use cases, integrations into partnering frameworks, etc.
* scaling in production with torchserve (meant to be model serving framework for PyTorch that makes it easy to deploy trained PyTorch models performantly at scale without having to write custom code)
* MLOps with Kubeflow (building pipelines)
* MLOps with MLFlow (from model artifact serving to auto-tracking of pytorch training metrics, hyperparameters search)

[**Disney's Creative Genome by Miquel FarrÃ©**](https://www.youtube.com/watch?v=KuDxEhHk2Rk)  
Miquel is Senior Technology Manager u/Disney. He speaks about Creative Genome - a project aimed to provide curated time-based metadata. On top of this metadata, they are building their models to recognize their characters in movies/animations/comics/series, detect certain activities and events.

[Capitan Alice in wonderland](https://preview.redd.it/5giswmvl8az61.png?width=738&format=png&auto=webp&s=62bc9da6fb0cbb1064dfaa04b1fd2fc1ff5ae32f)

[**Community Updates by Suraj Subramanian - PyTorch Developer Advocate @Faceook AI**](https://www.youtube.com/watch?v=0c53X2tiwps)  
Well, the name speaks for itself. Suraj gives some statistics on contributions into PyTorch, and also speak a bit about the ecosystem.

[**Applications of AI and PyTorch in Asia Pacific by Ritchie Ng**](https://www.youtube.com/watch?v=VSC7WBFMuZo)  
Ritchie Ng is the CEO of Hessian Matrix, an AI systematic global hedge fund based in Singapore. He provides an overview of APAC, speaks about CV in e-commerce and retail, NLP in finance.

# More resources:

* [Contributor Newsletter](https://pytorch.org/resources/contributors/)Â \- Includes curated news including RFCs, feature roadmaps, notable PRs, editorials from developers, and more to support keeping track of everything thatâ€™s happening in our community.
* [Contributors Discussion Forum](https://dev-discuss.pytorch.org/)Â \- Designed for contributors to learn and collaborate on the latest development across PyTorch.
* [PyTorch Developer Podcast (Beta)](https://pytorch-dev-podcast.simplecast.com/)Â \- Edward Yang, PyTorch Research Scientist, at Facebook AI shares bite-sized (10 to 20 mins) podcast episodes discussing topics about all sorts of internal development topics in PyTorch.

Good luck diving into that!"
10,MachineLearning,"Hi guys.
I am looking for an international internship in machine learning or computer vision.
I am really enthusiastic about these areas but I had no luck in finding an appropriate internship whether remote or not. I am located in the middle east.
Do you have any suggestions where can I gain experience in this area?
Thanks in advance."
11,MachineLearning,"we always imagine how classes get more and more clustered throughout the network. In this simple demonstration, I took a trained VGG13 on CIFAR10, and show a UMAP on the unraveled features at every latent space throughout the layers. 

[UMAP of selected layers of a model trained on MNIST ](https://preview.redd.it/8139slgg9fz61.jpg?width=2225&format=pjpg&auto=webp&s=ffe30f8604df809c8827e481d3d4117c7cd492aa)

[UMAP of layers of trained VGG13 on CIFAR10](https://reddit.com/link/ndhqy5/video/7ye9tr0d9fz61/player)

Full Post: [https://twitter.com/ml\_norms/status/1393687280049696774](https://twitter.com/ml_norms/status/1393687280049696774)"
12,MachineLearning,"Hi there. I am one of the editors from [The Gradient](https://thegradient.pub/), which I think (or hope) many on here have seen and like. Having been around for more than 3 years now, we've decided to branch out beyond what we've been doing and just released [the first edition](https://thegradientpub.substack.com/p/update-1-fbi-usage-of-facial-recognition) of our newsletter, The Update. 

Though admittedly I am making this post partially to promote it, since it's the very first one I also really want to ask for your opinions on the format/length/content of it and whether you find it compelling. We discussed how to create something we thought was different from other newsletters out there and actually interesting/worth reading, but it's hard to tell if what we came up with is actually good.

So would appreciate your feedback!"
13,MachineLearning,"Some that I know of:

* [https://www.paperswithname.com/](https://www.paperswithname.com/) (free) for downloading Arxiv papers with the title as filename.
* [Mendeley](https://www.mendeley.com/download-reference-manager/) (first 2GB of storage free) for organizing papers and storing them in the cloud.
* [Zotero](https://www.zotero.org/) (free?) for organizing papers locally."
14,MachineLearning,"""Forbidden knowledge in machine learning refections on the limits of research and publication.""  


by Dr. Thilo Hagendorff  


""Certain research strands can yield â€œforbidden knowledgeâ€. This term refers to knowledge that is considered too sensitive, dangerous or taboo to be produced or shared. Discourses about such publication restrictions are already entrenched in scientifc felds like IT security, synthetic biology or nuclear physics research. This paper makes the case for transferring this discourse to machine learning research. Some machine learning applications can very easily be misused and unfold harmful consequences, for instance, with regard to generative video or text synthesis, personality analysis, behavior manipulation, software vulnerability detection and the like"" 

&#x200B;

Linkt to paper:  [https://link.springer.com/article/10.1007/s00146-020-01045-4](https://link.springer.com/article/10.1007/s00146-020-01045-4)"
15,MachineLearning,"Mark writes ([https://twitter.com/yieldthought/status/1393589699357429761](https://twitter.com/yieldthought/status/1393589699357429761)):

>I increasingly feel like conferences matter less than Twitter+GitHub. By the time a paper hits conference the state of the art is two papers further. Acceptance by u/wightmanr into timm and hitting u/karpathyâ€™s arxiv-sanity trending is arguably more impactful than a NeurIPS talk.

&#x200B;

Andrej Karpathy writes ([https://twitter.com/karpathy/status/1393616063598776333](https://twitter.com/karpathy/status/1393616063598776333)):

>Thereâ€™s a few other prestigious venues like [@ykilcher](https://twitter.com/ykilcher) YouTube, paperswithcode, [@ak92501](https://twitter.com/ak92501)et al tweet streams etc :) but yes. I rather like the emerging hybrid model where the new cheap low latency async distributed consensus layer coexists with the legacy â€œLayer 1 chainâ€ (pubs)

&#x200B;

Arguably, this subreddit is also playing a role in this trend. Without being part of the traditional academic community, I feel like I have learned more about AI and ML without the need to do a Ph.D. or attend a conference. And I am deeply grateful this is possible. Thank you!  


What are the thoughts of others on this trend?"
16,MachineLearning,"**Is there a mathematical model of the Mind?**

Please join us for a virtual Google workshop on â€œ[Conceptual Understanding of Deep Learning](https://sites.google.com/view/conceptualdlworkshop/home)â€Â 

**When**:Â May 17th 9am-4pm PST.Â 

**Where**: [Live over Youtube](https://www.youtube.com/watch?v=g5DGBWjiULQ),

**Goal:** How does the Brain/Mind (perhaps even an artificial one) work at an algorithmic level? While deep learning has produced tremendous technological strides in recent decades, there is an unsettling feeling of a lack of â€œconceptualâ€ understanding of why it works and to what extent it will work in the current form. The goal of the workshop is to bring together theorists and practitioners to develop an understanding of the right algorithmic view of deep learning, characterizing the class of functions that can be learned, coming up with the right learning architecture that may (provably) learn multiple functions, concepts and remember them over time as humans do, theoretical understanding of language, logic, RL, meta learning and lifelong learning.

The speakers and panelists include **Turing award** winners Geoffrey Hinton, Leslie Valiant, and Godel Prize winner Christos Papadimitriou, and experts from diverse backgrounds including, ML/AI, algorithms, theory, and neuroscience ([full-details](https://sites.google.com/view/conceptualdlworkshop/home)).

**Panel Discussion:** There will also be a panel discussion on the fundamental question of â€œ**Is there a mathematical model for the Mind**?â€. We will explore basic questions such as â€œIs there a provable algorithm that captures the essential capabilities of the mind?â€, â€œHow do we remember complex phenomena?â€, â€œHow is a knowledge graph created automatically?â€, â€œHow do we learn new concepts, function and action hierarchies over time?â€ and â€œWhy do human decisions seem so interpretable?â€

Twitter:[ \#ConceptualDLWorkshop](https://twitter.com/search?q=%23ConceptualDLWorkshop&src=recent_search_click). Please [Retweet](https://twitter.com/rinapy/status/1384311169519788032). Hope to see you there!

Rina Panigrahy

([http://theory.stanford.edu/\~rinap](http://theory.stanford.edu/~rinap))"
17,MachineLearning,"[https://youtu.be/W-O7AZNzbzQ](https://youtu.be/W-O7AZNzbzQ)

GANs have dominated the image generation space for the majority of the last decade. This paper shows for the first time, how a non-GAN model, a DDPM, can be improved to overtake GANs at standard evaluation metrics for image generation. The produced samples look amazing and other than GANs, the new model has a formal probabilistic foundation. Is there a future for GANs or are Diffusion Models going to overtake them for good?

&#x200B;

OUTLINE:

0:00 - Intro & Overview

4:10 - Denoising Diffusion Probabilistic Models

11:30 - Formal derivation of the training loss

23:00 - Training in practice

27:55 - Learning the covariance

31:25 - Improving the noise schedule

33:35 - Reducing the loss gradient noise

40:35 - Classifier guidance

52:50 - Experimental Results

&#x200B;

Paper (this): [https://arxiv.org/abs/2105.05233](https://arxiv.org/abs/2105.05233)

Paper (previous): [https://arxiv.org/abs/2102.09672](https://arxiv.org/abs/2102.09672)

Code: [https://github.com/openai/guided-diffusion](https://github.com/openai/guided-diffusion)"
18,MachineLearning,"There are certain behaviours in AI/ML models that mimic natural phenomena.

Zebras confuse their predators with the striped pattern on their body. This is similar to adversarial attacks on ML/AI models. 

Could we possibly learn more from naturalists as the AI/ML community? What other phenomena are there?"
19,MachineLearning,"Hello everyone!

Want to join the place where people learn from research papers while talking to each other?

Paperfella is an app for that. It currently has two main functionalities.

1. It creates a smart real-time chat per research paper.
2. It improves the research papers so you can read it in vertical mode in your mobile without zooming. And you can also break down a word or expression to its most basic meaning by just touching the word or expression (Cambridge Dictionary's API). It also applies better styles on the typography and math symbols.

I want to talk to some people who'd like to help me with this idea or are interested in it."
20,MachineLearning," I have an image regression task. For example, to predict a person age given an image of his face. But I have some more auxiliary information for each image that is known to be correlated with the prediction - For example, weight, gender, race, etc.
How can I combine the auxiliary data with the image data ?
So naturally I can quantize the auxiliary data into a finite number of options and train a neural network for each dataset. But this is a poor option for many reasons, a main one is because I am using only a portion of the data for each network.
Can you refer me to a paper or architecture that use auxiliary information with a CNN ?"
21,MachineLearning,"A research team from Google shows that replacing transformersâ€™ self-attention sublayers with Fourier Transform achieves 92 percent of BERT accuracy on the GLUE benchmark with training times seven times faster on GPUs and twice as fast on TPUs.

Here is a quick read: [Google Replaces BERT Self-Attention with Fourier Transform: 92% Accuracy, 7 Times Faster on GPUs.](https://syncedreview.com/2021/05/14/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-19/)

The paper *FNet: Mixing Tokens with Fourier Transforms* is on [arXiv](https://arxiv.org/abs/2105.03824)."
22,MachineLearning,Hi. I'm building my own GPU Render Farm on NVIDIA RTX 3080 and 3090. I rent out my systems to 3d designers to render their projects. It's interesting to me if I can provide AI developers with powerful systems to do AI tests and so on. Do they need such rigs for calculation? What do you think?
23,MachineLearning,"Promising signs from WSL 2 GPU support for Docker on Windows....

Is Tensorflow GPU acceleration now possible running in Windows based Docker containers?

Before I revisit this and sink huge amounts of time trying to do the impossible (again) has anyone had success with this?

The learning experience was â€˜funâ€™ the first time, but probably much less so the second."
24,MachineLearning,"[Chen Gao](http://chengao.vision/)  [Ayush Saraf](https://free-view-video.github.io/#)  [Johannes Kopf](https://johanneskopf.de/)  [Jia-Bin Huang](https://filebox.ece.vt.edu/~jbhuang/)

**Project:** [**https://free-view-video.github.io/**](https://free-view-video.github.io/)  
**Abstract**:  We present an algorithm for generating novel views at arbitrary viewpoints and any input time step given a monocular video of a dynamic scene. Our work builds upon recent advances in neural implicit representation and uses continuous and differentiable functions for modeling the time-varying structure and the appearance of the scene. We jointly train a time-invariant static NeRF and a time-varying dynamic NeRF, and learn how to blend the results in an unsupervised manner. However, learning this implicit function from a single video is highly ill-posed (with infinitely many solutions that match the input video). To resolve the ambiguity, we introduce regularization losses to encourage a more physically plausible solution. We show extensive quantitative and qualitative results of dynamic view synthesis from casually captured videos.  


https://reddit.com/link/nd4d2t/video/7td8275wmbz61/player"
25,MachineLearning,"This blog lists out (All?) popular Unsupervised Keyword Extraction Algorithms in NLP. 

Here, I summarize almost 10 papers w.r.t all these techniques. Enjoy the read! ðŸŽ‰ 


https://link.medium.com/4ah0jdgXhgb"
26,MachineLearning,"Is there anything like this being developed? Like distributing training of Deep learning systems among computers around the world and then hosting it the same way. No single point of control or failure. 

I think it could be an interesting way to have truly open development of AI systems controlled by the people not behind paywalls. Could possibly be tied to a crypto to incentivize donating resources to the forward and backward computations."
27,MachineLearning,"The idea of creating confidence intervals in regression models is quite straightforward. 

For example :
https://www.researchgate.net/profile/Folorunso-Oludayo-Fasina/publication/284729754/figure/fig2/AS:300625800777756@1448686184816/Scatter-plot-with-linear-regression-fit-and-a-95-confidence-interval-for-reported.png

But do confidence intervals carry over to classification models?

1) For example, in this picture here (confidence interval for an ROC curve corresponding to a classification model ) https://i.stack.imgur.com/Y7KSNm.png - can the lower limit of the confidence interval from this ROC curve be used to gauge how well this model might generalize to new data?

2) For a classification model, can we make a confidence interval for the prediction of an individual observation? For instance, I wrote some R code (you can directly copy/paste the code) for a particular example where a random forest (i.e. classification model) is used to predict whether if an observation will be ""approved"" or ""rejected"" (see here for the code: https://shrib.com/#Madelyn_NMjYE8) .

Thus, for each observation, the classification model predicts the probability that this observation will be ""approved"" or ""rejected"". Whichever probability is higher, the model selects that outcome for the given observation.

Also, the higher one of these probabilities are, this means the classification model is more confident with its prediction (e.g. for two observations, the ratio of approved:rejected 0.9:0.1 vs 0.6:0.4 . The model is more confident about the first prediction)

Thus, is there anyway to apply the notion of confidence intervals to the probabilities for individual predictions?

Thanks"
28,MachineLearning,"Hi guys,

I'd like to ask the community for a problem I am trying to solve at the workplace.

We have a client that owns a series of restaurants over the territory. Every week, these restaurants receive food deliveries and our client keeps track of how much food is given to them vs how much it is sold.

The idea is simple: he uses an in-house algorithm that tunes the number of items a specific restaurant should receive for the week so that the number of unsold items doesn't (hopefully) go under a ""dangerous"" threshold. If the restaurant consistently sells most of the food it receives, the algorithm flags it as consistent and keeps on sending a similar number of food pieces every week. Otherwise, the number of deliveries is reduced to attempt to balance the number of unsold items.

This has worked quite well for the client, but he has asked me and my team to improve this process.

He has sent us data from a single restaurant that holds data from the beginning of 2021. The columns are the following -> restaurant\_id, date, type (delivered / sold), quantity, food\_description.

Do you have any ideas on how this problem can be tackled? I was thinking of linear regression and to use the number of sold items as my X to predict the y, which would be the number of items to deliver. I still don't know if this makes sense, so I am asking around for some ideas.

Thank you,"
29,MachineLearning,"Hi All,

I developed my own simple character level language model.  If I use natural log, I get the loss of \~1 for english. However, literature reports \~1 bit per character which is far ahead of mine. The natural log and log2 differs at a factor of ln2. 

My question (double check): is it possible that  the literature acturally mis-reported natural log rather than log2? for example I see minGTP reports natural log loss."
30,MachineLearning,"When training a GAN, should you track gradients w.r.t. the input noise vector? So if you have code like this:

```python
z = torch.randn(...) # generate noise vector
z.requires_grad = True # Is this necessary? 
generated = generator(z)
```

Is the `requires_grad` necessary? What would it actually _mean_ if we were to track gradients in the input noise?"
31,MachineLearning,"I have been trying to convert my tensorflow model to one that works with TPU but can't seem to do so. I have been trying to do so over a month now. 

I am getting this error: InvalidArgumentError: Unable to parse tensor proto 

So I  used a takedataset of 10, reduced the batch size to 16 and reduced the image dimensions. Still the same error.

What is wrong? Are TPUs worth the hassle of conversion in terms of speed?"
32,MachineLearning,"Hello Guys,

We  are going to have Sebastian Risi to discuss his latest research on  â€˜Minecraftâ€™ structures that build themselves and regenerating soft  robots through neural cellular automata, if you have any questions you  can send them here: [https://docs.google.com/forms/d/e/1FAIpQLSfQNaOhf\_OflZuiNzjhb-zH2vUDB4vLYCSI\_Qf7VYpEcBIEHg/viewform?vc=0&c=0&w=1&flr=0](https://docs.google.com/forms/d/e/1FAIpQLSfQNaOhf_OflZuiNzjhb-zH2vUDB4vLYCSI_Qf7VYpEcBIEHg/viewform?vc=0&c=0&w=1&flr=0)

For more details:

\[1\] Growing 3D Artefacts and Functional Machines with Neural Cellular Automata : [https://arxiv.org/abs/2103.08737](https://arxiv.org/abs/2103.08737)

\[2\] Regenerating Soft Robots throughNeural Cellular Automata: [https://arxiv.org/pdf/2102.02579.pdf](https://arxiv.org/pdf/2102.02579.pdf)

&#x200B;

&#x200B;

&#x200B;

https://preview.redd.it/3pyxrh63x2z61.png?width=2586&format=png&auto=webp&s=7b5cb627251c1e7880fdaa237319a71572fe4f7f"
33,MachineLearning,"In page 4 of Resnet's original paper ([https://arxiv.org/pdf/1512.03385.pdf](https://arxiv.org/pdf/1512.03385.pdf)), it says "" **When the dimensions increase (dotted line shortcuts in Fig. 3) ""** but looking at the network's architecture, the dimension of the input is decreasing due to the strides=2 and the depth is increasing instead, so I wonder if this is a typo or whether I missed something?"
34,MachineLearning,"+ There are many ways of improving machine learning model performance.

+ One such is feature selection.

+Â Amongst many feature selection techniques, genetic algorithm is one.

+ I have created a python library that helps you perform feature selection for your machine learning models.

+ It helps you identifyÂ the best set of features for yourÂ model. Feel free to use it.

pip install EvolutionaryFS


Example notebook:Â https://www.kaggle.com/azimulh/feature-selection-using-evolutionaryfs-library

Pypi page with documentation: https://pypi.org/project/EvolutionaryFS/"
35,MachineLearning,"Github: [https://github.com/SwinTransformer/Transformer-SSL](https://github.com/SwinTransformer/Transformer-SSL)

Tech Report: [https://arxiv.org/pdf/2105.04553.pdf](https://arxiv.org/pdf/2105.04553.pdf)

## Highlights

* **The first work to** i**nclude down-stream evaluation for SSL using Transformers**: provide results of the transferring performance on down-stream tasks of object detection and semantic segmentation
* **Light tricks**: lighter additional tricks than in previous works, such as MoCo v3 and DINO
* **High accuracy on ImageNet-1K linear evaluation**: 72.8 vs 72.5 (MoCo v3) vs 72.5 (DINO, no multi-crop aug.) using DeiT-S/16 and 300 epoch pre-training; 75.3 using Swin-T and 300-ep training"
36,MachineLearning,"For my mini-project, combining Computer Vision + NLP + RL interests me. I've come across this paper -- Recipe1M+: A Dataset for Learning Cross-Modal Embeddings for Cooking Recipes and Food Images where the main task is trainingg a neural network to learn a joint embedding of recipes and images that yields impressive results on an image-recipe retrieval task.Â 

It also has an image to recipe retrieval where theye evaluate all the recipe representations for im2recipe retrieval. Given a food image, the task is to retrieve its recipe from a collection of test recipes.

It also includes some embedding properties like word2vec.

They basically use CNN for encoding the image and RNNs to encode both the recipe and the instructions and then have a joint embedding for the recipe and instructions. Their embedding is created using a cosine Similarity loss and one semantic regularization loss.

For introduction of RL to image captioning, I've seen the they incorporated RL by having their Deep Q Network to learn through action - the next word of the imagecaption, state (the current words on the caption on time t) and reward being some score.

I was wondering how do I introduce Deep RL for this scenario on embeddings. Hopefully you can help guide me."
37,MachineLearning,"I'm using a GPU hosted runtime on Google collab and trying to use visdom for visualisations. I started the visdom server using my computer's terminal and hosted my localhost using ngrok and passed  the generated url inside visdom.Visdom() in Google collab. I'm getting an error saying connection timed out, and as a result another error saying Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom withÂ use_incoming_socket=False"
38,MachineLearning,"# [Improving Inversion and Generation Diversity in StyleGAN using a Gaussianized Latent Space](https://t.me/casual_gan/38)

ðŸŽ¯ At a glance:

>In this paper about improving latent space inversion for a pretrained StyleGAN2 generator the authors propose to model the output of the mapping network as a Gaussian, which can be expressed as a mean and a covariance matrix. This prior is used to regularize images that are projected into latent space  via optimization, which makes the inverted images lie in well conditioned regions of the generator's latent space, and allows for smoother interpolations and better editing.

[Samples from the model](https://preview.redd.it/1058coadc4z61.png?width=1219&format=png&auto=webp&s=42af3487e9d073a608b54ad12d067396e5931b5d)

\[[5 minute summary of main ideas](https://t.me/casual_gan/38)\] \[[arxiv](https://arxiv.org/pdf/2009.06529.pdf)\]  


P.S. Thanks for reading!  
If you found this useful check out other popular ML papers explained on [my channel](https://t.me/casual_gan)!  


**Links to other recent papers explained:**

* [VQ-VAE2](https://t.me/casual_gan/30)
* [StyleGAN2-ada](https://t.me/casual_gan/28)
* [MLP-Mixer](https://t.me/casual_gan/35)"
39,MachineLearning,"I'm trying to fine-rune ResNet-50 for a multiclass classification task. I have around 10k samples and 10 classes (about galaxies), but they're not balanced.

I've currently done the following steps (with some decent results):

* Added on top of resnet 2 Dense layers and a 0.5 dropout
* unfreezed the last 3 layers of ResNet
* added weights to the loss function to account for the imbalanced dataset
* some data augmentation (rotatation and flipping mostly)

What else could improve the results? I'm still new to this so I might have missed something important."
40,MachineLearning,"With COVID and border restrictions slowly easing in the US And Europe (whereas getting worse in India), do you guys think that all these top machine learning and NLP conferences will be in person any time soon?

What is the community view regarding in person conferences?  Do people think virtual conferences are the new norm and more productive/less carbon footprint/more visibility etc...biggest con:   no free travel :( ?"
41,MachineLearning," Hey Friends- you probably get posts from people not in the field who are curious all the time, so apologies.

I'm  looking for any resource I can on tools, applications, companies, or  resources that apply an AI/machine learning approach to game theory  problems. For example, in a COVID like situation where there is a  production limited good (i.e. the vaccine), and there are various groups  of people with different beliefs (1- the vaccine will be lifesaving, 2-  It may be lifesaving, but was developed too quickly, etc. etc. etc)-  I'm interested in modeling different outcomes given different starting  conditions. I won't continue to use the vaccine analogy, as it starts to  break down here- it's just for illustrative purposes.

So  with that being said- I'd love even simply being pointed in the right  direction for where to look for a tool, application, company, or other  resource."
42,MachineLearning,"I am curious as to how other have efficiently implemented crossover of neural network in regards to genetic algorithm.

In the past I have typically have very small networks of < 100 weights and would simply use my CPU to loop through and swap weights 50% of the time - thisnworked well for my needs.

Today my networks have > 10 million weights each and manually lopping through and swapping value will obviously not work due to time constrains - hence this post. 

I have a few ideas of how I could get these to work, specifically by using XOR over the entire matrix.

Any ideas as to if this would work? Are there better alternatives you can think of?

Thanks."
43,MachineLearning,"I have been submitting to top medical imaging conferences (miccai and isbi), I feel like half of the reviewers either didnâ€™t thoroughly read the paper or they were just not familiar with the topics or the conference requirements. I heard reviewers at other conferences are pretty noisy as well, so Iâ€™m wondering how we can improve the quality of the reviews. Iâ€™m gonna provide a few examples from my personal experience 

1. A paper of mine was accepted as ISBI and there were 2 reviewers. One of them thought my methods could do a lot of things that it was not capable of. I feel like they didnâ€™t understand my method and just thought my results looked cool, since itâ€™s pretty easy to see the limitations of my algorithm. The other reviewer obviously didnâ€™t read my paper carefully either. I explicitly explained that the only thing I had in common with a competing previous work was that we both used a graph representation, but the actual methods were completely different. I literally spent most of the introduction explaining this. Then that reviewer claimed my method was not much different from the previous one. 

2. This paper were rejected at miccai. While the reviewersâ€™ concern were valid and they wanted to see more experiments, it was only a 8-page single-column paper. There was no way I could fit all the ablation studies in there. I have already included 3 experiments that were both quantitative and qualitative. Also, a reviewer had a really weird comment regarding this paper. I was using a hierarchical conditional VAE, and the reviewer said the difference between my method and the original VAE was not clear.

3. Iâ€™m not sure if this is a misunderstanding but a reviewer straight up said my results were suspicious because the numbers kind of counter intuitive at first glance. I might need to analyze the results more but I thought the claim was kind of rude."
44,MachineLearning,"During pretraining of BERT, two sentences A and B are given, transformed using WordPiece- and position embeddings, and are made distinct from each other by including two extra features into the input:

- The [SEP] token, which is inserted between sentence A and B,
- The predefined Segment Embeddings, which are added to the the embedding layer.

 What I cant figure out is, why are both of these included? Shouldn't either one by themselves do the job?

The [SEP] token in particular seems redundant to me, as it isn't even used for the Next-Sentence  Prediction pretraining task which instead trains on the [CLS], if I've understood everything correctly."
45,MachineLearning,"Could you suggest possible strategies for Language VAE using Transformer?

Language VAE with RNNs uses the encoder output as an input with Gaussian noise into the decoder RNN.

1. Is it effective to follow a similar strategy for Transformers as well by passing Latent Vector as the start token?
2. Use outputs of the encoder with Gaussian noise as the attention weights into the decoder?

If you find better strategies, please do suggest any."
46,MachineLearning," 

Very interesting & insightful article: ""Why Are We Using Black Box Models in AI When We Donâ€™t Need To? A Lesson From An Explainable AI Competition""

byÂ Cynthia RudinÂ andÂ Joanna Radin

""In 2018, a landmark challenge in artificial intelligence (AI) took place, namely, the Explainable Machine Learning Challenge. The goal of the competition was to create a complicated black box model for the dataset and explain how it worked. One team did not follow the rules. Instead of sending in a black box, they created a model that was fully interpretable. This leads to the question of whether the real world of machine learning is similar to the Explainable Machine Learning Challenge, where black-box models are used even when they are not needed. We discuss this teamâ€™s thought processes during the competition and their implications, which reach far beyond the competition itself.Â ""

Link to paper: [https://hdsr.mitpress.mit.edu/pub/f9kuryi8/release/5](https://hdsr.mitpress.mit.edu/pub/f9kuryi8/release/5)"
47,MachineLearning,"Hi there, in the startup I am working we are exploring which might be viable alternatives to serve our ML models. Our product is mostly a (AI) service, queried via mobile app. We are looking for a solution which is scalable and maintainable, for when requests will grow in number.

Up to now, we have opted for NVIDIA Triton but I am asking for suggestions and/or your feedback on possible (better) alternatives."
48,MachineLearning,"Usually a multidisciplinary work. Usually with fancier images than ML/DL conferences.

But for arch. most only use simple combination of models like CNN, resnet. LSTM.

What are your thoughts on those works?"
49,MachineLearning,"&#x200B;

https://reddit.com/link/nc72uo/video/f0fqtjfwt2z61/player

What if we want to extract and summarize text from documents, also handle translation, combine the   outputs and load it into an Embeddings index. Enter workflows! The demo above takes a list of GitHub project pages, extracts text from HTML, summarizes the text and builds a similarity search index. This same concept could be applied towards a list of company pages, wikipedia pages and more. This is just one example of what txtai workflows can do.

txtai workflows are a simple yet powerful construct that takes a callable and returns elements. Workflows are streaming by nature and work on data in batches, allowing large volumes of data to be processed efficiently. The amount of functionality provided by machine learning models continues to grow rapidly. txtai provides an easy way to interface with these models. The following is a non-comprehensive list.

\- Questions - Extractive question-answering using a text context  
\- Labels - Apply labels to text using a zero-shot classification model  
\- Summary - Abstractive text summarization  
\- Text Extraction - Extract text from documents  
\- Transcription - Transcribe audio to text  
\- Translation - Machine translation

Workflows  allows joining these models together to create powerful data transformations. Workflows can also be constructed in JavaScript, Go, Rust and Java via the API.

See the following links for more information.

[GitHub](https://github.com/neuml/txtai) | [Workflow builder](https://github.com/neuml/txtai/blob/master/examples/workflows.py) | [Documentation](https://neuml.github.io/txtai) | [Article](https://towardsdatascience.com/run-machine-learning-workflows-to-transform-data-and-build-ai-powered-text-indices-with-txtai-43d769b566a7)"
50,MachineLearning," TLDR: For training from scratch on non-classification tasks with humble computation resources, are ResNets roughly as good as it gets? This has been my experience, although the literature (and the hype surrounding it) does not seem to agree with me at all. Please prove me wrong.

In the past years visual models have transitioned from ResNets to EfficientNets (and more recently Vision Transformers), and temporal/sequence models have transitioned from RNNs to Transformers. While the latter, in my experience, constitute a clear step forward for almost all aplications and resource-scenarios, the former, in my experience, has never really worked for me.

While I'm well aware that pre-trained efficientnets perform extremely well on ImageNet, and are quite successful for finetuning on other classification tasks, and even segmentation, for me they have never worked well for new tasks such as generation from visual features, or self-supervised learning. I have seen some threads about this here and there, but it does not seem to make a dent on the efficientnet hype overall.

There are also other models, such as RegNets and Vision Transformers, but these are still substantially slower during training time than normal ResNets without massive performance improvements (in fact, for vision transformers, this underwhelming behaviour was acknowledged in the recent DINO paper). So basically I am left with the questions: 1. are ResNets roughly as good as it gets?, or 2. Have I not found the good new visual models? or 3. Has my extensive experimentation with these new models led to misleading conclusions?

The fact that very recent self-supervised learning literature is still focused on ResNets (excluding very recent SSL vision transformer works), and that most practicioners I know that do not work strictly with classification still use ResNets, leads me to believe that perhaps there is something to this, and I am not totally deluded. Please prove me wrong. Cheers."
51,MachineLearning,"Check out our recent work, which was accepted by the 2021 International Joint Conference on Artificial Intelligence (IJCAI 2021)! We pose the **Unsupervised Progressive Learning (UPL) problem**: an online representation learning problem in which the learner observes a non-stationary and unlabeled data stream, learning a growing number of features that persist over time even though the data is not stored or replayed. To solve the UPL problem we propose the Self-Taught Associative Memory (STAM) architecture, which leverages online clustering, novelty detection, outlier forgetting, and prototypical feature storage (rather than a replay buffer of raw examples).

https://arxiv.org/abs/1904.02021"
52,MachineLearning,"Hi all, I'd like to use ML/DL for a different objective than usual. I want to find the f(x) in [a,b] that best respects some constraints both on f(x) and on x.
To be clearer, the result of the optimization should be a polynomial function, so anything like ""xÂ³+3x"" or ""2xÂ²+8"" ecc. The reason for using ML and not some bruce force approach is that the ML optimizer can learn which kind of functions better respect the constraints by trial and error and eventually finding the way, but that's just an idea. Maybe ML can't even be used.

I tried to search something in literature but I couldn't find anything. Could you help me out a little, at least for knowing what to look for? Thank you in advance!

EDIT: To be more specific, I have a function f(k,n) that, with fixed k=k0 and varying n (discrete), is something like a bell. Now the problem is that, when k0 increases, the bell width of f(k0,n) increases too. However, instead of f(k,n), I'm allowed to use f(g(k),n), where g(k) is polynomial in k. Now the question is: how can I find the best g(k) such that, when increasing k0, I have that f(g(k0),n) has a constant-width bell? (Let's assume that the width is the number of points on the n axis inside the bell)"
53,MachineLearning,"Free and Open-Source Face Recognition SystemÂ that can be integrated into any system without prior AI knowledge: [https://exadel.com/solutions/compreface/](https://exadel.com/solutions/compreface/)

You may also subscribe to CompreFace News and Updates to never miss new features and product improvements: [https://exadel-7026941.hs-sites.com/en/en/compreface-news-and-updates](https://exadel-7026941.hs-sites.com/en/en/compreface-news-and-updates)"
54,MachineLearning,"*This is satire, treat it as such. Don't take it personally. I know everything is not like this.* 

Terminology

1. Professor = CEO
2. PhD student/Postdocs = Program/Product Manager
3. Master's/Batchelor's students = Code Monkeys, Independent contractors, Unpaid Interns
4. Paper = Product
5. Publishing Paper in big venue = Product release
6. NSF/Amazon/Google/Facebook/Jeffery Epstein/Other Funding Souces = VC Funds. 

Life Cycle of A Product:  

1. CEO thinks of some company vision and hires some program managers. Sells the vision of a product as equity to some dreamy-eyed employees who become the code monkeys.  
2. CEO parallelly makes different code monkeys work on same vision while program managers are chilling. 
3. One code monkey from the army comes up with some new neural lego that works after months. CEO becomes super happy with the outcomes of the lego. Other code monkeys are told to keep working on a problem when there is already a working solution that even they can know. 
4. CEO tells winning code monkey lets make a product out of the lego. Step In Project Managers. No clue of how the lego was built, start dictating how to productize it. 
   1. Winning Code Monkey asks to give spec on what is needed for product release, Project manager gives some requirements. Code monkey satisfies requirements. One week later project manager changes the requirement. The pattern keeps repeating and code monkey keeps getting frustrated. 
5. Winning code Monkey keeps working on the product but CEO and project manager all have their visions on how to sell it.  Winning code Monkey asks for code and detailed information to run lego along with all results be fully open-sourced with the product. CEO and project manager tell the winning code monkey to fuck off because exposing too much information is not good for the product. 
6. On product release, the CEO goes to VC funds for more money to hire more project managers. 
   1. If multiple products succeed, Bask in VC Money.  If fail, no more funds and no more project managers. 
7. On product release, winning code monkey's contract is done and the project manager takes over the product, and post-release the product is shelved because it helped get new funding for the new project managers. Other code monkeys hopelessly play with neural lego dreaming of hopefully productizing one day with some other new vision of the CEO. 

Code monkey very upset that the code got no value in this product space. Code monkey also upset that working with many monkeys in an AGILE way could have made the product much faster but Program managers and CEO didn't like that too much as equity sharing on product becomes the issue.  

But what do I know. I am just a code monkey with a tiny tiny product experience."
55,MachineLearning,"When we talk about ML models' accuracy and other metrics, nobody cares whether they are better than random or not (I am exaggerating a little bit). What people care about is whether the model is *better* than humans' performance.

For some reason, this doesn't seem to be the case for bias and fairness. Whenever people talk about controversial potential algorithms (for instance, AI immigration officers or AI hiring such as HireVue) people get very defensive and say that the algorithms are going to be biased. Of course! 

But are they going to be *more* biased than humans? I highly doubt that. I bet an AI  wouldn't ask me to open my luggage so frequently after I land in London just because I have a beard and am not too white.

In any case, I don't understand why the baseline for fairness/bias for AI algorithms is zero and not human performance. 

Now, I recognize that the expectation of AI from users (e.g. interviewees from HireVue) are much higher than of humans and they might also feel more uncomfortable. So, yes, I do see why we want a fairer/less biased AI than humans but the conversation needs to go deeper than this.

There are costs and benefits to introducing AI -- if it's more accurate than humans, less biased than humans and cheaper than humans, chances are it should be used.

My point is simply saying ""AI is biased"" and putting a period, in my opinion, is not the right way to go about it. A Human is also biased and, in many cases, significantly more biased than the AI."
56,MachineLearning,"Hey everyone!

I created a twitter bot that tweets trending papers in the AI & ML category (cs.AI, cs.CL, cs.CV, cs.LG and stat.ML) on arxiv.org

[@arxivaiml](https://twitter.com/arxivaiml)

Tweets are based on the engagement score of Feedly. The algorithm is simple and naive implementation. If you have any idea to improve the bot, please let me know!"
57,MachineLearning,"I've noticed that a lot of GAN codebases runs the discriminator (D) on the gen'd data once for training the generator (G), and then again on the same data for training D. I guess this is mainly as a convenience because G and D's losses have opposite signs? Is there another upside or do we accept 50% (ish) extra processing time just to avoid a small hassle? Two ways around it I can think of:

1) use a minimizer on G and maximizer on D (a.k.a. negative learning rate)

2) somehow flip the sign of the gradient when backprop'ing from D to G."
58,MachineLearning,"Recently I found out about NFs and their property of being inherently invertible and also allowing conditional generative modelling.


What are some cool works that apply these conditional NFs to medical images? Are there works that try to disentangle features of images using these techniques?"
59,MachineLearning,"I have a dataset of 10 labels. I want to give an input and the model outputs the top 3 similar labels from that input. The input will NEVER be one of the 10 labels, however, I want to see which 3 labels the input is most LIKE. What sort of ML problem is this?

I hope that makes sense"
60,MachineLearning,"Hello everybody,

I read the vision transformers paper and then looked at the implementation in pytorch.

&#x200B;

It is usual in transformers to use positional encoding (using a purely deterministic sine and cosine embedding).

&#x200B;

However in the Vit implementation, the positional encoding is learned by the model itself.

&#x200B;

Someone can explain me: Why a standard positional encoding is not used ? And what is the meaning of learning this positional encoding ?

Thanks you !"
61,MachineLearning,"Project Enigma: https://stefanzukin.com/enigma/

[Stefan Zukin](https://twitter.com/StefanZukin/status/1392503331231342610), a grad student, trained [GPT-2](https://en.wikipedia.org/wiki/GPT-2) on 10,000 Nature papers and created an interactive game with the model, where you try to distinguish between a real abstract and one that is computer generated.

Some of them are quite hard: https://stefanzukin.com/enigma/"
62,MachineLearning,"Hey everyone!

I've been doing machine learning/deep learning for about a year now and would like to make some projects related to Physics.

I'm a CS major but absolutely love physics. I have an entire summer to myself now and would like to know how I could apply ML/DL to Physics problems, preferably using TensorFlow.

Do you guys have some idea about what kinds of problems I could use ML in? I'm willing to learn the required Physics and Mathematics wherever needed.

Thanks!"
63,MachineLearning,"Hi all,

This is technically a repost of a previous post: https://www.reddit.com/r/MachineLearning/comments/n6rqlk/d_deploying_ml_model_for_inference_on_user_devices

I'm still looking for an optimal way to be able to infer my convnets and GANs on user macOS and Windows devices using their GPUs. 

I went through torch to tflite conversion: https://towardsdatascience.com/my-journey-in-converting-pytorch-to-tensorflow-lite-d244376beed

But it doesn't seem to support user GPUs, and frankly I'm stuck looking for optimal solutions.

Any suggestions are super welcome, thank you."
64,MachineLearning,"Hi all, Iâ€™m trying to implement some topic modeling for employee training survey responses. I have 200 different training courses with between 10 and 400 survey comments each. I want to use LDA to extract topics, and then Iâ€™d like to make a word cloud with the actual topic titles colored by the average sentiment. 
 - Is there any way to automatically infer the topic labels (see idea below)? New training are being developed each week that have new topics like excel or providing feedback to the people you manage.
 - Additionally, does anyone know of any way to have a variable k number of topics auto selected by course (some courses are a single topic one hour course, while others are a week long with several training topics)?

 - *Idea for auto-tagging: Iâ€™m thinking about extracting the nouns from my lemmatized text since Iâ€™m truly looking for topics. Thinking I could then create a noun list and label topics by using the most frequent noun in each topic."
65,MachineLearning,"Is there such a resource? There are a lot of new papers these days but not all of them are actually good. Is there a resource where somebody else has already gone to the effort of sifting the wheat from the chaff so that we can see what a great paper should be like?

Alternatively, what are the papers that you think are the most well-written, do ""science"" in the best way, best explanations, actually reproducible based on the paper, don't fluff results?"
66,MachineLearning,"Recently, I've been looking into a number of publicly available datasets, and some of them have non-commercial licenses such as
[SKU-110K](https://github.com/eg4000/SKU110K_CVPR19) and [RPC](https://rpc-dataset.github.io/). My question is: where should you draw the line with commercial use?

Let's say we're doing some work for a profit-seeking company. Training on the datasets for a model that they intend to monetise is clearly not allowed. But what about transfer learning from the models that the authors trained? That seems less clear cut to me, but still quite sketchy. And what about using the dataset to confirm a hypothesis before going out and collecting your own images and annotations?

Any opinions, comments or experience on this that you could share would be most appreciated!"
67,MachineLearning,"Link: [https://arxiv.org/abs/2105.06033](https://arxiv.org/abs/2105.06033)

Recovering badly damaged face images is a useful yet challenging task, especially in extreme cases where the masked or damaged region is very large. One of the major challenges is the ability of the system to generalize on faces outside the training dataset. We propose to tackle this extreme inpainting task with a conditional Generative Adversarial Network (GAN) that utilizes structural information, such as edges, as a prior condition. Edge information can be obtained from the partially masked image and a structurally similar image or a hand drawing. In our proposed conditional GAN, we pass the conditional input in every layer of the encoder while maintaining consistency in the distributions between the learned weights and the incoming conditional input. We demonstrate the effectiveness of our method with badly damaged face examples.

&#x200B;

[Using edges as sketch condition](https://preview.redd.it/tqhnts8nszy61.png?width=1115&format=png&auto=webp&s=be9708fdc17d18fbc3b735c46eb7df884932b130)

[Using the hand-drawn sketch as a condition.](https://preview.redd.it/tjgz3w8nszy61.png?width=1680&format=png&auto=webp&s=522baee91e1d45e745264407d529922e162663c6)

&#x200B;

We were supposed to publish this paper in 2019, but due to unforeseen issues, we had to delay to EI2021."
68,MachineLearning,"A research team from DeepMind explores how neural networks can be fused with algorithmic computation and demonstrates an elegant neural end-to-end pipeline that goes straight from raw inputs to general outputs while emulating an algorithm internally.

Here is a quick read: [DeepMind Presents Neural Algorithmic Reasoning: The Art of Fusing Neural Networks With Algorithmic Computation.](https://syncedreview.com/2021/05/13/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-18/)

 The paper *Neural Algorithmic Reasoning* is on [arXiv](https://arxiv.org/pdf/2105.02761.pdf)."
69,MachineLearning,"Hi there, 
Deep learning is taking over a lot of other machine learning algorithms in industry. 

I was curious in what applications do other algorithms still outperform deep learning. And what algorithms are they?. I am mostly curious on this over in the industry world. If you could provide in the comments 1. The algorithm 2. The application and 3. The industry it would be awesome. Any comments are welcome!"
70,MachineLearning,That's the post.
71,MachineLearning,"Hi guys,
I am using the summarization from hugging face: https://huggingface.co/transformers/task_summary.html#summarization

In some of my summarizations I have realized that some information is added by them model without being present in the input.

Is there any of you experiencing that issue?
If yes how did you resolved it?

Thank you for your help and experience sharing."
72,MachineLearning,"I want to train a bipedal robot to walk using a deep RL controller. What sort of hardware resources would you need to run this training in hours not days?

Options like the NVIDIA DGX Station A100 cost upwards of $150k, but are as close to a data center in your office as you can get. How much does this sort of system speed things up? Amazon has its GPU cloud instance on similar hardware but if you are iterating often does renting end up costing more than just buying hardware?

Is there a general benchmark performance that you need to be able to do RL using sensors like lidar/cameras efficiently?  If so, what hardware fits this category?"
73,MachineLearning,"[PDF on ResearchGate](https://www.researchgate.net/publication/351476107_The_Modern_Mathematics_of_Deep_Learning) / [arXiv](https://arxiv.org/abs/2105.04026) (This review paper will appear as a book chapter in the book ""Theory of Deep Learning"" by Cambridge University Press)

**Abstract:**  We describe the new field of mathematical analysis of deep learning. This field emerged around a list of research questions that were not answered within the classical framework of learning theory. These questions concern: the outstanding generalization power of overparametrized neural networks, the role of depth in deep architectures, the apparent absence of the curse of dimensionality, the surprisingly successful optimization performance despite the non-convexity of the problem, understanding what features are learned, why deep architectures perform exceptionally well in physical problems, and which fine aspects of an architecture affect the behavior of a learning task in which way. We present an overview of modern approaches that yield partial answers to these questions. For selected approaches, we describe the main ideas in more detail."
74,MachineLearning,"&#x200B;

https://preview.redd.it/64iczbg37bz61.png?width=2172&format=png&auto=webp&s=808a3889573ae66abc4e25647e6bf7deabf45a2c

**Paper:** ""Can Vision Transformers Learn without Natural Images?""*Kodai Nakashima, Hirokatsu Kataoka, Asato Matsumoto, Kenji Iwata, Nakamasa Inoue*[https://arxiv.org/abs/2103.13023](https://arxiv.org/abs/2103.13023)

**TL;DR:**  An intriguing study showing that a computer-generated database of  fractals can replace ImageNet to pre-train vision transformers for small  datasets. It would be interesting to try this pre-training method on more challenging tasks, such as ImageNet with 1% labels. **Link to full review in the comments**"
75,MachineLearning,"I want to know what types of tools are available out there.

Would be good if you recommend both desktop based and webapps.

Also free or paid.

I want to explore data annotation tools for all types of labeling.

Text/Image/Video/Audio/Other."
76,MachineLearning,"Excellent visual and vision-language representations are crucial in solving computer vision problems such as image retrieval, image classification, video understanding. That is why visual and vision-language models rely on curated training datasets such as [ImageNet](https://www.image-net.org/), [OpenImages](https://opensource.google/projects/open-images-dataset), [Conceptual Captions](https://ai.google.com/research/ConceptualCaptions), which require expert knowledge and extensive labels. All these datasets need non-trivial data collection and cleaning steps, limiting the size of datasets and hindering the trained modelsâ€™ scale. In comparison, NLP models use large-scale pre-training on raw text *without* human labels and have achieved SotA performance on [GLUE](https://gluebenchmark.com/) and [SuperGLUE](https://super.gluebenchmark.com/) benchmarks.Â 

Google researchers propose a technique to bridge this gap by using publicly available image alt-text data (text appearing in place of an image on a webpage when the image fails to load). The team employs these image alt-text data to train larger, state-of-the-art vision and vision-language models.Â 

Summary: [https://www.marktechpost.com/2021/05/13/google-ai-introduces-align-to-scale-up-visual-and-vision-language-representation-learning-with-noisy-text-supervision/](https://www.marktechpost.com/2021/05/13/google-ai-introduces-align-to-scale-up-visual-and-vision-language-representation-learning-with-noisy-text-supervision/) 

Paper: [https://arxiv.org/pdf/2102.05918.pdf](https://arxiv.org/pdf/2102.05918.pdf) 

Google Blog: [https://ai.googleblog.com/2021/05/align-scaling-up-visual-and-vision.html](https://ai.googleblog.com/2021/05/align-scaling-up-visual-and-vision.html)"
77,MachineLearning,"This research talks about using Random Walk inspired Anonymous Walks as graph units to derive feature-based and data-driven Graph Embeddings in an unsupervised fashion. ðŸ”¥ 

https://youtu.be/VVml3nDiM3E"
78,MachineLearning,"I'll start with a very simple example.

Let's say I want to compute something similar to exponential moving average of time-series data, but with only N previous input values being averaged. I can make a vector of exponentially decaying weights and compute dot product of this vector and N previous inputs, getting the result I want. 

But of course it's inefficient and for large enough N it doesn't give much of a difference from a standard exponential moving average, computed using feedback. So I can just use EMA as a good approximation of my desired result. In some sense, I approximated a large memoryless linear system using a small linear system with memory.

I was wondering about a more general version of this idea: What if my weights were different, but with magnitudes still decaying ~exponentially, and I was only interested in approximation being ""good"" on a small subset of possible inputs. An example of this could be an artificial reverberation, which also works by taking a large weighted average of shifted copies of an audio signal. 

To me, this seems similar to the way RNNs work (i.e. taking advantage of internal state and restricted input space to find a good approximation of a non-trivial transform of time-series data), but since they're typically nonlinear I'm not sure if it's a good idea to use them here. On the other hand, I couldn't find much information on RNNs with purely linear activation functions.

Has anybody here seen something similar to this? Are there issues or complications that I'm missing? 

Thanks"
79,MachineLearning,"In the case of data being not so big, the AUC can be relatively random. That is why in this kind of cases you want to do cross validation and average the out-of-fold AUCs to have something close to the real one.

However in order to have an idea of how accurate this AUC is, it would be best to have a p-value for it. I did research and learned interesting things. One way would be to use boostrapping and it should work not too bad, however best would be to use actual stats, like you can find here:

https://statisticaloddsandends.wordpress.com/2020/06/07/what-is-the-delong-test-for-comparing-aucs/
https://www.rdocumentation.org/packages/pROC/versions/1.17.0.1
http://pamixsun.github.io/papers/sun2014fast.pdf
https://github.com/yandexdataschool/roc_comparison

fact is that there is good stats to actually model the AUC, get an estimate of the variance and a confidence interval. 
However in the case of the average of AUCs like in the case of cross-validated AUC, I don't rly know about stats that much. (as is the case with most ML engineers I guess) what would happend with the p-value/confidence interval ? 

I think its a very interesting topic and thanks for your help !"
80,MachineLearning,"HuggingFace just released version v4.6.0 of their [huggingface/transformers](https://github.com/huggingface/transformers) framework, with support for three vision transformers: **ViT** by Google, **DeiT** by Facebook Research, and **CLIP** by OpenAI!

These three architectures can now be loaded from PyTorch and load either original checkpoints contributed by the model authors or any checkpoint uploaded by the community on the [Hugging Face Hub](https://huggingface.co/models?pipeline_tag=image-classification), with support for inference widgets like the [image classification widget for ViT](https://huggingface.co/google/vit-base-patch16-224).

ViT and DeiT get state-of-the-art results in image classification, and CLIP can be used for a flurry of tasks including image-text similarity and zero-shot image classification.

See the release notes for version v4.6.0; ViT and DeiT heavily benefited from Ross Wightman's [timm](https://github.com/rwightman/pytorch-image-models) framework which offers a number of great vision models.

It is released alongside a few notebooks to play with the models: [Inference with ViT](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/VisionTransformer/Quick_demo_of_HuggingFace_version_of_Vision_Transformer_inference.ipynb) and [Training ViT](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/VisionTransformer/Fine_tuning_the_Vision_Transformer_on_CIFAR_10_with_the_%F0%9F%A4%97_Trainer.ipynb)."
81,MachineLearning,"Hello everyone. I am interested in getting something like IRM ([https://arxiv.org/abs/1907.02893](https://arxiv.org/abs/1907.02893)), i.e. a model that I can explicitly optimize doing something better than Empirical Risk Minimization.

My problem is a numerical regression tabular data problem, and I would like something that learns from a few tables and generalizes correctly to other tables.

I liked the IRM paper, it introduces a relatively simple loss function and the code is provided. However, I did not fully understand whether it will work when using arbitrary NN. There are some follow up critics ([http://proceedings.mlr.press/v130/kamath21a.html](http://proceedings.mlr.press/v130/kamath21a.html), [https://openreview.net/forum?id=BbNIbVPJ-42](https://openreview.net/forum?id=BbNIbVPJ-42)) and enhancements ([https://arxiv.org/abs/2103.12947v1](https://arxiv.org/abs/2103.12947v1) ).

Is this worth a try or should I stick to serious validation hyperparmeter tuning?"
82,MachineLearning," 

Hello all, I'm new member here. I solely create Reddit account for gaining knowledge in manufacturing area.

Need your help guys as I am curious about machine vision (Cognex, Keyence, Basler etc).

Place where I work have several machine vision for IC packages defect detection (for molding, leadframe, marking). What I don't understand is sometimes the vision system cannot detect the defect even though when we try to do offline test or verification on the machine it could detect the defect on IC package.

(FYI, we use Basler as 9 main camera and 3rd party vendor for software plus machine).

What do you think guys the common cause of this inconsistencies?

Is it common problem in manufacturing industry as well?"
83,MachineLearning,"Hi there! We've just added a new dataset to Gourdian, this one courtesy of Google's Project Sunroof. This dataset essentially describes the rooftop solar potential for different regions, based on Google's analysis of Google Maps data to find rooftops where solar would work, and aggregate those into region-wide statistics.

It comes in a couple of aggregation flavors - by census tract ( https://gourdian.net/g/eric/sunroof_solar.solar_potential_by_censustract#summary ), where the region name is the census tract id, and by postal code ( https://gourdian.net/g/eric/sunroof_solar.solar_potential_by_postal_code#summary ), where the name is the postal code. Each also contains latitude/longitude bounding boxes and averages, so that you can download based on that, and you should be able to do custom larger aggregations using those, if you'd like.

This dataset seems like it'd be interesting to cross reference with things like weather, and perhaps electricity prices, to find the best places for people to invest in rooftop solar. If you have any other ideas of what it'd be good to combine with, let us know, and we can try to prioritize ingesting those!"
84,MachineLearning,"Here's my problem. I would like to investigate claims made in a paper. AFAIK, the following is true:
1. Paper has no official code repo.
2. Paper has no presentation/explanation/demo video.

The paper in question is ""Wasserstein Dependency Measure for Representation Learning"" https://arxiv.org/abs/1903.11780

I was grateful to find at least one open source implementation, but I'm not confident it's enough to reproduce the results in the paper, because the focus of the experiments are different.
https://github.com/SeongokRyu/mutual_information_and_self-supervised_learning/tree/master/predictive_coding

Has anyone reading this post tried to implement this paper?

Do I pretend like the paper never happened, because the results can't be replicated?

Generally speaking, what do you do when you find yourself in this situation?

What do?"
85,MachineLearning,"When it comes to convolutional networks I see a lot of techniques for creating deeper and deeper models.  These include relu activations, batch norm between layers, residual networks, highway networks, etc.   However, when it comes to stacking RNN layers on top of each other all I ever see is maybe a few stacked layers and a dense output.  I don't see any reason why for instance you can't build something like a resnet out of RNN layers...

x\_skip = x  
x = LSTM(512)(x)  
x = LSTM(512)(x)  
x = x + x\_skip  
x\_skip = x  
x = LSTM(512)(x)  
x = LSTM(512)(x)  
x = x + x\_skip  
...  


So what I am asking is how deep have you ever stacked RNNs?  Has anyone tried/seen something like what I have above?  Would there be much point in doing so?"
86,MachineLearning,"We want to mess around with autonomous maneuvering at sea. This regards waves, winds and currents - the navigation part is easier.

Are there any datasets/simulators to start with? 

Many thanks for any info"
87,MachineLearning,"Are you familiar with the diagrams where image thumbnails are grouped in 2D automatically based on a distance/affinity matrix? Do you know what they are called? Does a python library for plotting them already exist?

*Thank you!*"
88,MachineLearning,"Hello  everyone, I have been working in this field since 2 years. In this  whole time, I have been experimenting several stuffs with CNNs, and I  personally think that Fully Connected layers are of no use, and  sometimes adversely affects the CNN.

I  am looking for certain experiments that provide a base for this, or  maybe a base for something opposite to this. Can you guys recommend some  good reads and/or resources for this?

Or maybe we can start a discussion here. I would like to contribute my views/ideas.

Thank you.."
89,MachineLearning,"To anyone who reads this Thank you. I appreciate the help. I  have tried searching online but to no avail, so I'm hoping reddit and people with more knowledge than myself may help.

As per the title I have 2 questions.

First, currently I am trying to predict a multiclass output of that can be one of  4 different options. When trying to use multiclass.roc from the pROC library to obtain the AUC after building models(for this model/case assume cross validated rf) I am getting an error relating to predictor must be numeric or ordered. Currently my y variable is structured as factors. I did not have this issue prior with an output of 3 possible classifications (different model). Is this just a limit of what the capabilities are for this function? In other words is this not possible?


Second, I have come across Matthews Correlation Coefficient as another means of model evaluation outside of such things as: accuracy, rmse, f1score, logos, etc. Is this only applicable to categorical data/models that can take factors/categorical data (i am using the yardstick package here) and not to numerical models such as knn or svm (I did OHE categorical variables as well as scale them depending on the model)?

If you read this far thank you"
90,MachineLearning,"After my [last post](https://www.reddit.com/r/MachineLearning/comments/mrcv7y/p_nimbo_run_jobs_on_aws_with_a_single_command/) on [Nimbo](https://nimbo.sh) a few people asked if we had an alternative to Google Colab but for AWS. Well, we now do :D.

If you [setup Nimbo](https://docs.nimbo.sh/getting-started), you can just run `nimbo notebook` and it will sync your code, data, and environment and launch a notebook on a remote instance which you can access in your localhost.

Now you can make use of your AWS credits to get a Colab-like experience (or dare I say, better than Colab, because we do all the setup for you).

I hope at least some of you find this useful, and as always I'm happy to receive feedback :)."
91,MachineLearning,"I'm interested in techniques to prime the end sequence of a transformer and am wondering if anyone knows of any papers or has suggestions on the best way to do this.

Here's what I mean by end priming: Let's say we're training a generative language model and want to generate a sequence which ends with ""straw.""

So, ""That's the last straw."" and ""That's the final straw."" might be valid completions that the network could give us.

I've tried two techniques so far and haven't had good results with either:

Technique 1: Alter the attention mask such that all time points can access the last N tokens (with N being the length of the primer). This approach results in training instability (the loss starts to oscillate widely after a certain point in training). So I modified it further such that I do ""crop"" the loss and do not include the last N tokens in its computation. This, too, is unstable and I've had to reduce the learning rate further but have still gotten poor results.

Technique 2: Place the primer at the start of the sequence (while leaving the attention mask alone -- i.e. each time point can only see itself and the past time points). For example, I'd want the model to output something like ""straw. This is the last"" Technique 2 also results in learning instabilities. When I reduce the learning rate low enough to avoid them, I'm left with convergence to a poorly performing model.

I'm able to train vanilla transformers just fine, so I believe it's unlikely there are problems elsewhere in my pipeline."
92,deeplearning,"Although BERT became really popular after its release, it did have some limitations. And there were certain limitations associated with autoregressive methods like ELMo and GPT as well. XLNet was introduced to get the best of both worlds while at the same time not include their weaknesses.

In continuation of my Paper Notes series, I have written an informative summary of the paper. Personally, reading the XLNet paper was a very fun experience. I was amazed at every step, how they were including stuff to make the whole model work so well. The paper contained many interesting concepts that I had to give time to understand. So don't worry if you don't get it on the first go. Check out the links below and happy reading!

Paper Summary - [XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://shreyansh26.github.io/post/2021-05-16_generalized_autoregressive_pretraining_xlnet/)

Annotated Paper - [https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/XLNet.pdf](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/XLNet.pdf)"
93,deeplearning," recently I was reading [this](https://towardsdatascience.com/bert-to-the-rescue-17671379687f#:%7E:text=BERT%20allows%20us%20to%20perform,the%20output%20of%20the%20model.) tutorial about BERT which was intended to classify IMDB's comments. In computer vision when we add our custom layers we freeze the base of the model, but this guy didn't freeze pre-trained BERT's model, and added his custom layers, is it normal? why people do that? I thought adding a layer which is randomly initialized and training whole model would mess up already trained weights but it seems that it didn't."
94,deeplearning,"Hello! I am working with a data set of around 100K images ,All images are of different  rectangular  shapes and I tried 

    transforms.Resize()

,But  it distorts most of the images and therefore I settled for a training  loader with a batch size of 1 and using gradient accumulation , with  images as their original size ,but even with `num_workers : 0 and  pin_memory : True` the speed up gain  after first epoch is almost  negligible, I assume this is because of high resolution of images  because with the same setting for smaller images it worked faster .I  want to know about any other approaches I can use to speed up the  training(using PyTorch) as it takes more than 45  mins to just complete   one epoch."
95,deeplearning,"Hi, I am training a supervised VAE. And I was early stopping on best val accuracy. I was pleased to see that at some epochs, the model gave a 10 fold CV val accuracy of 87% but train accuracy was very low (54%). My dataset is small, only 135 items, with 121 in train and 14 in val. This could be one of the reasons for the gap. 

I later saved the weights and tested on one of the validation sets separately. And now the accuracy changes for every run. I then had to set a seed to stabilize the accuracy, which is now 61%. Shouldn't it be the same as seen while training? I don't see why I had to set a seed while testing."
96,deeplearning,"I have been working on coding a CNN in python from scratch using numpy as a semester project and I think I have successfully implemented it up to backpropagation in the MaxPool Layers. However, my model seems to never converge whenever there is a Convolutional Layer(s) added. I am assuming there is a problem with the way I have implemented the backpropagation.

Most examples that I have seen for this implementation either really simplify it by using a one-channel input and a single one-channel filter, or just dive straight into the Mathematics which doesn't only not help but also confuses me more.

Here is the way I have tried to implement both Forward and Backward Propagation for multichannel inputs and outputs based on my own understanding and things I read online.

**Forward Prop:**

[Forward Propagation](https://preview.redd.it/141uuioc0hz61.jpg?width=1280&format=pjpg&auto=webp&s=1c791004c18b8569528e81af19d9718a6dbe88ca)

**Backward Prop for Filter Gradients:**

[Backward Prop for Filter Gradients](https://preview.redd.it/feg7r4zh0hz61.jpg?width=1280&format=pjpg&auto=webp&s=e33ae9cf25352016883f0c235e27bbe72ce57fc1)

**Backward Prop for Input Gradients:**

[ Backward Prop for Input Gradients](https://preview.redd.it/k9q3vdul0hz61.jpg?width=1280&format=pjpg&auto=webp&s=f1f5e9c7688280e5ac3084256aa2d1ba8f991e1e)

Kindly point out anything that's wrong here. I have been working on this part for the last 2 days but there has to be a problem because my model never seems to converge. Thanks!"
97,deeplearning,"Used **Global**, **Absolute Magnitude Weight**, **Unstructured** and **Iterative** pruning using ResNet-50 with *Transfer Learning* on CIFAR-10 dataset. Surprisingly, a **sparsity of 99.078%** has been achieved with an increase of performance! The code can be referred [here](https://github.com/arjun-majumdar/Neural_Network_Pruning/blob/main/ResNet50_Global_Absolute_Magnitude_Pruning.ipynb).

Original and unpruned model's val\_accuracy = 92.58%, original model size = 90 MB, zipped model size = 83.5 MB.

Pruned model's (sparsity = 99.078%) val\_accuracy = 92.94%, original model size = 90 MB, zipped model size = 7.1 MB.

**This results into a compression ratio of 11.76x.**

Thoughts?"
98,deeplearning,"What are the kind of topic that one should choose that are research based in field of data science , ml/dl
I want this for my portfolio for MS.
Whatever i am thinking of, i can find a full fledged project available already, pls let me know how can i choose something to have a impressive portfolio."
99,deeplearning,"# [Improving Inversion and Generation Diversity in StyleGAN using a Gaussianized Latent Space](https://t.me/casual_gan/38)

ðŸŽ¯ At a glance:

>In this paper about improving latent space inversion for a pretrained StyleGAN2 generator the authors propose to model the output of the mapping network as a Gaussian, which can be expressed as a mean and a covariance matrix. This prior is used to regularize images that are projected into latent space via optimization, which makes the inverted images lie in well conditioned regions of the generator's latent space, and allows for smoother interpolations and better editing.

[Samples from the model](https://preview.redd.it/s692zea8mbz61.png?width=1219&format=png&auto=webp&s=3e5d735783b7f128a78518c36225daa9594ec2c3)

\[[5 minute summary of main ideas](https://t.me/casual_gan/38)\] \[[arxiv](https://arxiv.org/pdf/2009.06529.pdf)\]

P.S. Thanks for reading!  
If you found this useful check out other popular ML papers explained on [my channel](https://t.me/casual_gan)!

**Links to other recent papers explained:**

* [VQ-VAE2](https://t.me/casual_gan/30)
* [StyleGAN2-ada](https://t.me/casual_gan/28)
* [MLP-Mixer](https://t.me/casual_gan/35)"
100,deeplearning,"A research team from Google shows that replacing transformersâ€™ self-attention sublayers with Fourier Transform achieves 92 percent of BERT accuracy on the GLUE benchmark with training times seven times faster on GPUs and twice as fast on TPUs.

Here is a quick read: [Google Replaces BERT Self-Attention with Fourier Transform: 92% Accuracy, 7 Times Faster on GPUs.](https://syncedreview.com/2021/05/14/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-19/)

The paper *FNet: Mixing Tokens with Fourier Transforms* is on [arXiv](https://arxiv.org/abs/2105.03824)."
101,deeplearning,Do we need something extra for being part of ML industry like Data Structure and Algorithms or it is just fine to have knowledge about Statistics and Machine Learning models and Frameworks. What are your thoughts on this ?
102,deeplearning,"This tutorial breaks down xUnit, a new activation unit that is particularly suitable for image restoration problems. xUnit implements a learnable nonlinear function with spatial connections, enabling the net to capture much more complex features while requiring a significantly smaller number of layers in order to reach the same performance. 

Topics covered include:

1. Motivation behind xUnit
2. xUnit explained
3. PyTorch Code
4. Paper results
5. Conclusion

Article link: [https://blog.paperspace.com/xunit-spatial-activation/](https://blog.paperspace.com/xunit-spatial-activation/)"
103,deeplearning,"Hi, looking for your thoughts and feedback. How would you have approached it?

If anyone is looking to play in latent domain, checkout this side project that I hosted on Streamlit. The aim was to transform an input image to something that looks somewhere between 2 digits. The repository below will give you a practical exposure to Auto Encoders, Latent Domain, PyTorch, Hosting on Streamlit.

GitHub Repository - [LINK](https://github.com/vdivakar/mnistMuddle)

Streamlit App Demo - [PAGE](https://share.streamlit.io/vdivakar/mnistmuddle/br_streamlit/app.py)

https://i.redd.it/9r7t48bgi1z61.gif"
104,deeplearning,"+ There are many ways of improving machine learning model performance.

+ One such is feature selection.

+Â Amongst many feature selection techniques, genetic algorithm is one.

+ I have created a python library that helps you perform feature selection for your machine learning models.

+ It helps you identifyÂ the best set of features for yourÂ model. Feel free to use it.

pip install EvolutionaryFS


Example notebook:Â https://www.kaggle.com/azimulh/feature-selection-using-evolutionaryfs-library

Pypi page with documentation: https://pypi.org/project/EvolutionaryFS/"
105,deeplearning,"So the conv layers in Neural Networks combined with pooling operations cause the hierarchical representations to be translation invariant, i.e. it should not matter for e.g. a digit if it appears in the upper left or lower right corner of an image. 

&#x200B;

However, if the location of the objects/information within a signal/image carries information as well, the translation invariance seems disadvantageous. What are the possibilities to build translational variance into the network if any?"
106,deeplearning,"A research team from DeepMind explores how neural networks can be fused with algorithmic computation and demonstrates an elegant neural end-to-end pipeline that goes straight from raw inputs to general outputs while emulating an algorithm internally.

Here is a quick read: [DeepMind Presents Neural Algorithmic Reasoning: The Art of Fusing Neural Networks With Algorithmic Computation.](https://syncedreview.com/2021/05/13/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-18/)

 The paper *Neural Algorithmic Reasoning* is on [arXiv](https://arxiv.org/pdf/2105.02761.pdf)."
107,deeplearning,"Hi i got some special gpus for sale that would be a cost effective for a multi gpu deep learning build.

Asus Turbo RTX3090 model made for servers or multiple gpu setups.

prefer to ship within the EU

2950 EUR each, brand new in bulk packaging

timestamps: [https://imgur.com/a/IMyf05U](https://imgur.com/a/IMyf05U)"
108,deeplearning,"&#x200B;

[PyGAD & Keras](https://preview.redd.it/l20gbrs2r0z61.png?width=1789&format=png&auto=webp&s=c5b111397c007b3c2447a1830a8f3201c8b44c98)

[https://towardsdatascience.com/how-to-train-keras-models-using-the-genetic-algorithm-with-pygad-9d9d626782d1](https://towardsdatascience.com/how-to-train-keras-models-using-the-genetic-algorithm-with-pygad-9d9d626782d1)"
109,deeplearning,"A quick announcement before we jump to our post today.  


We will launch aÂ Kickstarter campaign for OpenCV for BeginnersÂ onÂ May 18, 2021. It is a short, fun, and extremely affordable course.  
Please create a Kickstarter account and click on the ""Notify me on Launch"" button on theÂ pre-launch pageÂ so you don't miss the special price on Day 1.Â 1130 peopleÂ are already following our project on Kickstarter - don't wait until the last moment!  


[https://www.kickstarter.com/projects/opencv/opencv-for-beginners](https://www.kickstarter.com/projects/opencv/opencv-for-beginners)  


Today's post is about Generative and Discriminative Models  
In machine learning and deep learning, we often create these two different kinds of models for solving problems.  


Discriminative Models: These kinds of models focus on differences between classes to solve a problem. For example, a classifier built to classify dogs and cats is a discriminative model that learns the differences between a dog and a cat.  


Generative Models: A generative model tries to learn the appearance of the classes. For example, a generative model may be used to create a realistic picture of a dog.  


You will also get a foundational understanding of generative models.  


[https://learnopencv.com/generative-and-discriminative-models/](https://learnopencv.com/generative-and-discriminative-models/)

https://preview.redd.it/1c4s4lssp0z61.jpg?width=600&format=pjpg&auto=webp&s=9fe765ec7393de659b54095d9a99c087415c6827"
110,deeplearning,"I considered posting this to r/PhD, but ultimately decided that here was more relevant.

In short, I am a 2nd year PhD student looking to get a good industry job once I graduate. My lab is in the biomed engineering department and focuses on deep learning applied to medical imaging, but I am part of the electrical engineering dept. All of my experience in DL has come from my graduate courses in the past 2 years, which have all been math-heavy, and in that time, I've thought that I might be more interested in more general deep learning/computer vision research or deep learning for something like robotics, but I don't know if deviating from my lab would be wise.

My advisor's awesome and well established in his field, and I don't see myself switching labs (funding is also not an issue). He's pretty hands-off and gives me latitude to pursue my interests, but if I research something outside the lab's scope, then I'm not really leveraging any of the resources, network, or past knowledge that's here, which somewhat eliminates the purpose of being in a lab. Additionally, I'd be competing against researchers in their fields, who do have all of these resources. Also, while I think that I may be more interested general DL/CV or applied robotics, this could honestly be 'grass is greener' syndrome, where I automatically see fields that I know less about as comparatively more interesting and lucrative.

Overall, my options are to stick with my lab's direction, completely deviate and do my own thing, or somehow try and find something in between. My current goal is to get a lucrative and interesting job doing research in industry, but I don't have a good sense of how the PhD market for theoretical/applied DL fields really works/is. Is it common, or even possible for PhD students to study one application, but then ultimately land jobs in different applications that have some common principles?"
111,deeplearning,"I have come across a plethora of tools to be able to do this, with tensorboard being the most common by quite a distance. I generally do not have a problem with tensorboard per se but could not help but be curious about if the alternatives are really that much better? A lot of the alternatives like W&B or [Neptune.ai](https://Neptune.ai) , even charge for premium services to businesses. 

Given that there seem to be so many options now, what would people say is the best free option and which is the best paid one? and is there really such a big difference between them?"
112,deeplearning,"Hey i'm looking to build a deep learning pc. It seems im best off getting a RTX 3090. I'm not too clued up on parts for deep learning so could people recommend me what to have for the rest of the build? Should i get a full tower or a mid tower? What CPU and how much ram? 

Thanks"
113,deeplearning,"Hi everyone! I recently read this [wonderful piece](https://distill.pub/2017/momentum/) about the optimization of neural networks. And then I start to research on latest optimization algoritms such as Adagrad and Adam, but I realized that I can only scratch the surface. The original papers was really intense, and the blog posts that I saw was too simple.

So my question is where should I learn these topics in advance? What is the starting point? I think Classical convex optimization books is little bit different, am I right? Any book or blog post or course suggestion will be appreciated.

Ps: I have some background on basics (linear algebra, probability, neural networks in general)"
114,deeplearning,"Hello, I would like assistance for reviewing study guide with about 15 conceptual/technical questions/true-false/multiple-choice

&#x200B;

Introduction to Recurrent NNs

Recurrent Neural Networks

Attention Mechanisms

Applications of Deep Learning in Computer Vision

Graph Neural Networks (and Attention)

Pretrained Language Models

NLP application

Generative Adversarial Networks

&#x200B;

Relevant material: [http://d2l.ai/](http://d2l.ai/)

&#x200B;

Looking to pay somebody with relevant credentials for a 2 hour slot."
115,deeplearning,"This tutorial video covers how to get set up and running with Mask R-CNN for object detection with Keras in minutes.  

Full tutorial: [https://youtu.be/c1xCaw1tcQQ](https://youtu.be/c1xCaw1tcQQ)

Run the full code on a free GPU: [https://ml-showcase.paperspace.com/projects/object-detection-with-mask-r-cnn](https://ml-showcase.paperspace.com/projects/object-detection-with-mask-r-cnn)

Comments and discussion welcome!"
116,deeplearning,"# [Exploiting Spatial Dimensions of Latent in GAN for Real-time Image Editing](https://t.me/casual_gan/36)

One more paper about inverting images into latent spaces of generators. This time with the twist that it uses explicit spatial styles (style tensors instead of style vectors) in the generator, and the encoder, hence making it possible to perform local edits, and smoothly swap parts of images. Overall the authors show that their approach outperforms other baseline in the aforementioned tasks as well as image interpolation. Read [more details](https://t.me/casual_gan/36).

[Samples and model architecture](https://preview.redd.it/8tlmgnfynpy61.png?width=983&format=png&auto=webp&s=c49a27c0b2b41a9ce8125c0ee60606d109a8b92a)

\[[paper explained in 10 minutes](https://t.me/casual_gan/36)\] \[[Arxiv](https://arxiv.org/pdf/2104.14754.pdf)\]"
117,deeplearning,"Hey! Sorry if this is the wrong subreddit for this. This might sound weird but I really want to mimic the voice of a radio host for a voice over of a custom music mix. Of the programs Iâ€™ve seen, the only work with your own voice, and Iâ€™m not sure if there are any relatively easy ways for me to do this. If this technology exists yet, is there any way that I can learn to do it?"
118,deeplearning,I badly need  research partners. If anyone interested lemme knw!
119,deeplearning,"Hi all, I'm trying to train a forecasting model using deep learning with 1D-CNN. Currently, I train a single model per company. What I want to do is train a single model by combining the time-series values from all companies together.

&#x200B;

But this poses a problem because the values are vastly different from each other (some stocks trade a 10 units/share while others in 10,000 units/share). I will normalize the data ofc but wouldn't there be this jump in values every n-rows when the company changes? Should I use the company as a feature then? or should I treat close prices from all the companies as just one single company's close prices?   


Does anybody know a good way to do this?"
120,deeplearning,"A research team from DeepMind and Onshape combines a general-purpose language modelling technique and an off-the-shelf data serialization protocol to propose a machine learning model that can automatically generate high-quality sketches for Computer-Aided Design.

Here is a quick read: DeepMind & Onshape Leverage Transformers to Advance Automatic Computer-Aided Design.

The paper *Computer-Aided Design as Language* is on [arXiv](https://arxiv.org/pdf/2105.02769.pdf)."
121,deeplearning,"Hey everyone, I wanted to share a project of mine with you all. Hopefully you guys will like. 
Please have a look, if you could provide some feedback it would mean a lot to me. 

I am currently pursuing my masters and my work involves implementing lot of research paper but most of pipelines I implement are some variants of each other, hence I wanted to reuse them so I coalesced everything into a simple high level framework. 


TorchFlareÂ is a simple, beginner-friendly and an easy-to-use PyTorch Framework train your models without much effort. It provides an almost Keras-like experience for training your models with all the callbacks, metrics, etc

Features

A high-level module for Keras-like training.

Off-the-shelf Pytorch style Datasets/Dataloaders for standard tasks such asÂ Image classification, Image segmentation, Text Classification, etc

CallbacksÂ for model checkpoints, early stopping, and much more!

MetricsÂ and  much more.

Checkout the github. 

[Github ](https://github.com/Atharva-Phatak/torchflare)"
122,deeplearning,"So i am implementing a Variational Autoencoders for big size images (1280x720). 
After convolutional layers and flatten layer I have a output dim of 61440. So I use some FC layers to reduce dimensions to 215 for latent vector. Is this still too big (or too small)?

Thanks"
123,deeplearning,"Hey everyone, thanks for taking the time to read this post.  As I mentioned, I love teaching what I know because it helps me solidify concepts when I have to help explain it to someone.  I am looking for someone who likes to learn this way and can help me answer questions along my machine learning journey.

I have been learning machine learning for about 1 year, I took a few courses and built various models for things like simple machine learning classification/regression, deep learning, seq2seq and more.  I understand the core concepts and have strong intuition but I am looking for someone who can help me increase my understanding at a deeper level.  Things like hyper parameters, when to use certain loss functions or the nuances of pre-processing.  Maybe we can build something together!

I find that this is a great way to learn fast, and make a friend along the way!  Feel free to shoot me a pm and thanks for taking the time to read this!"
124,deeplearning,"Hi! I need help. China, pls download this rar archive.  
I cant creat account in csdn.net.  
Download link [https://download.csdn.net/download/qq21497936/13126842](https://download.csdn.net/download/qq21497936/13126842)  
If you can, plz send me mail [eryoma2121@gmail.com](mailto:eryoma2121@gmail.com)"
125,deeplearning,"While using convolutional nets to perform image classification, I encountered several difficulties importing image data using the native Tensorflow functions. So, I created my own custom image data pipeline, which gives the user finer control and more flexibility when importing image data. I hope it is useful to you guys as well. Let me know what you think.

https://github.com/nenyehub/tf-image-pipeline"
126,deeplearning,"I was working on fish detection and tracking system in 3 dimensions using MS Kinect, and used yolov5s for rgb frames. I wanted to experiment a bit with the architecture

of yolov5, but as a beginner i am struggling to find the relation between the arguments in the classes used in [common.py](https://common.py)  file and the arguments used in YAML  file in the Ultralytics repo. Can anybody help ?

PS : If you can add in some resources from where i can learn about the architecture and layers, then it would really help. Thank you !"
127,deeplearning,"Hello community, I was wondering how self-attention handle multivariate time series data. Knowing that the block usually accept vectors as input, but in my case I have a Matrix of data ( 5,7) where 5 is the sequence length and 7 is the dimension embedding.

will the self attention be applied for every feature sequentially ( 5,d1) then same for the second dimension (5,d2) etc... ? Or can it be applied on a context matrix as well ?"
128,deeplearning,"For instance, if I want to run CPU inference on a server I might consider the following things:

\- How much memory is required for my model parameters? (and how much memory is available on the server)

\- How long it takes to do inference on my machine? (and what type of CPU the server has)

With the above two I can usually do a back of the envelope calculation and get a ballpark understanding of what's required.

What about for mobile devices?

And is there such thing as some sort of emulation bench-marking tool?"
129,deeplearning,"A research team from ETH Zurich combines continual learning and self-supervision to propose a novel robot system that enables online life-long self-supervised learning of semantic scene understanding. 

Here is a quick read: [ETH Zurich Proposes a Robotic System Capable of Self-Improving Its Semantic Perception.](https://syncedreview.com/2021/05/11/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-16/)

The paper *Self-Improving Semantic Perception on a Construction Robot* is on [arXiv](https://arxiv.org/pdf/2105.01595.pdf)."
130,deeplearning,"I have 3D textured meshes for a dozen of objects, which have to be detected in synthetic images. I have 2D textures of backgrounds these objects will be visible in front of. Object detection will be performed on 2D images taken inside a 3D simulation (all data is synthetic).

In order to get the training data for DNN, I would overlay renderings of 3D meshes with varying viewpoint, scale and lighting over all available background textures at different locations. I'm sure, this obvious method was used by others countless times in the past and presumably there are some tools to automate it. Can someone point me in the right direction and post a link to an easy-to-use tool, which can do what I described above?"
131,deeplearning,"Hi all, 

I posted a bit around updating an old machine my lab has so it can be more suited for DL, turns out our budget was a lot more than I anticipated so we can actually afford a new machine - I don't however want to end up wasting money on overshooting on components I don't need. Any input on the specs below would be greatly appreciated. At the moment I'm looking at two options, either the Alienware Aurora r12 top-spec, or a custom build from PC specialist. I'll outline the two specs below. 

It should be noted I can't change many of the Alienware specs, but the PC specialist is fully customizable. They are roughly around the same price give or take Â£100-Â£200.

&#x200B;

**Alienware r12**

11th Gen i9-11900KF (8 core, 16MB cache, 3.5GHz to 5.3GHz w/Thermal Velocity Boost)

NVIDIA RTX 3090

64GB Dual Channel DDR4 XMP @ 3400MHz 

2TB M.2 NVMe SSD 

2TB 7200RPM SATA 6GB/s

High Performance CPU Liquid Cooling (they don't state specifically what, so I assume it's a custom in house job)

1000W Power Supply

&#x200B;

**PC Specialist** 

i9-10940X (14 core, 19.25 MB cache, 3.3GHz)

NVIDIA RTX3090

64GB Corsair Vengence DDR4 2400MHz (4 x 16GB sticks)

500GB Samsung EVO 970 PLUS M.2 NVMe (up to 3500MB/R, 3200MB/W)

4TB Corsair MP400 M.2 NVMe (up to 3480 MB/R, 3000 MB/W

8TB Seagate Barracuda SATA-III, 5400RPM

Corsair 850W power supply (Ultra Quiet apparently)

PC Specialist FrostFlow 150 Series high-performance CPU cooler (180W) - this is air flow cooling"
132,deeplearning,"My professor asked me to produce images using the Cyclegan architecture as this semester project. I intend to work on a computer vision project with Cyclegan architecture and looking for Dataset from the facade of buildings and paintings from the building.  The second DataSet can also be the images of the buildings in Japanese anime or manga or something similar. If you know such datasets, please let me know.

It is very urgent"
133,deeplearning,"I don't understand why Levine says at minute 3.00 in this video ([https://www.youtube.com/watch?v=xAcAWaeUxYs&list=PL\_iWQOsE6TfVmKkQHucjPAoRtIJYt8a5A&index=18](https://www.youtube.com/watch?v=xAcAWaeUxYs&list=PL_iWQOsE6TfVmKkQHucjPAoRtIJYt8a5A&index=18)) that filters always have one more dimension (4D) than the activations (3D).

Could you explain?   


Thanks!"
134,deeplearning,"One of the most common pruning techniques is ""unstructured, iterative, global magnitude pruning"" which prunes smallest magnitude p% of weights in each iterative pruning round. 'p' is typically between (10-20)%. However, after the desired sparsity is reached, say 96% (meaning that 96% of the weights in the neural network is 0), how can I remove these 0s to essentially remove say filters/neurons?

Because this pruning technique produces a lot of 0s which still participate in forward propagation using *out = W.out\_prev + b.* Therefore, this pruning technique will help in compression but not in the reduction of inference time.

Thanks!"
135,deeplearning,"Used Transfer Learning with ResNet-50 on CIFAR-10 in PyTorch to achieve val\_accuracy = 92.58%. You can see the code [here](https://github.com/arjun-majumdar/CNN_Classifications/blob/master/ResNet50_Transfer_Learning_CIFAR10_Finetuning_entire_model.ipynb).

**Key takeaway:** Change the first conv layer to have the hyper-parameters kernel\_size = (3, 3), stride = (1, 1) and padding = (1, 1) instead of the original ones since CIFAR-10 dataset has much smaller images and using the original conv layer hyper-parameters reduces the image size due to which the resulting model performs not so good, according to my experiments.

Thoughts?"
136,deeplearning,"I have two text columns. 

The objective is to vectorize each column separately. And then pass them into a MLP, so that the model can also understand which column a word is coming from.

But I am confused as to how to actually implement this.

Any help or resources would be appreciated. Let me know if there is a different approach to solve this problem as well.

Thank you!"
137,deeplearning,"&#x200B;

https://reddit.com/link/n8y5m8/video/j9dmhm03oay61/player

https://preview.redd.it/6r23c8t3oay61.jpg?width=2501&format=pjpg&auto=webp&s=25300c65c071332c9d7a84bd976953855cfdc691

&#x200B;"
138,deeplearning,"As the title said. Been looking to no avail for now. 

Thanks in advance for any help!"
139,deeplearning,"Imperial College London researchers show how to optimally train a variational quantum algorithm to represent quantum states and propose a stable variant of the quantum natural gradient, a generalized quantum natural gradient that can be trained free of barren plateaus.

Here is a quick read: [Imperial College London Proposes Optimal Training of Variational Quantum Algorithms Without Barren Plateaus.](https://syncedreview.com/2021/05/10/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-15/)

 The paper *Optimal Training of Variational Quantum Algorithms Without Barren Plateaus* is on [arXiv](https://arxiv.org/pdf/2104.14543.pdf)."
140,deeplearning," Trained a deep learning model that will convert your grayscale photos into colorful mode

 

https://preview.redd.it/bpme36geray61.png?width=817&format=png&auto=webp&s=7329ff427662b921f7a5b9da0658adfb8f6d1bbe

 

\-AutoEncoder Based Deep learning model that colorizes the old black and white images

Â· Used resnet18 for encoder part and up-sampled that latent representation in decoder part

Â· Deployed the simple webapp using streamlit on Heroku

Though this is just a based model. I know some ways of improving like using good encoder , training for higher epochs .I would like to hear from you guys

Suggestions are always welome :)

git -[https://github.com/Pranav082001/Neural-Image-Colorizer](https://github.com/Pranav082001/Neural-Image-Colorizer)"
141,deeplearning,"In this tutorial, we'll cover how to train YOLO v5 on a road sign object detection task, which can easily be swapped for your own custom dataset. This tutorial will be broken down into the following parts:

1. Setting up YOLO v5 and dependencies
2. Downloading the data and converting it to YOLO v5 format (we'll write a custom function for this so you can easily apply it to your own data)
3. Training options
4. Inference on images and videos

Tutorial link: [https://blog.paperspace.com/train-yolov5-custom-data/](https://blog.paperspace.com/train-yolov5-custom-data/)

Run the full code on a free GPU: [https://ml-showcase.paperspace.com/projects/yolov5](https://ml-showcase.paperspace.com/projects/yolov5)

Comments and questions welcome!"
142,deeplearning,"

I have been out of the loop for around one year, doing diverse projects not related to DL.

I have a couple of Keras models using custom layers, based on TensorFlow 1.13, I was wondering what is the best way to upgrade them to TF 2.x

I have read of an official TF function that analyzes your code, is that also applied to Keras? What has been your experience?

Thanks in advance"
143,deeplearning,"Everyone who is interested in NLP or even DL and ML for that matter, has definitely heard about the BERT family of models. BERT, RoBERTa, DistilBERT and many many more. This paper ""BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"" first introduced this and it has now completely changed the way AI practitioners are solving and looking at NLP problems these days.

As a part of my Paper Notes series, I have gone through the paper and created an informative summary of the paper. This time it goes a bit longer than the previous paper summaries, but it had to be done. The paper contained many tiny interesting nuggets that I had to include. Check out the links below and happy reading!

Paper Summary -  [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://shreyansh26.github.io/post/2021-05-09_pretraining_deep_bidirectional_transformers_bert/)

Annotated Paper -  [https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/BERT.pdf](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/BERT.pdf)"
144,deeplearning,"I'm looking for a reading buddy to read and discuss papers related to the topic.

My background is in computer vision, been working with biomedical images for over 3 years both in research and industry collaboration settings, and have a pretty good understanding of how the process is being done currently.

Will be reading extensively over the next few days. Comment or pm if interested.  I can share what I have found so far."
145,deeplearning,"I've been working on a WGAN-GP with a custom dataset, but I've been getting the erratic loss seen in the figure below. The figure plots the losses for batched over 8 epochs.

The base is a DCGAN with 32x32x3 images with no normalization layers, and I've implemented the WGAN-GP using code straight out of the Keras docs ([https://keras.io/examples/generative/wgan\_gp/](https://keras.io/examples/generative/wgan_gp/)), the output images are just noise with (mostly) similar colors to the examples.  


So what could be the issue? And how can I solve this?

Thank you

https://preview.redd.it/xm7siosl14y61.png?width=397&format=png&auto=webp&s=85e2935901c48e528586707a5dfd1f61deb86ceb"
146,deeplearning,"Hello guys,

I'm struggling with my DL model (regression task, LSTM combined with some dense layers), since despite some hyperparameters tuning i always end with a sudden rise of the loss function and then a 'infinite"" plateau for hundreds of epochs.

My hypothesis were: 
-learning rate and local minima issue? i tried several (1e-3,1e-4) 
-Optimizer issue? i tried SGD for example
 -Too complex model? i removed some layers or neurons 
-Metric issue? i tried MAE

Among theses hypothesis and perhaps others, which one seems the most likely ? I looked for differents curve patterns but didn't find this one.

Thanks a lot!"
147,deeplearning,"Every data scientist will have to use SOM at least once in their life. So here you are a Very Simplified Introduction to Self Organizing Map.

[https://ravinduramesh.blogspot.com/2021/04/intro-to-self-organizing-map-and-self.html](https://ravinduramesh.blogspot.com/2021/04/intro-to-self-organizing-map-and-self.html)"
148,deeplearning,"I am building a ConvNet using Keras for classifying A and B phases in EEG signals. I have a dataset of 21984 samples (10992 of each A and B phase). I have plotted the recurrence plot for each of these samples, giving me a 2D image which is the input for my ConvNet. I am using ResNet50V2 architecture followed by fully connected using Sigmoid classifier.

The issue is, I am not able to achieve accuracy beyond 63-65%. My hyperparameters are, Batch size = 128, Nadam optimizer with a learning rate of 1e-6 and 1000 epochs that has an EarlyStopping callback with the patience of 50 epochs, monitoring the minimization of Validation Loss. I am splitting the dataset as 60% training, 20% validation, and 20% testing sets.

I need suggestions on how to improve the score. Do suggest alternative approaches for time-series classification using ConvNets"
149,deeplearning,[deleted]
150,deeplearning,"I'm in the process of building a univariate LSTM model for stock prediction but I'm stuck on how to properly scale/norm my training and test data.  Since the data is non-stationary (generally increasing trend) I cannot simply fit\_transform() a scaler on training and fit() on test because the distributions among training and test are different.  I would have high test values which wouldnt scale properly. I'm using a sliding window approach (30 day windows) predicting 1 day in the future.

Been reading into ""Adaptive Normalization"" but I'm open to ideas.

Thanks!"
151,deeplearning,"A research team from MIT and MIT-IBM Watson AI Lab proposes Curious Representation Learning (CRL), a framework that learns to understand the surrounding environment by training a reinforcement learning (RL) agent to maximize the error of a representation learner to gain an incentive to explore the environment.

Here is a quick read: [MIT & IBM 'Curiosity' Framework Explores Embodied Environments to Learn Task-Agnostic Visual Representations.](https://syncedreview.com/2021/05/07/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-14/)

 The paper *Curious Representation Learning for Embodied Intelligence* is on [arXiv](https://arxiv.org/pdf/2105.01060.pdf)."
152,deeplearning,"Hello everyone,

Quick question: I am working on a low resource language that even large multilingual models such as [mBERT](https://huggingface.co/bert-base-multilingual-cased) fail to represent properly. So, can I fine-tune these models on MLM just like they were originally trained and then fine-tune it again on a specific task? In other words:

1. Fine-tune mBERT on the masked language modeling task (using a domain-specific corpus)
2. Fine-tune the resulting model on a different task (say semantic analysis)
3. Test the model

Does this make sense? Is this equivalent to training a BERT model from scratch using the same multilingual corpus in mBERT, with my corpus added to it, or is it different? If so, how's it different?

Thank you for your time. I really appreciate any knowledge on the matter."
153,deeplearning,"This tutorial covers how to implement 5 different question-answering models with Hugging Face, along with the theory behind each model and the different datasets used to pre-train them. We'll also look at the varying baselines for each of the models in terms of F1 and EM scores.  

Topics covered include:

* The Transformer Architecture
* Popular Datasets and Evaluation Metrics
* BERT (Bidirectional Encoder Representations from Transformers)
* ALBERT: A Lite BERT
* ELECTRA
* BART
* Issues with Long Document Question-Answering Using Standard Models
* LONGFORMER: the Long-Document Transformer

Tutorial link: [https://blog.paperspace.com/question-answering-models-a-comparison/](https://blog.paperspace.com/question-answering-models-a-comparison/)

Run the full code on a free GPU: [https://ml-showcase.paperspace.com/projects/question-answering-models](https://ml-showcase.paperspace.com/projects/question-answering-models)

Questions and comments encouraged!"
154,deeplearning,"doing an art project on memories and want to want to use perhaps some ai software like stylegan(welcome to any suggestions) to merge faces together to create a weird outcomes, if u peeps could point me in the right direction for any tutorial, link, websites or methods.bearing in mind i am using a mac operating system which seem like it might be a bit of a hinderance. but anyway all the best, if anybody could help out it would be very much appreciated"
155,deeplearning,"Hi all, 

I'm a PhD student and I've got some funding to put together a machine for ML/DL. My lab currently has a pretty powerful machine....or at least it was pretty powerful about 10 years ago. I'm wondering whether I can just upgrade a couple of components on it to make it fit for purpose or whether I'm better off just trying to spec out a whole new machine. 

These are the current specs:

* Dual Xeon e5-2670
* 256GB RAM (I'm going to assume DDR3) - I'm not actually in the lab to check.
* Quatro FX 5800

I'm wondering can I just get away with updating the GPU to something like a 3080? If I get a new machine there's no way (I don't think) I'll have the budget to match the RAM amount and get a decent GPU inside it.   


Or would I be better off spending the extra cash to get less but newer faster RAM, more up-to-date CPU, and a better GPU? If money was no object I'd obviously just a new machine, but I'm trying to be cost-efficient."
156,deeplearning,"I have coded ""Global, unstructured & iterative"" pruning using ResNet-18 trained from scratch on CIFAR-10 dataset in PyTorch. You can refer to the code [here](https://github.com/arjun-majumdar/Neural_Network_Pruning/blob/main/ResNet18_Global_Pruning.ipynb). Let me know your comments/thoughts.

Cheers!"
157,deeplearning,"Hi everyone, I have been working on an LSTM regression model and it seems that it is not working.  [Here is the results showing training and validation loss over 50 epochs](https://imgur.com/a/RLqcuCt).  If anyone has any thoughts on how to fix this, I am all ears.  I can clarify anything to help troubleshoot as well.  The model predicts the same value for every predicition.  Is this overfitting? An input scaling issue? or something else?  [Here is the preprocessing and model](https://pastebin.com/dsYgjPW2)"
158,deeplearning,"Hi all,

I have recently started blogging and as initial attempt, I tried to write on domain adaptation. Kindly have a read of you are interested in the topic.
Follow us on medium to know about more such topics
 https://medium.com/@AandE/understanding-domain-adaptation-5baa723ac71f"
159,deeplearning,"Hey everyone,

A friend and I developed [Nimbo](https://nimbo.sh), a dead-simple CLI that wraps the AWS CLI, allowing you to run code on AWS as if you were running it locally. You can find the source code here ([https://github.com/nimbo-sh/nimbo](https://github.com/nimbo-sh/nimbo)) and the docs here ([https://docs.nimbo.sh](https://docs.nimbo.sh/)).

We decided to build this because we were frustrated with how cumbersome using AWS was, and we just wanted to be able to run jobs on AWS as easily as we run them locally. At the same time, we wanted to make use of the cheap spot instances (on Nimbo, this is a single parameter). All in all, we didn't like the current user experience of working with AWS, and we believed it was possible to vastly improve it.

For this reason, we also provide many useful commands to make it faster and easier to work with AWS, such as launching notebooks on EC2, easily checking prices, logging onto an instance, or syncing data to/from S3 (you can see some useful commands at [https://docs.nimbo.sh/useful-commands](https://docs.nimbo.sh/useful-commands)).

Unlike other similar services, we are solely client-side, meaning that the code runs on your EC2 instances and data is stored in your S3 buckets (we don't have a server; all the infrastructure orchestration happens in the Nimbo package). We are also open contribution, meaning that all the source code is publicly available on our GitHub, and we welcome community contribution.

We have tons of ideas for Nimbo, like adding docker support, and providing instances with preloaded datasets like ImageNet, so that you don't have to download and store it yourself - you simply spin the instance, and the dataset is available at /datasets. We are currently working on adding GCP support, so that you can use AWS or GCP with the same config file.

We are happy to receive any feedback and suggestions you have."
160,deeplearning,"Hey folks! Please help support us by reviewing our post our Product Hunt!    ðŸ¥³ **ðŸ˜ƒ** ðŸ¥³Â  

[https://www.producthunt.com/posts/open-source-ai-ml-data-annotation](https://www.producthunt.com/posts/open-source-ai-ml-data-annotation)"
161,imageprocessing,"We have worked on a reinforcement learning project to improve reward on an Atari dataset. Can we submit it to ICIP conference. I don't see any relevant topic to this project in the topic list. Please suggest if there is any topic section in which we can submit (or we shouldn't submit?)

Topic list: https://cmsworkshops.com/ICIP2020/Papers/PaperTopics.asp"
162,imageprocessing,"  

Hi, iâ€™m working on a university project in wich we try to analyze the news published in online media. For this end weâ€™ve use [Capture a Website screenshot](https://www.site-shot.com/) to take a screenshot of every news published by several websites, but as you can see the â€œscreenshotâ€ takes the whole website, not only the news, so  when we transform that .jpg file to a .pdf and then to a .docx file, we get a lot of information we donâ€™t actually need.

There are several â€œpatternsâ€ (the headline and the â€œcommentâ€ section or the author name for example) that tipycally signall the start and endpoint of the news, so i though if there is a software that automatically recognize this â€œpatternsâ€ and then batch cut all the images (there must be something like 5.000 by now) that would save us a lot of work.

I've add a cropped and uncropped .jpg as example of what we expect to achieve. Thank you very much!

&#x200B;

https://preview.redd.it/had4usclzgc41.png?width=1024&format=png&auto=webp&s=e97803cd5b12a7b19a49226857c7233980a93d3f

https://preview.redd.it/tgu0qsclzgc41.png?width=1036&format=png&auto=webp&s=acb79a0a0d85bd3a120c06f50904038dae6b7a4e"
163,imageprocessing,"I'm planning to do my thesis on Jaywalking detection using yolov3 and dectron 2. Can someone help me out to get a video footage for people illegally crossing the street. 

Thanks"
164,imageprocessing,"I have an assignment about mean shift clustering in first step I download a dataset and second step is -> Choose an input pair (an RGB image and a corresponding depth map). (You might consider choosing one of the inputs at the indices 202, 296, 298, and, 325.) from that dataset I guess but I have no idea how to choose them can anyone help I stuck hard :D"
165,imageprocessing,"I'm researching computer methods for the problem of gender determination out of fingerprints. I'd be glad to have your opinions on this.  
1- Partial prints    
2- Full prints  
3- What algorithms are used? AI methods (deep learning, etc)  
Thanks"
166,imageprocessing,"Iâ€™m looking for suggestions as to how I could quantify the differences in these images.   In some you can see the striped pattern much more clearly but in others you canâ€™t.  Iâ€™m trying to figure out a way to calculate the differences.   Any suggestions would be appreciated.  


https://imgur.com/gallery/HshM9Lt"
167,imageprocessing," \[Posted on r/deeplearning\] Reposting for a wider response.

>I need to search for action similarity between an image and frames from the video. I need this to find the starting time of the frame where the action represented by the image is being carried out.  
>  
>Visual similarity via pixel by pixel difference will not work at all since there may not be the same placement of the person/action in both (the image and the frame). Even if that is the case, the color of attire/background, etc. might differ.  
>  
>I need to this for any general sports-related action involving humans. I could not find any classification models which seem to be so detailed so as to classify between such nuanced and minutely differing actions as is the case with sports.  
>  
>Is there any way I can achieve this? How helpful it might be if I use another representation of action (say keypoint set as given by [openpose](https://github.com/CMU-Perceptual-Computing-Lab/openpose))? One flaw that instantly comes to mind with this approach is that it would not provide for comparison of objects involved in the action but only the people.  
>  
>Any help is appreciated. Thanks a lot."
168,imageprocessing,"Hi,

I am working on an image segmentation project and would like to know how to identify (draw boxes/contours), extract intersecting lines,  separately, from an image that I've already pre-processed, using thresholding and the water and the watershed algorithm.

Here is sample images I would be working with:

&#x200B;

[image 1](https://preview.redd.it/tio1x5bmsy341.png?width=1220&format=png&auto=webp&s=66e1b5031033d2427f40596214c832613e9c7a45)

All the help will be much appreciated."
169,imageprocessing,"Hello,

I have a university project where I must do the detection of cigarette buts on the floor using a webcam vision for the recognition with image processing technology.
The language for the programming must be Python.
Is there any idea how I should proceed?

Thanks in advance ðŸ˜Š"
170,imageprocessing,"Hi.

I am trying to convert a black and white image into 2D matrix, hopefully with binary numbers to to show pixels that are on/off. I've been searching and looking at topics like image segmentation, feature detection, using opencv. I unfortunately don't know where to start.

Any help would be much appreciated.

Thanks"
171,imageprocessing,"Why learn image processing?

[https://www.youtube.com/watch?v=6Qfdn9QCdis&t=67s](https://www.youtube.com/watch?v=6Qfdn9QCdis&t=67s)

Full course is available at

[https://evergreen-school1.teachable.com/p/fundamentals-of-image-convolutions-using-opencv-an-python/?preview=logged\_out](https://evergreen-school1.teachable.com/p/fundamentals-of-image-convolutions-using-opencv-an-python/?preview=logged_out)"
172,imageprocessing,"Who can please explain to me in simple words how does watershed segmentation work (in terms of pixels not in water flooding).

I need to implement the function and not use the one that's already implemented in opencv.

Thank you in advance !"
173,imageprocessing,"Hi Guys,

if anyone can please help me identify the person who tried to kill me today by getting the license number, i'll be so grateful...

&#x200B;

&#x200B;

https://preview.redd.it/67wn6od7f8041.png?width=1920&format=png&auto=webp&s=c4a1a6cd431300b7e6d9a130b27accfd2933fdd1"
174,imageprocessing,"The idea behind the whole thing is that I am currently working on a project. I created the whole reconstruction but now I want to create the whole project with the same settings but this time with 1/3 of the photos blurred to see what the final result would be. As well see this time how many tie points the sparse point cloud, dense point cloud, etc have. Any recommendations would be appreciated"
175,imageprocessing,I have been trying to implement ANPR algorithm in LabVIEW. I have to choose a Structural Element matrix of a particular size for performing dilation and erosion to a real-time car image of size 640X480. What should be the size of the matrix?
176,imageprocessing," [http://www.aiobjectives.com/2019/10/10/person-re-identification-text-to-image/](http://www.aiobjectives.com/2019/10/10/person-re-identification-text-to-image/) 

https://preview.redd.it/s7lb3wmmirz31.png?width=1280&format=png&auto=webp&s=f827ac2578346d32822f64c615597b3968b5b9f5"
177,imageprocessing,"Hi, i got this project from my university, to translate sign-language to words and vice versa, although we havent been taught anything related to image processing. I've tried reading books but theres too much information there, so i decided to come here to ask for help on what to do. Can you people help me out, need to know what exactly to read (related to my project) to help me code it out, what algorithms are there and which might be suitable for my project (for recognizing the hand, and for sign language training), how should i start out this project, links to research papers of similar projects, anything that can help me out, thank you."
178,imageprocessing,"I have attached an image that has been turned into 8-bit binary (BW), and I am trying to detect the circles. As you can see, the circles can be seen, but they have gaps in their perimeter, and I was wondering if there was any way of completing the perimeter to separate the circles from one another?

&#x200B;

Thanks."
179,imageprocessing,"Here is a series of posts I am writing on image processing for beginners:

1. [Lessons on Digital Image Processing (#1)](https://medium.com/analytics-vidhya/lessons-on-digital-image-processing-1-b7a1fa3acfe9)
2. [Introduction to Digital Image Processing in Python](https://medium.com/analytics-vidhya/lessons-on-digital-image-processing-2-983d8bab98c8)
3. [The R, G, and B in an Image](https://medium.com/analytics-vidhya/the-r-g-and-b-in-an-image-971b9aecfb7f)

It would be great if you take a few mins to read that and give me feedback."
180,imageprocessing,"Hi there,
I wonder whether there is a video format, that allows me to store videos in a compact/compressed way.

My videos have between 1-2 hours of length and consist of very repeative frames/tiles.

To be more exact:
I am screenrecording certain webinars in 1920x1080, which show my prof (in a 180x 120px frame) and the rest is been used by a powerpoint presentation of around 20 slides.
So in opinion the most compressive way would be to store the mentioned 180x120px separately and to overlay these of around 20 pictures of the mentioned slides.

(to be honest: These 20 pictures is just mentioned to illustrate the application. As he is sometimes drawing on the power point slides, there are some more pictures to take. There is also the windows time bar in the bottom border, showing the current time - so another tile which is been modified 120x in two hours)

Is there a format allowing this application/such kind of compression?

Which format is been used by observation cams? Theyâ€™re are also recording more or less the same picture the whole time, which is just modified by passing animals, passing people, the motion of trees in the wind or from the moving sun.

Thanks in advance!

P.S. please excuse my bad english. I am still learning... ;-)"
181,imageprocessing,"Iâ€™m working on a project where Iâ€™m trying to quantify the smoothness of surfaces for work.  In this pic I have two images from surfaces that have different roughness.  If you look closely, the line pattern that is reflected off the surface varies from one surface to the other.  

Does anyone have any suggestions as to how theyâ€™d process these types of images to try to quantitate the way the white and black lines look?  

Iâ€™m planning to crop away the brown frame and process only the line pattern.  

Many thanks


https://imgur.com/gallery/AmBE7IC"
182,imageprocessing,"Apologies if this is a stupid question, but I'm currently contemplating a final year project idea that would involve using image processing to detect the material of an object. As I am a noob to this I was hoping someone could inform me if this is possible. Thanks!"
183,imageprocessing,"I am taking large numbers of photographs of the moon and looking for birds that are flying across it. It's tedious to do manually.   
   
I know there is software that will align the moon shots and stack them to take a median pixel to make the moon look really sharp. But I'm not looking for the most similar pixels, I'm looking for the few images that are most different, especially in a particular part of the frame where a bird obscures the moon. The statistically most different frames, post alignment.    
   
I can imagine a software like this might be already in use for something like security camera monitoring where people want to see a summary of what weird stuff moved around in a restricted area or something like that.    
   
Any ideas? Thanks."
184,imageprocessing,"***The challenge is a fixed frame display size of 472x836 pixels.*** 

While advising users to supply images of optimal size and aspect ratio, invariably some photos may be displayed with the correct height but not the proper width or -- vice versa. 

Is there a digital tool in the form of an SDK or API that can extend the edge of an image via a technique like a Gaussian blur? I see something like this approach being used when TV journalists must make a vertical cell phone video more aesthetically fit the broadcast screen.

Any suggestions are appreciated. We'd be delighted to license the code that can accomplish such an enhancement for our app."
185,imageprocessing,"Hello everyone. I'm a newbie to computer vision and computational photography.

I'm trying to solve the following problem:

I've taken a burst shot on my DSLR camera of me making a dribble and dunking the basketball, and it consists of 8 photos. Using OpenCV and python, I am trying to combine all those photos together. I have tried doing the alpha blending addition of the images, but the combined novel image gets too transparent. Does anyone have any suggestions on how to approach this?

The goal is to have a novel image that looks similar to the image below.

&#x200B;

https://preview.redd.it/2o44vn7hpnk31.jpg?width=640&format=pjpg&auto=webp&s=807f4e5aaefd1b9cc5f75718f77b85d351b05f03"
186,imageprocessing,I am a Master student and need some topics to do my project in Image Processing.I have time of one year to do my project...Please suggest some topics
187,imageprocessing,"How to start image processing, tutorials any??"
188,imageprocessing,"I am currently working on soccer stream translation to a 2D reference plane. Segmentation approach for my soccer field translation is to detect the circle in the frame and according to the radius of the original circle i ll' translate the distance of 1 px to meters. I have segmented the lines using LSD(Line Segment Detector) approach. Although LSD is segmenting each line in the frame but it makes [LSD OUTPUT](https://imgur.com/WkzKajO). In order to fill the empty spaces i dilated the output image with [5x5](https://imgur.com/mYotObH) kernel and [10x10](https://imgur.com/tfwLewv) kernel.
I am currently trying to detect the Ellipse/circle in the image so that i can translate 1 pixel distance to meters and track the player on a reference (120,90) 2D Cartesian plane. Any method that can detect this circle or curve in the frame will help.
Note: **Issue with contours** is that, due to dilation the contours is unable to detect the ellipse and on applying [canny](https://imgur.com/2dtx4bQ) the ellipse once again gets missing points.
**Issue with Hough Circle & Ellipse** Both not working using [scikit-image](https://scikit-image.org/â€¦/plot_circular_elliptical_hough_tâ€¦) code ref."
189,imageprocessing,"Let's say I filter an image with a Gabor filter. Algorithmically I implement this as a Gaussian convolved with a sinusoid grating of some orientation. 

&#x200B;

Now let's say I want (roughly) recover the original image from the filtered one. How can one do that?

&#x200B;

Thanks!!"
190,imageprocessing,"I want the drone go in a spiral around a pole without GPS and with only one camera . 

I want to implement something like this

 [https://www.dronegenuity.com/doing-more-with-point-of-interest/](https://www.dronegenuity.com/doing-more-with-point-of-interest/) 

&#x200B;

Ive already tried using optical flow but it eventually looses the point of interest"
191,imageprocessing,"I am looking for a Digital Image Processing and analysis textbook, but there are specific topics that I would like the book to cover. Among other topics, I would like it to include a discussion of: (Orthonormal) basic functions, Mahalanobis distance, subspaces, image registration, error accumulation, Background estimation, and image moments.

What textbook(s) would you recommend? I'm not new to image processing, but I'm unfamiliar with these topics.  The sources that I've found tend to be published articles, and not a comprehensive text. Thank you in advance!"
192,imageprocessing,"We are happy to introduce [Quik.ai](https://Quik.ai) \- the **online platform** that processes images itself, driven on artificial intelligence.

* Quik.ai processes **an image for 3 sec.**
* **Batch images** can be edited with multiple features simultaneously.
* Best product image editing solution for **eCommerce**, but **designers** may use it as well for their purposes.

https://preview.redd.it/q9tre0lp08d31.png?width=700&format=png&auto=webp&s=de7df37d3101bb38189a820a12a2e9d361a559dd

Some features [Quik.ai](https://Quik.ai) does:

https://preview.redd.it/qo1jorlt08d31.jpg?width=1195&format=pjpg&auto=webp&s=bc6dd421a6b75801b12531378f26d3ecaf9e36ea

&#x200B;

https://preview.redd.it/aenkpxhu08d31.jpg?width=1195&format=pjpg&auto=webp&s=e586787a5152ce34e7276b8998a32ea531907cc3

&#x200B;

https://preview.redd.it/bchnq9av08d31.jpg?width=1195&format=pjpg&auto=webp&s=ac1442c5de7e97464c19e78efe0229bfcd1b86d1

&#x200B;

https://preview.redd.it/uot86igl28d31.jpg?width=1195&format=pjpg&auto=webp&s=ee641e6d78c77421082c82a211cdbd03491c518d

Watch the video about how it works:

[`https://www.youtube.com/embed/YqUov31oRAg`](https://www.youtube.com/embed/YqUov31oRAg)"
193,imageprocessing,"Let's say you do photography and you post images online to get customers. You know that your rival will try to steal your picture and claim it as his own by watermarking it. You know that he keeps his watermark constant but can place it randomly anywhere on the image. Given that you know the watermark ahead of time, what transformation can be done to the image so that you can still post it online (since that is how you get people to buy your images) without changing the image content too much, but are confident that your rival can't steal it from you until he changes his watermark?"
194,imageprocessing,I am new to image processing and I am doing a project on image processing using openCV python in which I have to detect walls from a floorplan(jpg format). I have the bounding box for 1 wall. Is there any approach which I can use to obtain the bounding boxes for rest of the walls?
195,imageprocessing,"I don't know if this is the right place to ask but I was wondering if there was a way to optically spread out a section of the spectrum.
What i mean is lets say you're looking at a field of grass, you want to emphasize the difference in green, can i stretch green over the spectrum so that Yellow-green is red and green-blue is violet.
I'd love to be able to do it without a camera,processor, screen setup."
196,imageprocessing,"I am confused between spatial domain and frequency domain. i can't really differentiate them. I know spatial domain deals with image plan. Frequency domain deals with intensity i guess. Here is my doubt what we are actually dealing in spatial domain? spatial domain works on pixels directly and a pixel contain the intensity value of each colour at that point/pixel. so if we change values of pixels we are actually dealing with frequency domain here.We do spatial enhancement like negative of image in which we kind of interchange the intensity values from dark to light or light to dark. In spatial shouldn't we deal with the position or something like that as the word suggests?

This might be a foolish question but i am really confused between them. Please explain me in details what we are actually dealing with in both these domains like what values/ properties we are changing in both these domains. I have read alot of articles but none worked for me."
197,imageprocessing,i am quite interested in working wit image wit depth data . can anybody suggest some filetype to work wit.. or any good resources.
198,imageprocessing,"Hi there, I have just started an image processing course and I have a  question that keeps bugging me, which I can't find the answer to. 

What is the difference between   probability distribution function  and  cumulative distribution function ?"
199,imageprocessing,"Hello Everyone!  
I am working on this problem from a long time. Actually, I have created a hair segmentation mask of an image and I now want to change the hair colors according to some input rgb value. I have used PIL with python for this task using alpha blending but results are not good. Kindly tell me how can I color the hairs according to segmentation mask."
200,imageprocessing,"Hello, is it possible to create artificial ultrasound from MRI data (while providing the deformation field that the MRI went through)? Is that a program or algorithm that does that? Thank you."
201,imageprocessing," 

I graduated this December with an EE degree and have been running into a series of brick walls trying to get into image processing as a career. Sadly only in the last year of my college was I able to take an image processing course and only then did I find how much I actually enjoy it.

&#x200B;

Out of school I applied to several places and after about three weeks actually got an interview with Lockheed Martin where they offered me the job to work on missiles using image processing. They even wanted to get me certified in radiology. The job was super cool but the location turned me off. Thinking this was just the start of many great things I turned down their offer. How stupid I was. I have almost reached a breaking point in my search after 4+ months. I have had pros look over my resume, I am going to networking groups, I have tried career fairs, and I am going through every job board every day just to find something and nothing seems to help.

&#x200B;

Every job board will have maybe 20 hits on the search ""image processing"" or ""Matlab"" of those 20, 10 might be applicable to actual image processing and not something totally unrelated (or sponsored and completely unrelated, thanks Indeed), of those 10, 1 might not require 6+ years experience, require being a post doctoral fellow, or other credentials. Networking groups are just filled with old people who think I am an electrician and have no idea what I have done or want to do. Only one career fair has actually been a career fair and that was for my college, the other 3 I have gone to are nothing but ""get a job as a cop"" or ""food service"" or disguised college recruiting events. The worse part is the next career fair for my college isn't even till September. Even my back up plan of just looking for EE jobs results in the same thing, hundreds of hits, 30% are applicable (If I ever meet someone IRL that calls themselves a ""hotel engineer"" I will strangle them) , 90% of that 30% call themselves ""entry level"" but require 6+ years and special software and such, and the remaining are field engineer jobs and FPGA design jobs.

&#x200B;

I am genuinely starting to break down and my mental health is beginning to take a hit. Every day I get up and all I see is rejection email after rejection email. Even after 4 months and literally hundreds of applications I have only gotten like 5 interviews, 1 from Lockheed where they offered me the job, 3 phone/skype/webcam, and 1 from Raytheon where they flew me to Texas just to tear me a new asshole and tell me everything I have ever done is worthless in the field of EE.

&#x200B;

I tried recently to talk to my professor from school but all he did was tell me that image processing is great, but DEEP LEARNING with an image processing background, is the future and said I should look into that. Welp... I learned some, even watched all of a Stanford course on it on YouTube and did all the lessons. Well guess what the results are when you type that into a job board and what do you get? 70% non-applicable ->90% of the 30 want 6+ years and specialized software.

&#x200B;

Please can someone help identify what I am doing wrong? I just want a job doing something I remotely enjoy. It's almost daily I don't think about that job I didn't take and contemplate hanging myself. It has to be me right? Supposedly the job numbers are insanely good right now."
202,imageprocessing,"Hi, i'm currently finishing my computer science degree, and for my last assignment i have to implement a couple of image denoising algorithms using kotlin and opencv. Right now i've implemented the mean filter and it turned out Ok but now i have to implement the BM3D and i cant seem to find any info on it, i mean i've found some withe papers but i dont really understand what i have to do. I know i'll have to implement some hard threshold and wiener filterings, but cant really understand how they are related. Does anyone know or has some info on this, like how can i implement this BM3D algorithm"
203,imageprocessing,"I was given the task to make a poster for my university and although, I am good at posters, I am not so well in image processing. This poster needs to have a picture I was sent and it is very distorted at the very basic level of pixels. The whole image is bursting into pixels and I cannot seem to find any tool to enhance the picture to make it work for an A3 sized poster. Any suggestions might help."
204,imageprocessing,"Hey all, I've been looking into twitch and streaming videos. I saw that Wolfram is streaming about knowledgebase query language on the 14th. Heres the link if anyone is interested...

[https://www.twitch.tv/events/ZVdXsv1\_QDO9jPYvZ0MsxQ](https://www.twitch.tv/events/ZVdXsv1_QDO9jPYvZ0MsxQ)"
205,imageprocessing,"I am looking for a way to compare 2 3D mri images, to see how it changes over a period of time. I could see the changes on each slice using imshowpair but I would like to see the same effect in 3D. Anyone knows how I can do that? Any useful toolbox? 
Thanks in advance!!"
206,imageprocessing,"Hi- I'm trying to see if there has been any research done in this hypothetical field.  

Given two consecutive frames of a video file, one at full resolution and the next one shrunk down (say to half the width and height), we would want to apply super resolution to the lowres frame by *using the high-res data found in the highres frame*.  An appropriate algorithm could note the similarities between the two frames and take advantage of the high-res version by placing it in the super-resolved version of the originally low-res frame.

&#x200B;

Does anything like this exist?  Thanks!"
207,imageprocessing,I would really love to learn image processing for it would really help me in he future and I have to learn the basics the basics as soon as possible .... Anyone interested please dm 
208,imageprocessing,"Hello, I'm a newb to image processing. I'm realizing that ""edge effect"" might be a ubiquitous issue in the image processing professional's daily life and wanted to ask about the common ways you deal with it. For clarification, I am talking about the phenomenon where when moving a kernel across a matrix, the outer rows and columns of pixels of the image will either have to be estimated or not given at all. How big of an issue is this for image processing professionals? What kind of methods or algorithmic tricks do you use to get around this?

&#x200B;

I am curious because I am hoping to split a large image into smaller tiles, and will try to experiment with various algorithms that ""borrow"" values from adjacent pixels. I don't want there to be a bunch of border lines where the values aren't calculated correctly. My instinct is to do some creative ""slicing"" on the images to create an overlap of pixels that eventually results in a complete calculation (aside from the very outer edge of the **entire** image). Is this type of thinking heading down the right path?

Let me know if my question doesn't make any sense and I will do my best to clarify. For what it's worth, my only experience in programming with images is in python representing images as numpy arrays. Thank you!"
209,imageprocessing,"I am researching current papers and software for noise reduction. I was wondering, if maybe someone here has experiences with the current status there and can give me some suggestions on what to look at. I am searching for the latest papers in the field but mainly software / code that you can actually already use for your own footage, if say, you are a photographer or film maker. Thanks for any replies!"
210,imageprocessing,"Can anyone help me with implementing MARGA in Matlab? 

Heres the paper 

https://www.sciencedirect.com/science/article/pii/S0169260713003878"
211,imageprocessing,"I am currently in need of a good background subs traction algorithm that can extract one person from the image. Basically this algorithm should be able to detect and remove background where background is not a green screen. 

Can you guys point me toward any implemented algorithm that I can use to achieve the objective. "
212,imageprocessing,"Anyone knows what does ROI means in image processing, Iâ€™m reading a track and trace machine manual and itâ€™s mentioning outer and inner ROI, anyone can help "
213,imageprocessing,"My first experience with Image Classification using Keras with Pre-trained VGG16 Model. 

[https://prakhartechviz.blogspot.com/2019/01/image-classification-keras.html](https://prakhartechviz.blogspot.com/2019/01/image-classification-keras.html)"
214,imageprocessing,"Hi all, I'm trying to find a way to find straight contours/lines/edges in noisy images (see the blue lines I drew in the image below). 
Does anyone have a recommendation on how I would go about this?

https://imgur.com/a/y01Betk"
215,imageprocessing,"Hi, I've a little bit strange question. I need to study and understand the theory behind the digital image processing. So study images like matrix, understand luminosity, contrast and working whit histograms. 
But I don't find any textbook or comprehensive resources about this. Which field it is? I'm not really interested in practical processing (maybe after) but in theory.
Do you have any tips or resources?"
216,imageprocessing,"Which of the following are linear shift invariant filters? 
-laplacian filter 
-median filter 
-dilation filter 

What is the relation between a linear shift invariant filter and a convolution filter??"
217,imageprocessing,"I am proposing a digital image enhancement algorithm but I need to write down a validation method for my algorithm. I have no idea how are they done, any help would do."
218,imageprocessing,"The idea is to detect circles of the open cross sections of stacked pipes and subsequently estimate the 'circularity' or 'concentricity' of those circles.

My initial approach involves a Hough Transform detector, but the drawback is to include the expected radius manually.

How do I train a CNN to detect circles of variable radii?"
219,imageprocessing,"My husband Ariel was a victim in a hit and run in Seattle. He was riding his bike downhill when a car driving in the opposite direction took a left, hitting Ariel and smashing his bike. Ariel was injured badly and taken to hospital. The driver who hit him fled the scene, leaving Ariel on the ground, and his mangled bike with him.

We have several cameras documenting the car from different angles - several from a bus that drove just past the car and filmed it from the front and the back (as the car drove past the bus), as well as one camera (a Nest) from a window of a neighbor. In all, there are dozens of frames across videos that capture the license plate itself, but none of them has the resolution to show the license plate number. 

I know there are super-resolution methods that rely on a plurality of (blurry) frames to create a higher resolution image. There may be other methods I'm not aware of. I don't have the technical ability unfortunately to do this enhancement of resolution. (I am an engineer with some background in signal processing - but my days at the university were 15 years ago...)

We know the make and model of the car, as well as the demographics of the driver and a general idea of where he lives. Even if we're able to uncover one character from the license plate - that will go a long way for the police to be able to narrow down their search and reach him.

I wanted to reach out to you - the technically savvy, see if there's anything that can be done. I will send the videos and point to the precise times where the car and its license plates are seen. 

I appreciate any help that might bring Ariel some justice... Thanks for reading."
220,imageprocessing,"Hi, sorry if I'm posting this on the wrong subreddit. I am trying to build a smoker detection using image processing . I feel like smoke detection is the easiest and the most robust way to do it. But I can't seem to get it to work. I've tried detection of moving particles in a video and then done colour thresholding but it gets a lot of other stuff aswell. I've tried CNN classifier. But it didn't work aswell. Any better way to do this or any other way to reduce the false truth? Any help would be nice ðŸ˜Š"
221,imageprocessing,"I am allowed to use the readim function of cv2 but nothing more, I have to calculate the histogram data of .jpeg files manually. How does one get the hue values of pixels as an array? Are there any good tutorials on this?"
222,imageprocessing,"Hey there, folks, I was wondering if anybody here works with the ISIS3 processing suite?"
223,imageprocessing,"It took me just 2 minutes to train with 50 positive images and 100 negative images.

Checkout the tutorial here: https://youtu.be/ydSXgBZ1ybk"
224,imageprocessing," 

I used Matlab (but anything would work), and then used histograming of different video regions to do a frame-by-frame segment classification of a youtube video. More details here, if you want to check it out:

[https://www.youtube.com/watch?v=aYJAHdwlBCM](https://www.youtube.com/watch?v=aYJAHdwlBCM)"
225,imageprocessing,"Assume a color X with alpha 1 and RGB 255,230,210.

How can i find another color ( or an array of colors ) with alpha A that blended with a background of color Y ( e.g 255,255,255 ) would produce the original color ?

EDIT: I guess im assuming an ADD operation for composing the final image. What im really trying to do is extract the information out of an image as low in alpha as i can so i can then transfer the result image elsewhere without having 'opinionated color'. Think extracting text out of an A4 and placing it on a different color background."
226,imageprocessing,"I'm trying to come up with a method to match a given mathematical plot against a database of other plots. To make it more specific: plots are generated in R as PNG and might have different dimensions. The latter means that simple pixel-by-pixel matching won't work, even when resized, because text, plotting symbol, margins etc between two versions of the same old are non-linear transformations of each other.

There's a number of good image matching algorithms available online but those assume any area in the picture is relevant, whereas with mathematical plots it's predominantly about the artifacts representing data that's being plotted.

I'm looking for pointers: is there maybe an algorithm, paper etc related to this task? Or maybe someone heard of a specialized DNN (which could help in identifying those most important artifacts)? Appreciate all comments and suggestions."
227,imageprocessing,"I am working on a problem where I need to find bounding boxes for white area in an image. Since I am dealing with real-world pictures, I have set a threshold on the RGB values, I create a mask from that and then label it and get bounding box coordinates from that. Here is the code.

    import numpy as np
    from skimage import io, measure
    
    def bin_labelled_img_to_bboxes(bin_image_labelled):
            bboxes = []
            for j in np.unique(bin_image_labelled):
                if j == 0:
                    continue
                curr = (bin_image_labelled == j)
                if np.sum(curr) < 50*50:
                    continue
                indices = np.nonzero(curr)
                miny = np.min(indices[0])
                minx = np.min(indices[1])
                maxy = np.max(indices[0])
                maxx = np.max(indices[1])
                bboxes.append(((miny, minx), (maxy, maxx)))
            return bboxes
    
    class WhiteSeperator(object):
        def __init__ (self, img_path):
            self.img_path = img_path
            self.img = io.imread(self.img_path)
            self.bin_image_labelled = np.zeros((self.img.shape[0], self.img.shape[1]))
            self.bboxes = []
    
        def get_bin_labelled_img(self):
            img = self.img
            chan1 = (img[:,:,0] > 200) * (img[:,:,0] <= 255)
            chan2 = (img[:,:,0] > 180) * (img[:,:,0] <= 255)
            chan3 = (img[:,:,0] > 140) * (img[:,:,0] <= 255)
    
            bin_img = (chan1*chan2*chan3)
            bin_image_labelled = measure.label(bin_img)
            
            return bin_image_labelled
    
        def get_white_bboxes(self):
            final_white_bboxes = []
            self.bin_image_labelled = self.get_bin_labelled_img()
            white_bboxes = bin_labelled_img_to_bboxes(self.bin_image_labelled)
            
            for bbox in white_bboxes:
                width = bbox[1][1]-bbox[0][1]
                height = bbox[1][0]-bbox[0][0]
                if height > 80 and width > 200:
                    self.bboxes.append(bbox)
                    final_white_bboxes.append(bbox)
            return final_white_bboxes

This takes about 3-11 seconds per image for high res images (3000 something x 2000 something). My assumption is that the variance in time per image depends on the number of white bounding boxes found (blaming the bin\_labelled\_img\_to\_bboxes function here)

Since I have to do this on video frames, even 3 seconds is super slow. Can the above be done in a more efficient way?"
228,imageprocessing,"I am working with 384x256 images that are very noisy. I have explored box blurring by convolving with a uniform 3x3 kernel or performing 2x2 binning. One thing is that with blurring the resultant image will have the same resolution as the original, but with 2x2 binning, the resultant image will have half the resolution (192x128). I am thinking the spatial information is lost anyway from blurring, so is blurring actually still preferable to binning?"
229,imageprocessing,"I'm trying to understand cubic convolution interpolation and I've come across something I can't quite wrap my head around.

In the [wikipedia article](https://en.wikipedia.org/wiki/Bicubic_interpolation#Bicubic_convolution_algorithm) we see the kernel presented in [this form](https://imgur.com/a/3h8USjI).  Slightly on from there assuming a = -0.5 we see an equivalent representation in [matrix notation](https://imgur.com/a/kbMGk8H).  

How did they arrive at that matrix?"
230,imageprocessing,"I am a beginner to image processing and I am working on a medical image processing project. I want to segment out only the **major vessels** in a given image. 

For example, if the input image is:

[Input image 1](https://preview.redd.it/xtqvo0qzl9c11.png?width=431&format=png&auto=webp&s=5f414e14e2bcaa362c6b0d80a8680378a6dd346c)

The major vessels in this image would be:

[Marked image](https://preview.redd.it/c41hiva4m9c11.jpg?width=432&format=pjpg&auto=webp&s=8f51574b964a27d5e682f6ddf433693ffaab56d3)

I need to find the direction of the complete blue line. 

Another example:

[Input 2](https://preview.redd.it/knrxq4xdm9c11.png?width=431&format=png&auto=webp&s=ed9f5f3099834d6ef6a9e71a49618927ab7e8a65)

The **major vessels** in this image would be:

[Marked image 2](https://preview.redd.it/zub3yv6im9c11.jpg?width=430&format=pjpg&auto=webp&s=9deb430d302fc1f5fd2e826f844faeb495d68e75)

The major vessel here is going in a different direction than the first input image. I want to rotate the 2nd image such that the major vessel goes in the same direction or almost the same direction as the first image."
231,imageprocessing,"I want to manually define an image region and store it in python code. Then when the function is called on an image, all the pixels in that region should be shaded. How do I go about this? I will be applying this transform on the same image every time. The image is intended to be served onto a webpage after all the transformations have been done.

"
232,imageprocessing,"Hey there,
I am currently working on the problem of Image Registration and implementing feature based registration based on HOG in OpenCV(python). The process involves three steps
1. Keypoints extraction(done using FAST algorithm)
2. Feature Description(HOG)
3. Feature Matching
I am a newbie in the field of Image processing and want to compare the HOG vectors for feature matching. I tried using the cdist() method in openCV but it results into memory error. I also tried the inbuilt method of brute force matching but it seems it doesnâ€™t work for HOG descriptors and only worrks for multidimensional descriptors like sift and surf.
Can someone suggest a good method to proceed to feature matching stage?
Thank you."
233,dataanalysis,"
# Data Analysis' Best of 2020

Like many other subreddits that are winding up 2020, /r/dataanalysis will be participating in [Reddit's **Best of 2020** event](https://www.reddit.com/r/bestof2020/). And now that 2020 is on the verge of being history, we are looking for you to nominate the best submissions and comments made throughout the year. 

# Added Motivation

A lot of these ""Best of"" contests have relatively low participation. So to ensure that doesn't happen here, we're adding an extra element:

* Those who offer nominations will themselves be included in a draw for additional Reddit award prizes. 
* For each nomination a user offers, up to a maximum of 10 (you can of course nominate more!), that user's name will be included as an entry in the draw. 

There will be more than 1 award to be distributed, provided that we have at least 50 entries.

# Categories

Since lots of members just comment, there are some categories which are exclusive for comments, others are exlusive for post, and some apply to both comments and posts.

* Best Career Question (Post)
* Best Technical Question (Post)
* Best Guide / How-To (Either)
* Best Technical Answer (Comment)
* Best Career Advice (Comment)
* Best Career Advice (Post)
* Best Data Visualization (Either)
* Best Resource (Either)
* Funniest (Either)

# Voting Method

* The thread here is where you nominate. Each of the comments below is a category. 
* For each submission you want to nominate, 
  1. Reply to the top level comment under the relevant category with a direct link to the post
  2. Include the username of the nominee  
  3. Give a 1 or 2 point explanation of why you want to nominate that one, *for that category*, e.g. ""Great explanation of how SQL works!""
* To vote on the best nomination for each category, simply upvote the nomination comments you believe most deserving! No downvoting, please.
* If the nomination does not fit the category, it may be removed in accordance with mod judgement.

# Deadline

* Submissions & voting need to be complete by January 9, 23:59 PST. 


# Other Rules

* The post or comment must have been made in 2020 (the 366 days since preceeding this post!) and not edited after the time of this post.
* You can nominate posts by anyone but yourself.
* If you nominate multiple posts by others (and you should!!), you shouldn't nominate the same redditor more than once.
* Every nomination must not be in violation of Reddit's rules nor /r/dataanalysis' rules (see sidebar)
* Comments cannot be nominated for multiple qualifying categories.
* Comments by anyone who participated as a Mod here during 2020 is ineligible to participate.
* At genuine least 5 nominations, by 5 separate users are needed in a category in order for that category to be eligible. 
* If the top 2 to 3 nominations within a category have scores within 20% of the maximum, the prize may be split or selected from the top 2 to 3 at random.
* Don't make a duplicate nomination. 
* Finally, there will be an announcement thread for the winners. The winners need to reply in that thread *before the end of January 2021* in order to receive a prize. 

# Have a Safe & Happy New Year!"
234,dataanalysis,"I have given a few interviews for entry-level data analyst/data science roles. I was asked a few of the following situational questions. I would like to know how would you answer it. My answers were quite vague or crisp and short. And would like to know more

1. the sales manager has some new data and wants to set a meeting to discuss few things, what questions would you ask him before you get started/  how would you prep on your part.
2. you want to make a dashboard for the ceo, sales head, and the sales exec, what approach would you follow with your dashboard.
3. how do you deal with missing data? how do you know when to use mean, median or mode?"
235,dataanalysis," Hey everyone, my name is Sean and Iâ€™m an intern at Evil Geniuses (Tier 1 Esports Organization) working with the data and tech team. We will be hosting a workshop next week (5/19 at 11 AM PT / 2 PM ET) focused on the use of data in esports. The two panelists who will be running the workshop are Soham â€œvalensâ€ Chowdhury (Head of Data Science) and Zach Kamran (Head of Tech and Analytics). I have copied the Eventbrite link below, please free free to sign up, the event is completely free. If you have any questions, please don't hesitate to reach out to me on twitter (@reegs191)!

Eventbrite: [https://www.eventbrite.com/e/data-and-tech-innovation-in-esports-tickets-154295117851](https://www.eventbrite.com/e/data-and-tech-innovation-in-esports-tickets-154295117851)"
236,dataanalysis," Hi, I'm bumping this up to the top since we will be interviewing next week for this position.  Please email if interested. 

I work for a consulting group that creates dashboards and reports for manufacturers. We are looking for someone who may be beginning their journey or in school for data analytics that would like to work remotely 10-20 hours a week for 4-6 months and possibly join our team in the future.

This does not require a working knowledge of SQL or Python, although this skill set may serve well in the future. We primarily work in Excel, G-Suite, Google Data Studios, and Tableau.

The position would involve pulling and compiling reports, some data entry, and help to maintain and to improve dashboards and processes.

Please reach out to me if interested with a little history about where you are in your journey, what your PayScale request would be, and your availability.

Edit: I created an email I can publish to send a resume or job history and a little history of your journey: [Vdriven.analytics@gmail.com](mailto:Vdriven.analytics@gmail.com)"
237,dataanalysis,"Hi fellow Data Scientists and Data Analysts, I am currently working as a data Analyst. I am utilizing Sql, python excel and power BI on a day to day basis in my work. I aspire to become a Data Scientist, I am working as a data Analyst in healthcare industry for a year.My work in Sql include writing manual queries to the database for importing data. In python, my role is automating reports on a regular basis. I also visualize reports using Power BI and integrate to my company portal. What skills do I need to learn and what steps do I need to take to achieve this goal of mine? Any advice is greatly appreciated. Thanks in advance"
238,dataanalysis,"Im new to dataanalysis. And Im working on learning how to do it using python with Jupiter notebook. I needed a dataset to work with to keep the learning experience interesting so I chose the historic numbers of reported inflation from my government. Im from Norway and they report on inflation using CPI.

However, the dataset is not a straight forward spreadsheet like the ones typically used in tutorials. It looks like this

&#x200B;

https://preview.redd.it/ucoa8q3b6fz61.png?width=833&format=png&auto=webp&s=4825447f583eef3af0d270b4b52b001b177afbe1

Column 1 and 2: Number and name of the product group. 

Column 3 and 4: Month of reported numbers (doubled for some reason, I can delete one column)

Column 5-8: Different numbers reported for the product group.

&#x200B;

After the months has reached 2021, a new product appears on column 1 and 2 and the months reset.. etc.

&#x200B;

How should I attack this spreadsheet. Im sure that this is a quite normal way of presenting data like this and that its probably quite simple. Im just dont know where to start and what to Google."
239,dataanalysis,"Hi, I'm a 2nd year college student studying finance and business analytics. So far my skillset is just basic SQL and Excel with a little bit of R programming. I want to better my skills and learn what it's like to actually do analytic work. I'm willing to learn a lot off-work and I just realized college isn't helping my skillset be competent enough. Does anyone know businesses/websites that will take newbies who volunteer?

Tldr: I'm a noob at data analytics and want to volunteer my time. Know any resources that take volunteers for data related work?"
240,dataanalysis,"Hello,

I am a junior in High School and part of my program is to work with a researcher to do a project. My lab moved virtual this year and this caused me to be working with coding instead of hands on lab work which is what I ""signed up for"". Basically Ive been able to slack all year and my mentor is a little flakey which has further allowed me to avoid doing any and all work. I realize that this is my own fault and instead of starting my project a day before I need to finish Im starting a month before. Yay! The problem here being that I was given instruction at the beginning of the school year and idiot me did not write down or record them leaving myself with small clues about what I am actually supposed to be doing. Now I am supposed to have learned R, which I have not done, and I have a paper titled, ""Comprehensive characterization of plasma cell-free *Echinococcus* spp. DNA in echinococcosis patients using ultra-high- throughput sequencing"" as well as the data that was used in this paper. I am supposed to be analyzing this data but I honestly don't know what I am supposed to be looking for. I have one page of notes where I wrote, ""find motifs"", ""we predict from this gene..."", and ""will show in Serem""

I thought that I would bring this mess to reddit in the hopes that some random person might know exactly what I was talking about and would be able to help. If you have any ideas of another sub this would help in I would greatly appreciate it, and any and all resources would help.  Im just trying to save my ass before I email my mentor saying that I have no idea what I am doing. 

Hopefully thanks in advance"
241,dataanalysis,"Hey everyone!

I graduated from college last December and am 2 months in to my first ""real"" job. It's not a data analysis position, but I have already done a couple of projects that I think relate to data science. For example, I work at a data center and I created an excel doc that visualizes connections between UPSs and PDUs, and used a ton of formulas to create the ability to see what would happen/how power would redistribute if a UPS went down. 

I found that I actually really enjoyed that project: treating it like a puzzle, learning about how to use excel on a much more complicated level than I'd ever done before, and getting immense satisfaction when I completed it and turned it in to my boss. 

So my question is: what are some steps I can take (that don't involve going back to college or getting a different job) so I can explore and see if data analysis really is something I want to do? I do have access to LinkedinLearning (aka Lynda).

Thanks in advance!"
242,dataanalysis,"Hi, I'm currently working in the data migration field (mainly with VBA) and are working towards becoming a data analyst. 

I'm aware of what skills are required for data analysis, but my current manager has asked me to learn Javascript. 

My question is: is there much of a need for this language in the data analysis profession? I'm just wondering how deep I should go with it or whether I should learn just enough to get by and focus my attention on SQL / PowerBI / Python etc instead. 

I know Google Scripts App use Javascript for Google Sheet manipulation - so the only real benefit I see would be if there is a huge shift from desktop sheets (Excel) to G-sheets which I doubt is going to happen. 

Are there any other benefits for Javascript or should I focus my attention elsewhere? 

Thanks in advance."
243,dataanalysis,"My code

a='2021-05-15'

a1=pd.to\_datetime(a,format='%Y-%m-%d')

a1.Timestamp().month"
244,dataanalysis,"import pandas as pd

def date\_summary(x):

return ([x.today](https://x.today)(),[x.today](https://x.today)().year,[x.today](https://x.today)().month)

date\_summary(pd.Timestamp())"
245,dataanalysis,"A client produces 6-12 spreadsheets each quarter.

They have an excel guru put together a big document that visualizes the data. The document contains things like bar charts and descriptive statistics.

I would like to prepare a dashboard application  that is hosted online or could be shared as a standalone application.

The application should be able to accept the data sets as input (ideally, with a drag-and-drop graphical interface), COMBINE the data sets behind the scenes, and produce the necessary data viz.

Goal is to automate the data viz process, and the mechanics should be straightforward since the data sets have the same structure from year to year.

CHALLENGES:

â€¢ The data sets are company sensitive. I cannot host a web application on any old web server. I need some contractual guarantee the data isnâ€™t being spied on. My understanding is that most companies have freedom to intercept online info. Maybe then I donâ€™t host the application online at all? An .html file could work.

â€¢ Client has restrictions on what kind of software they can install. I may be able to install PowerBI or Tableau on my system, but client may not be able.

â€¢ It would be nice to change the infrastructure so that the data is organized somewhere centralized but I donâ€™t have control over that.

I am aware that Tableau can easily visualize data from multiple sources. I.e. it would be simple for ME to organize the spreadsheets, visualize key metrics, and host it online. What I would like is a freestanding application where the CLIENT drags and drops the spreadsheets and an application spits out some visuals.

Thoughts?

Is this too advanced for PowerBI/Tableau? Do I need Shiny/Dash?"
246,dataanalysis,"Modern BI platforms like bippâ€™s are engineered to let business users explore and query these visualizations to make strategic and tactical business decisions. In an interview with Analytics Insight, Angshuman Guha, Co-Founder and CEO of bipp, elaborates how their company is working towards delivering best and unique cloud-based business intelligence to a wide range of companies: [bipp Is Reimagining BI for the Data-Driven Decision-Making Age](https://www.analyticsinsight.net/bipp-is-reimagining-bi-for-the-data-driven-decision-making-age/)"
247,dataanalysis,"Can anyone lead me in the right direction? 

I want to export chats from old and new communities focused on similar topics but in different regions. 

My goal is to analyze the chat/phrases/emoji/stickers/gifs that lead up to certain events and see if a relatable pattern can be found in chats for newer communities in other regions. 

Hit me up if you want to know more or know any cool tools or bots that can make this easier!"
248,dataanalysis,"As the title says, I am starting my career after Masters in Computer Science with intermediate knowledge of Python and C++ programming. And couple of small academic projects done with pandas.

1) How hard/easy can this be for me to be a Data Analyst?

2) What are the most important skills, how should one proceed to get a job in this field?

3) What does a day to day job look like for Data Analysts?

4) Is this a difficult field to get into, compared to Front end/Full stack developer?

Thanks in advance"
249,dataanalysis,"Hello. I'm completely noob at this. When learning Power BI DAX, I found that the functions could be done in SQL with less computer's memory taken. So, Is it okay to clean the data in SQL and then use Power BI for visualization only? 

Do you guys have any example on how Power BI could do better than SQL in cleaning and formating the datas? Thanks in advance!"
250,dataanalysis,"help me!!!!

thank you v much need it asap"
251,dataanalysis,"Does any one of you here comes from eastern Europe or any undeveloped country? If so, did you find a job in some developed countries or you decided to stay at your own country?
Im from Croatia and Im thinking about finding a job somewhere else where my life will be better and where I could be paid enough for my skills. Im new to this field, currently working on a Google certificate and looking for a junior position. Any advices for me?"
252,dataanalysis,"I donâ€™t have much experience with qualitative data coding for a customer survey I implemented. Any expertise on grouping,efficiency, and visualization would be highly appreciated. If there are any software tools you recommend to use I would appreciate those as well. Thank you!"
253,dataanalysis,Is VBA even alive in 2021??
254,dataanalysis,"We're in the very early stages and thought we'd show you so we can get feedback and get a direction as to what we should build over the coming days.

Even though it looks like a spreadsheet,  it works like a database. This means you can not only run SQL queries on the spreadsheet but also scale it to thousands or millions of rows.

**Key differentiators**

1. You can write SQL queries on your spreadsheet. You can also do JOIN queries across spreadsheets.
2. API out of the box for your data so you can wire it to other systems.
3. Easily handle millions of rows - buttery smooth
4. Import your CSV or Excel files and run SQL queries over

**Upcoming features :**

1. Save SQL queries for future use
2. Native connection to the databases
3. Self hostable version

You can sign up here -> [www.spanrr.com](https://www.spanrr.com)

Please let us know what you think? Anything you like to see in the coming days?  


  
Feel free to ask anything in the comments below."
255,dataanalysis,"Is anyone looking for a US-based paid internship? I work for a consulting group that creates dashboards and reports for manufacturers. We are looking for someone who may be beginning their journey or in school for data analytics that would like to work remotely 10-20 hours a week for 4-6 months and possibly join our team in the future.

This does not require a working knowledge of SQL or Python, although this skill set may serve well in the future. We primarily work in Excel, G-Suite, Google Data Studios, and Tableau.

The position would involve pulling and compiling reports, some data entry, and help to maintain and to improve dashboards and processes.

Please reach out to me if interested with a little history about where you are in your journey, what your PayScale request would be, and your availability.

Edit: I created an email I can publish to send a resume or job history and a little history of your journey: Vdriven.analytics@gmail.com

Thank you!"
256,dataanalysis,"Is anyone looking for a US-based paid internship?  I work for a consulting group that creates dashboards and reports for manufacturers. We are looking for someone who may be beginning their journey or in school for data analytics that would like to work remotely 10-20 hours a week for 4-6 months and possibly join our team in the future. 

This does not require a working knowledge of SQL or Python, although this skill set may serve well in the future.  We primarily work in Excel, G-Suite, Google Data Studios, and Tableau. 

The position would involve pulling and compiling reports, some data entry, and help to maintain and to improve dashboards and processes.

Please PM me if interested with a little history about where you are in your journey, what your PayScale request would be, and your availability."
257,dataanalysis,"Iâ€™m seeing tons of certs offered by CCs in my area. I know that going to grad school would be a safer bet, but I simply do not have even close to the money needed. Could a professional certificate from a CC get someone a job in the field of data analytics? Not looking for something crazyâ€”just entry level. Thank you in advance for any advice.

EDIT: I have a bachelorâ€™s degree in a completely unrelated field"
258,dataanalysis,"Hey everyone,

I'm trying to use data analysis to create statements that say something like, ""If you are in this role for X number of months, you will make it to X number of months / years"". I only have Excel (I might could use R to do it though). Any ideas? I started with a survival analysis (again, in Excel which may not be entirely accurate), but I'm second-guessing myself here.

I have over 4,000 employees who have all termed in my file, so I don't think I'm at a lack of data. I have how many days they were in role, how many months, etc. I can get all of that from the time in days via a calculation. Just not sure how I can take this data and turn it into some of those statements like I presented above."
259,dataanalysis,"Hey everyone! Quick introduction. IÂ´m 22, finishing my Bachelors in Advertising and Marketing and learning for the past 3/4 months Data Analysis skills (SQL,Power BI, Tableau and a little bit of Python)

IÂ´m still on the learning process. Will soon start working with Apache Spark and Python to improve my skills and fit as a more ""skilled"" Data Analyst.

So the big question is How to promote/market myself as a Data Analyst? IÂ´m not an expert, IÂ´m building my portfolio and I want to stand out a little bit from the rest. Here I have some ideas I want to validate, have another opinion about them and see, with time, how can I market better myself in this particular position

* Making a Youtube Channel
* Making a Podcast
* Wannabe Influencer on Data Analysis
* Advertise content on Instagram 
* Network with people (I need to learn this too)

ThatÂ´s it! Hope we can share opinions and see what a newbie in the field can do to stand out but also donÂ´t be and idiot saying I know everything when certainly itÂ´s not the case.

Thanks!"
260,dataanalysis,Does anyone have any experience with these bootcamps? Can you suggest a legit one? I have 5-6 weeks time to find a job.
261,dataanalysis,"I'm currently working on extracting some data from an extremely large CSV file which needs to be manually filtered and sorted. Normally I would simply use Excel and select the columns I need, but due to the size of the file the only way I can access any content is through a hex editor. Other programs like Notepad++, CSVConverter, and Google Sheets have all failed to deal with the large amount of data. 

Due to the nature of the file, I cannot simply ask for a copy with the data split into individual files. I have considered using a database, but I doubt any database software would take it other than command line tool. However, I am willing to learn. Does anyone have an suggestions on how exactly to tackle a problem like this?

Edit: Using KNIME, I've managed to get the file down to around 10 GB in size. Great! But I'll likely have to split it a few times so it's more manageable.

Edit 2: Using Bash, I've split it into 21 500MB files. These are able to be opened by Notepad++ Where I can do all of the filtering manually using the search and bookmark line tool. It's a little tedious, but very doable. Thanks for the help!"
262,dataanalysis,What do you consider as an ethical dilema in data analysis?
263,dataanalysis,"I like many others am starting my journey into data analysis, and I am really interested in joining a discussion group with other beginners and experts ideally on discord.

If one exists then can someone let me know and dish out some links? Otherwise if you are interested maybe we can start one?"
264,dataanalysis,"Hi, I have been preparing for data analyst/business analyst role and this is my transition role as earlier I worked as software developer. Can anyone suggest me a place to practice mock interviews, both technical and behavioral?
Thanks in advance!!"
265,dataanalysis,"Is anyone taking the 8th course, the capstone project of Google Data Analytics? I need your kind help.  The mean of the trip duration/ ride length, for casual, is giving me an enormous mean (3X than members). Am I doing something wrong or all of you got the same mean? Kindly help. Thanks for reading through my problem.

&#x200B;

&#x200B;

[Mean in casual is enormous](https://preview.redd.it/lqji2fe1fcy61.png?width=365&format=png&auto=webp&s=f2751e89c7746ea80700a6d153692fa25ad2dce7)"
266,dataanalysis,"Recently saw ad for like 3 months or 10 month programs for DA certificates and got me thinking...

What are some major differences between a degree and a certificate?

Looking to add some DA knowledge and background to my accounting and CPA background. Would either a DA degree or certificate help me get bigger payday? Or is my background somewhat irrelevant for a DA role?"
267,dataanalysis,"Hey folks,

I'm in the process of building a fashion aggregation website as a portfolio piece. To obtain the data for this site, I have multiple scrapers for many of the largest fashion retailers in North America. 

To describe the data - one product can have many variants. e.g, 'Summer Dress' that comes in 3 colours and 8 sizes.  As such this product would have 24 variant products, the generic being the 'parent' product. Each variant may have different pricing, availability, sizing, colour etc.

My question concerns table construction - my scrapers output every variant of every product with their associated data, which can be in CSV or pandas DataFrame format. Can any of you tell me how I would go about populating two database tables from this data:

1. Table with the parent product, with foreign keys to each of its variants

2. All variant products of a parent product, linked to that product such that on my eventual website, they can all be found through searching the foreign keys of the parent product. 

I hope that makes sense, in a bit of a jam here. I'm not sure what to Google - even if you can't provide an answer, any points on even what to research would be of great help. 

TLDR: How do I populate 2 database tables with one CSV file, one table for the generic product, and one for all of its variant's fields?"
268,dataanalysis,"I've been messing around with this [task.To](https://task.To) clarify,I want to make 93 dataset fits into 90 dataset."
269,dataanalysis,"Hey, the work of data analysis has been considered by some people as something tha can become unethical, what do think? 

What line do you considere should not cross the human being in the use of data analysis?

What do you considere can be an ethical dilema in the world of data analysis?"
270,dataanalysis,"&#x200B;

Would this be a strong scale? How do you know?Â 

Are there any items that could be dropped to improve the scale? If so, which variables and how do you know?

https://preview.redd.it/120o4g6z91y61.png?width=1258&format=png&auto=webp&s=454660979cd13fda900229d6eb00518365e3964c"
271,dataanalysis,"Howdy,

Any recommendations for a US based 2-3 month course? I have a business background and intermediate coding experience. Iâ€™m looking to quickly get bootstrapped in the field.

Thanks!"
272,dataanalysis,"After working as a data analyst in various roles in the past 6 years I've realized that I don't like analyzing data. However, I do enjoy transforming/preparing/wrangling data and building dashboards. As long as I don't have to go like ""this is what the data says...."" I'm good.

I was wondering if it's possible to make a decent income with Fiverr/Upwork doing just the above. Or any other career recommendations for someone like me?"
273,dataanalysis,"your 21 years old, going to finish your master's degree in data analytics. What would you be your first priority? What would you do to achieve it?"
274,dataanalysis,"So my undergraduate degree is in law but I have no desire in becoming a lawyer (I've done internships at law offices etc and its just not for me). After a lot of thinking I realised that I really enjoy working with and processing data (I think kinda ironically a lot of my course work  I would work with a lot of data and make sense of it and then draw legal conclusions or apply it to different theories) so I would like to pursue a career in data analytics. But I have no idea where to start, I've tired searching the Internet but it's all kinda confusing. I have basic programming skills and have started a data science course on udemy (from kirill eremenko).

So my questions are:
- what courses should I take- are there any boot camp style courses that people have really enjoyed and found enriching? (I'm in Europe if that's relevant) 
- should I build and portfolio, how many pieces of work should I display if I do so?
- has anyone else managed a career transition and if so how did they do it?"
275,dataanalysis,"Ganna Pogrebna and Patrick Henz review the qualification and Portugal F1 2021 race from a data analytics point-of-view. We focus on (1) the internal team duels and discuss why this year is so tough for new drivers to establish themselves inside their teams. Furthermore, (2) we use natural language processing and sentiment analysisâ€‹ to show whether emotional loading of their commentaries can predict the outcome of the race. Enjoy! 

[https://youtu.be/Dm1e68io5xw](https://youtu.be/Dm1e68io5xw)"
276,dataanalysis,"I understand that you might be building a portfolio of case studies but have no idea what a ""business question"" of a particular dataset might be to build the analysis around. 

If you've found a dataset you're interested in analysing, then post the questions you're interested in asking and I'll tell you if I think it's a good question for a case study (it probably is!). Otherwise tell me more about the dataset.

What I need to know about the dataset is: What  it is, who collected it and what type of data it contains. Over what time period is also useful if there's DateTime data. 

Side note: I've been considering ""business questions"" for about 15 years so happy to give you my take ;)"
277,dataanalysis,"(Dumb question) I've been practicing data pre-processing and exploratory analysis, so what should I do next??"
278,dataanalysis,"short background:

*  I've been a data analyst for the past 8 years. The company revolved mainly around NLP, and ML
* It's not a ""classic analyst"" - no sql,  very little python. I mostly work with NLP dev and data scientists and analyze the models, their output and give insights on how to improve it
* I'm a linguist. I like the NLP and text analysis stuff :) 
* I've been learning python and sql on my own and I think I'm not bad and can do intermediate-level questions. I apply these tools in my job when I can, independently 

I got an offer with a 40% increase in salary for a data analysis role. It's in the security domain and would involve a lot of regex, which I will learn on site. I know the basics but the role would turn me into a regex master I guess. A nice skill to have, I don't know how useful though.

So, in closing, another non-classic analyst role, but it again touches on language, which I like.

I feel  like I'm already in a niche market, and this role would keep me there. On the other hand, breaking into the more mainstream positions would be a bit tough because I've never looked at this kind of data. I don't know if it will interest me. So I'm asking for a bunch of stranger on the internet for advice!

Would you stay in this niche? Where I live I didn't see many NLP analyst jobs. I am a bit worries that I'm boxing myself in. Would appreciate your thoughts! 

English is not mother tongue. I hope I'm clear."
279,dataanalysis,"Hi everyone, I have an associate's degree in data science and have experience with Python, R, SQL, Tableau, and more. I am having troubles finding work as most of the positions over here are for more advanced degrees so I have a few questions...

1. What's the best way to network in this field? I've had a few interviews but they wanted someone with experience and I'm entry level.

2. How can I make myself stand out against my competitors and those with higher degrees? I can perform the job descriptions with ease. A degree is just a degree. I have independent experience and knowledge backing me up.

3. What are some certifications/licenses that would be especially helpful? 

4. Do you have any job suggestions for me? If you're from the area and would like to chat or think you can help me out, let me know!"
280,dataanalysis,"I've worked in the sports consultancy industry for about 3 years and over that time have had some strong thoughts about how data analysis can and should be conducted more effectively.

I have created a community to test the idea of 'democratising analysis' and creating a freelance analyst economy.

Check it out r/TheAnalystEconomy

We are ultimately trying to create an environment where freelance analysts (potentially you) have the opportunity to earn an income by contributing to projects they find interesting.

At the very least you will get the opportunity to hone your skills on cool business problems and learn from a community of unique and interesting perspectives.

We are kicking things off with a project to build a crowd forecasting model for the AFL (Australian Football League).

Take a look at our community and join if you think it's something you'd enjoy. And feel free to share with any friends"
281,dataanalysis,"Hi, Iâ€™m finishing my google data analysis course and I have some questions. Iâ€™m originally from Belgium but moved to Puebla 6 months ago and I want to get started as a data analysts. I wanted to know how easily I could find a job in this department. Knowing that my Spanish is quite good (B2+/C1) but not my native languages. Also is there something else I should learn except Excel, Sql and Tableau?"
282,dataanalysis,"Hey!

What do you considere can be an ethical dilema in the world of data analysis?

What line do you considere should not cross the human being in the use of data analysis?"
283,dataanalysis," I have 2 different ranges of data.I'm aiming for scaling one fitting another.Note that each data in 2 dataset has it own value depending on time.As to say,First one has 90 dataset yet the second has 93.I want to make 93 fit in range of 90."
284,dataanalysis,"Hey guys, 

I just started my journey into Data Analysis. I am currently working on my bachelor degree. I currently have an associates in Business Management. Where is the best place to start I want to do some self teaching prior to jumping into school. Do you guys have any recommendations on any free sites that could help me learn required skills. Also any suggestions on some entry level positions that could help me in the future. Any advice would be greatly appreciated."
285,dataanalysis,"Hi,
I've been in my Python developer position for about two years but have been doing some reporting from a mariadb DB and a tool called Jaspersoft for most of it.

I want to go down the path of being a proper/professional data analyst/architect one day, but tbh, I don't feel like I've learnt a lot or enough to get a proper data analyst position.

My skills: Intermediate Python, Advanced MySQL, intermediate visualisation/reporting.

What are some courses or skills I can add onto here to get a proper data analyst position?"
286,dataanalysis,"Im 26, I recently got it together and about to finish my junior year at UW. I've been stressed about my major because I don't particularly want to be writing social media posts for a company I don't care about. I found out about Marketing Analytics and believe that this would be far more interesting for me to focus on. My school doesn't offer any data analytics classes within my major, currently, I'm in a marketing research class but it's very basic statistics that are all done with a program.

Recently I finished a digital marketing certification through Google. I was looking into data analytics certification (a sea of them), some are very expensive, my school offers a duo that would come out to over $4,000. While researching, the general consensus is that I should spend my time/money learning SQL, Phyton, Excel(pivot tables/VLookup) instead of a broad data analytics cert.

Does anybody have any advice? I think the best thing is experience but to gain that experience it looks like ill have to invest time into myself after class.

I'm hoping to have these in my back pocket so I can look for an internship which will have to be during my Senior year since I'm taking summer classes.

(I bought SQL and Phyton Bootcamp courses through Udemy for $50 total just as a starter and have linked learning through my school in which I'm taking an excel certification)"
287,dataanalysis,"Hi,

I moved to the states back in 2019. In EU, I was working in the iGaming industry as a Fraud Analyst but since I moved here, starting a new life on top of everything going on COVID and all, it's been a struggle to land a job. In the meantime, I recently started learning SQL by myself.

Although I have given some projects with HTML5, CSS3 and C# at collage, haven't used them since 2016, so it's a weakness. Now I am heavily considering to take [this course](https://www.pathstream.com/pages/continuing_nyu_tableau?utm_source=linkedin_pst_ta&utm_campaign=l1004_klik_pst_-_nyu_tableau_wv_tier-2_p_data-management-interests_c-s_-_-_-_no_ta_no_cpc_ty&utm_medium=cpc&utm_content=klik_01-06-2021_refresh_learn_le6_nyu-logo&s=nyu&c=tableau&li_fat_id=75ffe19d-421c-466c-a21a-07e4e7816bd5) provided by the collaboration of NYU Tandon School of Engineering, Tableau and Pathstream. 

The context and the structure of the program is appealing to me, and I honestly believe it would give me a good understanding of the full picture of the industry and provide a good start. And I found it affordable and potentially worth for money. 

I wonder if anyone here took this course, because I wasn't able to find any feedbacks online from the people who might have taken this course earlier. It starts on May 11th, hope to get some insight before that date.

I also found SQL's syntax easy to pick up, but to me, the hardest part would be visualizing the data structure you'd like to work on. So if anyone here already active in the field who doesn't mind sharing their thoughts, suggestions on this, please feel free to educate me. I know what I want but I have no idea where to start and where to move on. I am a goal oriented person so I'm just trying to draw a road map to myself then I can clearly see my progress and make sure I am not wasting my time or delaying anything. That's why I am considering investing in [this course](https://www.pathstream.com/pages/continuing_nyu_tableau?utm_source=linkedin_pst_ta&utm_campaign=l1004_klik_pst_-_nyu_tableau_wv_tier-2_p_data-management-interests_c-s_-_-_-_no_ta_no_cpc_ty&utm_medium=cpc&utm_content=klik_01-06-2021_refresh_learn_le6_nyu-logo&s=nyu&c=tableau&li_fat_id=75ffe19d-421c-466c-a21a-07e4e7816bd5) at the first place.

Best."
288,dataanalysis,"I'm going to have an interview with a company in the next couple of weeks that will focus on the technical aspects of the job. I'd be on a team of data analysts at a non-tech company. The main technical skills they highlight on the listing were Excel, Python, and Tableau (weirdly, not SQL). I've been told that there probably won't be live coding. I'm not sure exactly how I should prepare for this, or what kinds of questions they'll pose to gauge my proficiency without actually demonstrating it. If anyone has any advice I'd love to hear it! xo"
289,dataanalysis,"Did you learn / grow / develop / become more proficient as a data professional by:

[View Poll](https://www.reddit.com/poll/n4yjeu)"
290,dataanalysis,"We interviewed different people working in data engineering to talk about the future of the data analytics space. What was particularly interesting in this exercise was how differently those interviewed thought about the future of the space. We've ï»¿heard everything from streaming to cataloging to monitoring as future areas that teams believe will become front and center over the next five years. Below are the top three takeaways we had from the interviews presented in the report.

**Specialization will grow within the data team**

Most data engineers and data analysts are wearing many hats today. This is because the investment into the data team has only recently increased. As the value of data teams becomes more evident and more investment is placed in this department, data teams will specialize to focus on a particular function. This could mean having a reliability data engineer, a visualization lead, and a separation between backend and frontend data engineering teams. We believe these kinds of organizational changes will begin to take shape over the next 5 years.

**The ""data gap"" between data producers and consumers will shrink**

As more investment is directed towards self-service analytics, the gap between data consumers and data producers will continue to shrink. Tools that help teams centralize an understanding of data will become mandatory across all data teams. We've solved storing data, and moving data, as well as visualizing data. When we look at the challenges that a team faces today, the idea of self-serve analytics and understanding is the next largest issue.

**Data will become a product**

More data teams will adopt practices that help them ï»¿measure, manage and develop data like a product team. On the surface, this might mean a transition towards agile project management. At a more intricate level, this might mean transitioning towards data tools that enable cross-organization collaboration, version control, and monitoring. We believe that innovation in this area of data analytics will be interesting.

If you're interested in the future of data analytics and want to see the full transcripts, you can read the entire[ report here](https://www.secoda.co/the-future-of-data-analytics). If you're interested in the article with key takeaways, you can check it out here: [https://www.secoda.co/blog/future-of-data-engineering](https://www.secoda.co/blog/future-of-data-engineering)"
291,dataanalysis,"I have to work with several tables that have poorly or inconsistently named IDs, as well as no documentation to help determine what is what. 

Some things I've seen: 

* A table has ""id"" and ""idnumber"" fields and they are different numbers. 
* In a schema one table is ""thing"", the other is ""things"". Both have just ""id"" as the primary key
* A table has ""id"" and ""table\_id"" fields and they are different numbers. 

What are your opinions here? I prefer explicit naming and truly hate seeing ""id"" in any table. I've seen other discussions where it is preferred to use \`table.id\` syntax, as the table should tell you what the id is referencing. I think that's fine, except that sometimes the tables are also poorly named. Thoughts?"
292,dataanalysis," 

Hi there

I just started collecting information about my coffee consumption because I know it is way to much.

I set up a simple google sheet and put the information I could think of.

I'm collecting data on the sum of normal and decaf cups I have and I want to see the progression of change and maybe in a year see the change.

Do you have any tips or ideas on how I could improve this?

My friend talked about Power BI but I know nothing about it.

Do you know of any tools I could use that's better than sheets?

All feedback appreciated!

&#x200B;

&#x200B;

https://preview.redd.it/4t464zba63x61.png?width=2496&format=png&auto=webp&s=8c0d66d89c9ca859cf18872f768307e49077f3c9"
293,dataanalysis,"Hi all, I am a software developer with about 3 year of experience now and now i am fed up with the kind of work that i am doing, so i made up my mind to transition into analytics role but confused among Business analyst or Data analyst. Please help me with some clarifications."
294,dataanalysis,"Hello guys. I am learning Python (&SQL of course) with Data Camp's Data Analyst career track. I have no intention, at least for now, to be a Data Scientist. So I thought it would be unwise for me to learn too much about code. 

Should I learn visualization tool like Power Bi instead of focus only on Python's dataviz libraries? The JDs of data analyst job usually list those tools. 

Thanks in advance!"
295,dataanalysis,"I'm currently in a migration role, mostly using VBA with a tiny bit of basic SQL. 

I quite like data analysis and are wanting to make the move early next year. 

I gather I need to know Power BI, PowerQuery, PowerPivot, Tableau and Python. 

Questions: How well do I need to know these products, and how many hours a week should I be studying if I want to make the move in 9 months time? Or is a lot of the learning done on the job?

Cheers"
296,dataanalysis,"Hi, everybody, I want to develop a new dataset software, and I want to know what do you need in a dataset software, what do you think is missing in the dataset programs? what are the things that you hate in these programs and you hope that they could be fixed?. I'll be so grateful if you helped me and give me some ideas ðŸ¤—"
297,dataanalysis,"Hi guys, is there any news api that gives access to all the content for developers? i need it for my course final project"
298,dataanalysis,"There are local elections running in the UK. Being disillusioned with the state of our local town and politics. I needed a way to understand the candidates better so I can vote for someone who is closest to the ideal candidate I would have liked to see.

So far 9 of them have answered my questions. What are some interesting ways to analyse this qualitative data?

Here are the results, btw:

[https://www.notion.so/Councillor-Candidate-Interaction-52770c9557c34c6abdd93b74f096c253](https://www.notion.so/Councillor-Candidate-Interaction-52770c9557c34c6abdd93b74f096c253)"
299,dataanalysis,"Can you become a data analyst with a degree in humanities, with completion of a course on data analytics?"
300,dataanalysis,"Hope this is the best place to post this question. 

I have a problem that Iâ€™m looking to model. Iâ€™m looking to determine the probability of a surgery resident performing a particular procedure 40 times within 5 years. 

There are 5 residents in each year, 25 total. Priority goes to the more senior residents and I know the OR of each level getting the case from historical data. Every year that passes, 5 senior residents leave and 5 new residents enter. The number of available cases varies every year and I have over a decade of those data as well. Lastly, when a resident achieves the required number, they continue to do those cases. However, they try to give them to others who donâ€™t have enough and theyâ€™re less likely to perform them than their seniority cohorts who havenâ€™t gotten their numbers yet. 

I want to know the likelihood of a resident finishing with the required number and if all will achieve the required number, the likelihood by year of achieving it. 

I have a some experience in data modeling but Iâ€™m having trouble breaking this problem down properly. Would greatly appreciate some guidance. Thanks!"
301,dataanalysis,"Hey guys,

Im struggling hard with my SPSS analysis for my thesis, and I'm desperate to succeed my thesis. I'm looking for someone whos clever with SPSS, and could help out this student :D. 

I have a dataset, and I know what the plan/analysis is, but just cannot figure out how to do this. Please respond or contact me if you're good with SPSS and would like to help out. I can share the datafile and syntax. Would be so helpful and so kind!! Thanks in advance.. :)"
302,dataanalysis,"I have a bachelor degree in Statistics, specializing in Computer Science and graduated about 2 years ago.

A year ago I land on a job where it is more relevant to my skills (somewhat SQL, somewhat reporting and somewhat web dev) and so far I am burning out at work. Disorganized and misleading management seems to be a problem at work (oh, there it is, my analytical skills haha..) - hence I didn't get a chance to use R or Python or Powerbi but have been using Excel most of the time. Which I still learn a lot but at the same time, is frustrating as I have to lead the set up.

I am thinking to move away from my position as I feel drowning to the hole where I have to fix the relays of problems at this company but when I often see other job descriptions for data analyst - ""Excellent Communication"" is the only part that freaks me out.

My colleagues and my family are saying my English is fine but what I need to know is if I am sufficient for the professional level. But what level exactly? Maybe if I can see the example of reports in business it would be helpful to know. Or is there anyone out there similar to my situation who became a data analyst?

Much appreciate for your support."
303,Python,"Tell /r/python what you're working on this week! You can be bragging, grousing, sharing your passion, or explaining your pain. Talk about your current project or your pet project; whatever you want to share."
304,Python,Comment any project ideas beginner or advanced in this thread for others to give a try! If you complete one make sure to reply to the comment with how you found it and attach some source code!
305,Python,"I was wondering if there is a scenario where you would actually need BeautifulSoup. IMHO you can do with Selenium as much and even more than with BS, and Selenium is easier, at least for me. But if people use it there must be a reason, right?"
306,Python,"I just one day realized that with all these colorful Adobe icons, I thought I could create a colored image with them. The final code came out quite simple, but I spent days finding the best method for selecting the most similar-colored icon.

Here's an example of the Mona Lisa

[Mona Lisa in adobe icons](https://preview.redd.it/4r5bhmma4iz61.png?width=800&format=png&auto=webp&s=4edad4301b44ca05dd9fc05d314eeb03f3980558)

I also rendered a video by splitting a video in frames using a video editing tool, converting each frame using the script, then combining them together using the video editing tool again.

Here's an example of a conversion of the Japanese animation demon slayer.

[https://youtu.be/weQpX3cdDYg](https://youtu.be/weQpX3cdDYg)

My current problem is finding the right icon for low-hue colors. Currently for hue>=20 colors, I use the hue-difference method and for hue<20 colors, I choose among the grayish icons depending on the brightness. I've been trying different methods using hue, saturation, and brightness, but I wasn't able to find the solution yet. I'm not an expert in colors, so if anyone could check the code and give me some advice, I'd be happy about it.

Github

[https://github.com/cxhuy/image2adobe](https://github.com/cxhuy/image2adobe)"
307,Python,"I'm really happy that so many of you decided to contribute to the code, and make this a better trading tool. The project is open source of course, and anyone can run the bot on their machine :)

The bot was built to look at all the coins on Binance and pick the most volatile ones in a given timeframe, in order to automatically buy the ones which are likely to keep increasing in price in the short-term at least.

Here's more detailed breakdown of the main configuration:

* The bot will listen to changes in price across all Coins on Binance paired to USDT
* By default Margin (like BTCDOWNUSDT) and Fiat pairs are excluded
* The bot checks if the any coin has gone up by more than 3% in the last minute
* The bot will buy 15 USDT of the most volatile coins on Binance
* The bot will sell at 2% profit or 2% stop loss

Now all these configurations above are customisable, you can input any values you like it you are interested in trying out a different strategy.

The dev community has contributed with some more major updates like:

* Trailing stop loss - the stop loss will move up and follow the price -2% (configurable), which essentially allows the bot to maximise the profit in a bull run, as long as it continues
* Better testing - the bot is able so simulate real-life trades and store the output in a file to determine whether your configuration is profitable.

If you are interested in testing, using or contributing to the code here is the official GitHub Repo:

[https://github.com/CyberPunkMetalHead/Binance-volatility-trading-bot](https://github.com/CyberPunkMetalHead/Binance-volatility-trading-bot)

For a step-by-step guide on how to install and configure this bot for personal use: [https://www.cryptomaton.org/2021/05/16/trailing-stop-loss-and-more-improvements-added-to-the-binance-volatility-trading-bot/](https://www.cryptomaton.org/2021/05/16/trailing-stop-loss-and-more-improvements-added-to-the-binance-volatility-trading-bot/)

Thanks again to everyone getting involved in this!"
308,Python,"I also hardcoded the raw bytes of all of the images so that the program can run completely independent of any other file, in one line.

[https:\/\/github.com\/Boss68\/Flappy-Bird-written-entirely-in-one-line-of-python](https://reddit.com/link/nd76nk/video/dje7ta8pacz61/player)"
309,Python,"https://github.com/shersonb/python-ciqueue

I have made use of Pythonâ€™s queue module in a lot of my projects involving multiple threads.

One of the things that is currently difficult is the ability to break all threads waiting to get an item from a queue.

The .close() method allows for us to unblock (and raise the Closed exception within) all threads waiting to get items from a queue once it is empty, after reaching a point where no more items are to be put into the queue. This will also prevent putting further items from being put into the queue, and instead will raise the Closed exception.

The .interrupt() method causes *all* threads either putting or getting items to unblock and raise the Interrupted exception in the event an exception occurs."
310,Python,"Like only Bruce Lee can use a nunchaku perfectly, only senior Python developers can use the eval() function properly.

More details: [The Eval Function in Python](https://medium.com/techtofreedom/the-eval-function-in-python-a-powerful-but-dangerous-weapon-ba44e39fa9e2)"
311,Python,"**TL;DR**: Download book for free [here](https://gumroad.com/l/pydonts/w99ucle), leave honest feedback below.

Hey there, Reddit.

So, I have been working on a Python book about writing elegant Python code. This book takes a series of articles I publish weekly on my blog (https://mathspp.com/blog/pydonts) and compiles them into a book format, for convenience and ease of access to all of the information.

I am still publishing articles on that series, and, therefore, the book is still growing. I have had some nice feedback from the community (i.e., from people like you) but I'm looking for something more.

I would like you to give me your most honest feedback on everything related to the book, but especially about:
 - the book cover
 - the book description on the sites
 - the book font and overall layout
 - the content of the chapters

When giving feedback, feel free to say what/how you feel about X, Y, or Z, and, if possible, say what you would have done differently.
I appreciate that most people have different opinions regarding many different subjects and that is what I want: exposure to many different opinions.
Naturally, I will agree with some people and disagree with other people, but if your critique is honest and comes from a good place (even if it is a bad critique) it will be helpful because it will make me think about how I am doing things.

Hopefully, if enough people go through the trouble of giving some honest feedback, I might be able to spot major flaws on my work and fix them _while_ the book is still being written.

You can get the book from Leanpub or Gumroad, but currently I'm giving away the book for free on Gumroad ([https://gumroad.com/l/pydonts/w99ucle](https://gumroad.com/l/pydonts/w99ucle)) so that you do not have to spend your money to help me out.

Thanks a lot for your time!"
312,Python,"At a basic level, this program will interface with your Spotify active device and modify (add to) your queue. This python project utilizes Spotipy which enables use of python to interface with the Spotify API.

DiscoveryQueue works by having you provide a Starting Artist and then it adds the top songs from the Related Artists of your designated Starting Artist to your queue. I frequently utilized this method of song discovery (by sifting through related artists) and really wanted to find a way to automate the process. DiscoveryQueue is just that! Although I may be a bit biased, I have found that DiscoveryQueue has made my playlists much more unique, deep, and enjoyable. All while requiring me to put in less work than I previously did for similar results.

I hope that you find it equally as useful and easy to use!

You can access the files/code and outline of how to use the program via: [***https://github.com/malakosss/DiscoveryQueue***](https://github.com/malakosss/DiscoveryQueue)

***To use the program, just download the .zip file that is labelled with Windows or macOS depending on your operating system!***"
313,Python,"In the last weeks I created some Python Short-Videos on YouTube ([https://www.youtube.com/watch?v=duc4gvUlZqE](https://www.youtube.com/watch?v=duc4gvUlZqE)) . That means, one video is not longer than 20-25 seconds. I thought it might be useful for some of you.

My approach is rather radical, using mostly just 10-20 seconds to show some interesting aspect of Python, or some interesting program for beginners.

My goal in each video is to introduce a particular aspect of Python, and to limit myself to the most necessary, and I make it a point to let the viewer think for themselves as they watch. So they are not meant to be classic tutorials.

Do you find the videos interesting? Do you have any suggestions?

What are your predictions for the future? Will 10-seconds-videos trend soon reach the education sector as well?

Of course I would be happy about feedback.

(Sorry, this was already posted in r/learnprogramming, but I thought, this could be useful expecially for you)"
314,Python,"On [Bite Size Data Science](https://www.patreon.com/BiteSizeDataScience) (a Patreon site) you will find monthly educational and inspirational Jupyter notebooks using Python, with exercises (and solution scripts), and you also support open source software (through NumFOCUS)! Upcoming topics are:

\- Declarative and Interactive plotting  
\- Dissecting decision trees  
\- Beyond just recognizing hand-written digits  
\- Function inception and magic  
\- Why logistic regression is a linear model  
\- Pipelines to automate your workflow  
\- What to put in your BAGG and which models to boost  
\- Gaussian Processes for arbitrary function fitting  
\- Numpy broadcasting and ufuncs put to use for heavy lifting  
\- Protecting yourself from overfitting  
\- Climbing the learning curve of learning curves  
\- Getting lost in a jungle of loss functions  
\- Regression and classification are the same thing  
\- Time series decomposition and forecasting  
\- Outlier detection by hand and with a toolkit"
315,Python,"Hey Python-friends,

In the last couple of weeks I worked on a small side project combining Space Science and Machine Learning.

Background: As a former Solar System scientist I still like to work on astronomy topics in my free time. My main focus: Asteroids, Near-Earth Objects, Comets, Cosmic Dust and Meteors. So basically everything that is rocky or icy.

Asteroids appear like dots in a telescope. If they approach our planet quite close one can use radars to determine their size and shape quite well. The rest of the time scientists can ""only"" determine their brightness, indirectly their size, and orbit around the Sun (and other intrinsic parameters). That's it!

But one can also determine the spectrum of an asteroid: E.g., by determining the reflectance of the surface for different wavelengths. These reflectance spectra allow scientists to determine the composition of the object. In total, there are 4 ""main groups"":

* C: Carbonaceous Asteroid, most common in the Solar System with... well you guess it, carbon-like compositions
* S: ... like ""stony"" asteroids, silicates, minerals, etc. dominate the surface
* X: -class asteroids are mostly classified as ""iron"" asteroids (no these are not pure ""iron rocks"" but show a high abundance of iron, nickel, etc.
* Other: Outliers with rare or unique compositions

These main groups are the most common ones. Other classification systems by Bus et al., Tholen et al. and so on (I spare you with the details) introduce more classes and differentiate them to up to 20 classes and more.

Why am I telling you this? Well I was thinking: Bus et al. classified over 1200 spectra by hand (20 years ago). Why not testing Machine Learning algorithms on these data for classification purposes? And that's what I did. In the GitHub repo that is shown below, several Jupyter Notebooks are stored starting from fetching and parsing the data, to trainings of multi class Support Vector Machines (SVMs) using scikit-learn.

Further, I programmed a small Feed-Forward and 1D Convolutional Neural Network using Keras to compress the spectra to a 2-dimensional space, to see whether ""spectra clusters"" appear that can be associated with these arbitrary classification schemas. Small videos of these clusters can be seen on my [Twitter post](https://twitter.com/MrAstroThomas/status/1393191707710271489); however these interactive plotting routines are all available in the corresponding scripts.

[The GitHub Repository](https://github.com/ThomasAlbin/sandbox/tree/main/asteroid_taxonomy)

*What is the long-term goal of this project and the ""sandbox projects"" in general?* In June I would like to show the results on a space science conference. Further, I am developing a Solar System Python library that focuses on Small Bodies (Asteroids, etc.) that could be used by students and also by myself for my Medium tutorials (and also future YT tutorials). I think that enthusiastic Python developers and free-time data scientists and citizen scientists could improve, support and boost the scientific community with great ideas and Open Source solutions.

I hope you all do well during these challenging times and find some calm moments for projects and your hobbies,

Thomas"
316,Python,"**What is it?**  
Reviews is a terminal UI Dashboard for monitoring requests for code review across several Github repositories and pull requests.   


**What does it look like?**

https://preview.redd.it/aa9i4yx1i9z61.png?width=1915&format=png&auto=webp&s=55468a9cea99edff1a8c1c260ec776e8e2177280

**How to use it?**  


You can install it directly from PyPi and configure it to use and provide your configuration like so

`pip install reviews`  


The following is example configuration for the TUI:

`export GITHUB_TOKEN=""your-token-here""`  
`export GITHUB_USER=""apoclyps""`  
`export REPOSITORY_CONFIGURATION=""apoclyps/micropython-by-example,apoclyps/reviews,apoclyps/magic-home,datadog/dd-trace-py""`  


Once configured you can run it from your terminal using:

`reviews dashboard --no-reload`  


**How to get involved?**

The code is available on Github [https://github.com/apoclyps/reviews](https://github.com/apoclyps/reviews) and there is a small video demo on the repository. You can install and use it from PyPI: [https://pypi.org/project/reviews/](https://pypi.org/project/reviews/)

I've also created a number of an issue for first-time contributors, but I'm open to anyone creating a feature request for anything they would like to add. I'm always happy to receive feedback to improve reviews.

**#python #cli #pypi #github #codereview**"
317,Python,"Why Do I Learn Python?

Python is an easy language with simple syntax. Python is becoming popular day by day as it is the major backbone of new technologies like data science, machine learning, and artificial intelligence. So several educational websites are offering the best Python courses.

[https://techarge.in/getting-started-with-python/](https://techarge.in/getting-started-with-python/)"
318,Python,"Hi all! this is my first public repo on Github after starting to learn python a few months ago and I am quite excited :)

It's a simple script that that can send an email update on the daily performance of a Binance crypto wallet.

It takes:

\- Binance API details (key and secret)

\- email details (sender email, sender email password, sender smtp server, and recipient email)

and sends an email with how much the wallet is worth now, how much it was worth 24 hours ago and the % increase/decrease

I flaired it as intermediate as I think it's a bit more than basic but you guys let me know.

&#x200B;

[https://github.com/MarcoMiki/WalletUpdates](https://github.com/MarcoMiki/WalletUpdates)

&#x200B;

Note that if you wish to use a gmail to send the email you need to enable less secure apps access for that Google profile. More info here: [https://support.google.com/accounts/answer/6010255](https://support.google.com/accounts/answer/6010255) (You may want to create a dummy gmail for this purpose)"
319,Python,"Hey /r/Python!

We just had an interview with Neeraj, the technical co-founder of [Bugout.dev](https://Bugout.dev) and I thought /r/Python might be interested in reading it, since a lot of the Bugout tooling is written in Python!

We talked about how he met his cofounder, how his grandmother influenced his decision to become a software engineer, why he and his co-founder started Bugout, and why he loves Python!

You can read the interview [here](https://console.substack.com/p/console-53?r=3cbez&utm_campaign=post&utm_medium=web&utm_source=copy), and it also includes a link out to one of their GitHub repos."
320,Python,"Hello!

This is my first post on r/Python, I recently decided that I wanted a calculator in the terminal that works interactively and most importantly: visually displays the equations using Unicode characters!

You can find the source code on [the GitHub page](https://github.com/timeopochin/ilo-nanpa.git) :)

I chose [RPN](https://en.m.wikipedia.org/wiki/Reverse_Polish_notation) to input the equations. I am pretty proud of this project that is still in its infancy, mostly because I think it has potential for being a tool that I use regularly."
321,Python,"  

https://preview.redd.it/35xjl5il5gz61.png?width=5334&format=png&auto=webp&s=fb174b56299df1557e267c80b11c662061cbf782

Hi,

This is a the first part of a step by tutorial , that explain how to detect a full body landmark and estimate the position

The is tutorial elaborated include full example from the beginning till a full working process , and demonstrate how to control a game using your body and hands.

This tutorial is based on Python, OpenCV , and Mediapipe

I added a link for the code in the video description, so you can download and enjoy 

The link for the video is : [https://youtu.be/UarMb\_12udw](https://youtu.be/UarMb_12udw)

The link for the code is : [https://github.com/feitgemel/BodyPos/tree/master/MediaPipe/Holistic](https://github.com/feitgemel/BodyPos/tree/master/MediaPipe/Holistic)

Eran"
322,Python,You can look at the [README](https://github.com/timeopochin/GanTTY.git) on the GitHub repository to see it in action :)
323,Python,"Hey everyone, 

I created a Python SDK for the Tiingo Financial Markets API. It supports interfacing with the REST Endpoints of Tiingo's API and outputs data in JSON and Pandas formats. I'll be adding Websocket support as well in the very near future. 

Please star and give it a try at [https://github.com/philipk19238/pytiingo](https://github.com/philipk19238/pytiingo)

Regarding Tiingo, I wholeheartedly believe that it is one of the best options for obtaining financial data. I have no connections to the firm but here are what I believe to be its strongest value propositions: 

* Very generous free tier (500 requests per hour, 20,00 requests per day)
* Historical & Real-time data for equities, cryptocurrencies, and currencies 
* Websocket access to firehose data, can stream live data that update by the nanosecond 
* Accuracy - they have a propriety error checking framework 

Give it a try at [https://api.tiingo.com/](https://api.tiingo.com/)"
324,Python,"hello dear Experts 

&#x200B;

good day - i am doing some tests with SoupStrainer -  and want to see what is getting back with 

this great option to get back links out of a HTML-page. 

&#x200B;

    import requests 
    from bs4 import BeautifulSoup, SoupStrainer
    
    content = requests.get('https://www.google.com').content
    
    for link in BeautifulSoup(content, parse_only=SoupStrainer('a')):
      if hasattr(link, ""href""):
        print(link['href'])
    

&#x200B;

note: i only want to have the links that are in bold tags

&#x200B;

all with a bold tag: 

    
    <li><b><a href=""linkitem_a.html"">linkitem_a</a></b> {bla_bla_a} (bla_bla_a), apple_crumble
    </li>
    <li><a href=""linkitem_b.html"">linkitem_b</a> {bla_bla_b} (bla_bla_b), apple_crumble
    </li>
    <li><b><a href=""linkitem_c.html"">linkitem_c</a></b> {bla_bla_c} (bla_bla_c), apple_crumble"
325,Python,"Hi guys,

Maybe this is a post for r/learnpython but I was unable to get the advice I needed from there.

I'm looking to set up a file observer to trigger a script every time an event happens in that file. I have tried to use watchdog but am having difficulties and was wondering if there is a way to do this through the terminal? Here is the script:

    import os
    from shutil import move
    import re
    
    user = os.getenv(""USER"") # Get USER
    root_dir = f'/Users/{user}/Desktop/' # root directory with screensots
    target_dir = f'/Users/{user}/Documents/Screenshots' # Target directory for screenshots
    
    regex = ""Screen Shot"" # Regex to check whether a screen shot or not
    
    def move_files(root_dir, target_dir):
        
        for file in os.listdir(root_dir): # iterate files in root directory
            if re.match(regex, file) != None: # use regex to check whether a screenshot or not
                file = root_dir + file # Create full source path 
                move(file, target_dir) # Move to target_dir
                
    move_files(root_dir, target_dir)

Any advice would be great, thanks!"
326,Python,"A while ago, I posted here about [pyHanko's 0.1.0 release](https://www.reddit.com/r/Python/comments/kn1alp/pyhanko_pdf_signatures_in_python/). Since then, pyHanko has matured quite a bit, both in terms of new features and general robustness; see the [long list of changes](https://pyhanko.readthedocs.io/en/latest/changelog.html) in the documentation. We're not quite ready for a `1.0.0` release yet, but I believe that that's not too far off now. [Feedback](https://github.com/MatthiasValvekens/pyHanko/issues) from the community has been extremely valuable in the development process, so thanks to all of you who filed issues!

[PyHanko](https://github.com/MatthiasValvekens/pyHanko) is a Python PDF signing library released under the MIT license, with the ultimate (and rather ambitious) goal to cover all digital signing features of the PDF standard as completely as possible, while at the same time offering a fairly simple CLI to perform basic signing and validation tasks.
It functions both as a Python library for handling common signing & validation tasks, and as a command-line tool. The CLI was built using [Click](https://github.com/pallets/click), so it comes with a built-in help function.

Here are some of the things that changed between version 0.1.0 and 0.6.0:

 * RSASSA-PSS support.
 * Support all document encryption schemes in PDF 2.0.
 * Major improvements to the PKCS#11 integration.
 * Greatly improved incremental update analysis for validating documents with multiple signatures.
 * Better support for remote signing services (""some assembly required"", as they say: you still have to write some integration code yourself)
 * [Certomancer](https://github.com/MatthiasValvekens/certomancer) for automated PKI testing (this doesn't affect you as a user, but it has definitely made iterating on test code a whole lot easier).
 * Migrated to [cryptography](https://github.com/pyca/cryptography) as the main crypto dependency; [oscrypto](https://github.com/wbond/oscrypto) is still used as a back-up for some legacy corner cases.
 * Tons and tons of bug fixes & minor enhancements.

See [the GitHub readme](https://github.com/MatthiasValvekens/pyHanko) for a brief overview of the feature set. More documentation is available on [ReadTheDocs](https://pyhanko.readthedocs.io/en/latest/). The documentation covers both the library and the CLI.

Releases are published on [GitHub](https://github.com/MatthiasValvekens/pyHanko/releases) and on [PyPI](https://pypi.org/project/pyHanko/)."
327,Python,"In the past months, I have been busy creating a library to make it easier to profile and test your Python code for performance issues. For more information about the project, I would suggest checking out my GitHub repository.

[https://github.com/JoeyHendricks/QuickPotato](https://github.com/JoeyHendricks/QuickPotato)

Because performance results are complicated I have created powerful interactive visualization to find performance bottlenecks easier. 

I would like to know from other Python developers which visualization I could add next to the project and increase its analytic capabilities?"
328,Python,"Heap is a tree-based data structure that is useful in maintaining queue of items according to their priorities ðŸ› 

I have recently written a blog post about heaps, their properties and applications:

[https://www.romaglushko.com/blog/heapify/](https://www.romaglushko.com/blog/heapify/)

The article contains a lot of visualizations and could be a good way to understand how heaps work, especially for beginners. Also, heap is a popular topic on coding interviews.

Hope it'll be helpful ðŸ™Œ"
329,Python,"I started this as a project to help me get better with Python, but it became unexpectedly elaborate. I've been working on it for more than a month, and it's now jam-packed with a ton of features.

Deezer and SoundCloud downloads are free, but you need an account for Qobuz and Tidal. If you guys have any suggestions for improvements, or questions about the development/learning process, let me know and I'd be happy to answer.

Github: [https://github.com/nathom/streamrip](https://github.com/nathom/streamrip)"
330,Python,"Dear community,

Disclaimer: I own the course I will post here. I *looked up the community rules*, and it doesn't seem to disallow posts about free courses. I am sharing this course 100% free for the next 2 days. I hope I don't break any of the community rules (if so please kindly let me know).

The course is for the absolute beginner! You will learn the basics of programming with Python and develop small projects. If you know nothing about Python and programming then this course is for you. It will walk you through some basic theory and teach you step by step how to think like a programmer.

Here is the link: [https://www.udemy.com/course/learn-to-think-and-act-like-a-programmer-using-python/?couponCode=MAYD21](https://www.udemy.com/course/learn-to-think-and-act-like-a-programmer-using-python/?couponCode=MAYD21) (EDIT: The free code unfortunately has now expired, but you can use MAYD21 for a discount if you want to).

I hope you will find this useful! Feel free to share it with anyone you like.

Please stay safe!"
331,Python,"Hello!

It's my first post in r/Python. I'm maded application for lead-generation. This app generation possible email's and validating. If you don't intrested at lead generation, you can just see, this app so intresting.

You can see more [here](https://github.com/gylah-u/lead-generating-email)."
332,Python,"\[self-promotion post\]

There are a lot of ""how to write 2048 game"" tutorials, however, the process of developing game agents for the 2048 game is also challenging

I would like to present the [https://code2048ga.me/](https://code2048ga.me/) where you can try to create your own game agent for this game using Python. Your goal is to write a function that returns swipe direction depends on the game field state and at the end achieve the best possible score/tile

https://reddit.com/link/ncz4gc/video/c4102va1faz61/player

The problem is open-ended and could be interesting not only for beginners. One of the simple python solution (simple ""priority strategy"") for the inspiration: [https://pastebin.com/nfxN6zzZ](https://pastebin.com/nfxN6zzZ)"
333,Python,"Hello Developers, 

I've prepared a sample Dockerized flask app deployed on Kubernetes on Azure using AKS!

[https://github.com/ahmedkhemiri95/flask-app-kubernetes](https://github.com/ahmedkhemiri95/flask-app-kubernetes)

You can run application in different ways :

1. As standalone app.

2. As a Docker container running on your machine

3. Run flask-app-kubernetes repo from Docker Hub : [https://hub.docker.com/.../ahmedkhem.../flask-app-kubernetes](https://hub.docker.com/repository/docker/ahmedkhemiri24/flask-app-kubernetes?fbclid=IwAR2dfnd4yHgFRoasdsv_pZXnPs57c_sizC7L_4QY-ShqTGokG2otuzlaZWU)"
334,Python,"&#x200B;

You need to familiar with only one thing to remove square braces from a list. (i.e; .replace() function)

Removing braces from a list can be mind boggling, you can find difficulty while removing braces as you use list to store various characters of different data types, but you want to show your elements without without brackets and inverted commas. So be Patience and read the [full article :-](https://techedushark.blogspot.com/2021/05/remove-square-braces-from-list-in-python.html)"
335,Python,"This is a quick cheatsheet for list comprehension 

https://preview.redd.it/67auw33yc8z61.png?width=673&format=png&auto=webp&s=b5f2f663d9e4ed956c68568c4fb1ec6375b266f1

The above is the same as:

`temp = []`

`for num in list_of_numbers:`

  `temp.append( num * 2 )`

`Result = temp`

&#x200B;

If anyone is interested, I have a full article here about this: 

[https://pythonhowtoprogram.com/how-list-comprehension-works-in-python-3/](https://pythonhowtoprogram.com/how-list-comprehension-works-in-python-3/)"
336,Python,"**Hey everyone I wrote an article on how you can convert any pdf file into audiobook using Python and also playing it inside the program.**

**We are creating a GUI to select any pdf file user want and then read all the pages for him/her.**

  
**Check it out and drop your valuable feedback and suggestions ðŸŒ»**

[dev.to link](https://dev.to/_s_w_a_y_a_m_/how-to-convert-pdf-file-into-an-audiobook-5b62)

[hashnode link](https://swayam-blog.hashnode.dev/how-to-convert-pdf-file-into-an-audiobook)"
337,Python,"Do cheek it out , if out are beginner in python, it is pretty hands on lab with explaining every line of code , there is not much of code to worry about. 

[https://github.com/SeedML/Python-Basics-/blob/main/1-python\_Basic\_%26\_Data\_Types.ipynb](https://github.com/SeedML/Python-Basics-/blob/main/1-python_Basic_%26_Data_Types.ipynb)"
338,Python," The objective of the project is to predict the hotel booking status of the guest if it'll be canceled or not based on the various features like ADR (Average Daily Rate), booking changes, lead time, type of the hotel booked, and more. The type of hotels given in the dataset is  Resort Hotels and City Hotels. This is a data science project done using Python.

[Kaggle Notebook](https://www.kaggle.com/sumitm004/eda-sa-and-hotel-booking-cancellation-prediction)"
339,Python,"The library serves useful and stylish widgets to speed up the development process while having a good loking UI! It can be used with PySide2 as well with just small changes.  


GitHub Repo: [https://github.com/kadir014/pyqt5-custom-widgets](https://github.com/kadir014/pyqt5-custom-widgets)  


&#x200B;

https://preview.redd.it/gpbtf4glg5z61.png?width=900&format=png&auto=webp&s=3ba23b36b08cb591a420a94246cbc6ac738bbdd0"
340,Python,"// For the whole script and detailed explanations follow the [GitHub Link](https://github.com/lazymazyjazzy/Stock-Analysis-wML). //

Table Of Content

* [General Info for ML Model of Predicting TUPRS.IS Stock Prices](https://github.com/lazymazyjazzy/Stock-Analysis-wML#general-info-for-ml-model-of-predicting-tuprsis-stock-prices)
* [Quick Look On Real World Data Frame and Graphs](https://github.com/lazymazyjazzy/Stock-Analysis-wML#quick-look-on-real-world-data-frame-and-graphs)
* [Machine Learning Model and Predictions for Different Variables](https://github.com/lazymazyjazzy/Stock-Analysis-wML#machine-learning-model-and-predictions-for-different-variables)
* [Effects of Other Variables on Stock Prices](https://github.com/lazymazyjazzy/Stock-Analysis-wML#effects-of-other-variables-on-stock-prices)

## General Info for ML Model of Predicting TUPRS.IS Stock Prices

[TUPRS-IS](https://finance.yahoo.com/quote/TUPRS.IS?p=TUPRS.IS&.tsrc=fin-srch) is a stock that you can buy globally, belongs to TUPRAS Turkiye Petroleum Refineries which is one of the biggest companies in Turkey with the market cap around 24,5 B.

[TUPRS.IS Stock Overview](https://preview.redd.it/1wwtcf1a13z61.png?width=1866&format=png&auto=webp&s=5c17f66ad725302ab6ce328c61c372f5d1988b72)

This machine learning model is created for observing the effects of following criterias on TUPRS.IS stock market price;

* TUPRS.IS Stock Market Volume
* [Crude Oil Prices in USD](https://finance.yahoo.com/quote/CL=F?p=CL=F&.tsrc=fin-srch)
* Crude Oil Volume
* [USD/EUR Currency Rate](https://finance.yahoo.com/quote/EUR=X?p=EUR=X&.tsrc=fin-srch)
* [USD/TRY Currency Rate](https://finance.yahoo.com/quote/TRY=X?p=TRY=X&.tsrc=fin-srch)
* [Turkish Monthly Inflation Rates](https://www.tcmb.gov.tr/wps/wcm/connect/EN/TCMB+EN/Main+Menu/Statistics/Inflation+Data)

Since it is a Turkish company, USD/TRY currency is also evaluated along with the inflation rates.

All data provided for the model is scraped through web, and features are pre-processed within the script I wrote. You can directly copy the script and run if you have necessary libraries.

For Yahoo Finance scraping, I've used a class written in [Stack Overflow by Mike-D](https://stackoverflow.com/questions/44225771/scraping-historical-data-from-yahoo-finance-with-python). Yahoo Finance provides the historical data in infinite scrolling format. It is really hard to scrape through with classical BS4 and lxml.

https://preview.redd.it/72ol7c9f13z61.png?width=1050&format=png&auto=webp&s=587e68282884edd3e771f959998383f4c135fa45

Versions for the libraries I've used; jupyter==1.0.0, lxml==4.5.1, MarkupSafe==1.1.1, matplotlib==3.3.2, notebook==6.0.3, numpy==1.18.1, openpyxl==3.0.4, pandas==1.1.2, Pillow==7.2.0, scikit-learn==0.23.2, scipy==1.4.1, seaborn==0.11.0, SQLAlchemy==1.3.18.

&#x200B;

https://preview.redd.it/gijohybh13z61.png?width=1008&format=png&auto=webp&s=4f5a0cd8f5295100de4517ffb80b65c1609bda89

## Quick Look On Real World Data Frame and Graphs

This was the head(first few lines) of core dataframe I've used after scraping to provide graphs etc. There were around 5k rows, having the data from 2005 to today.

&#x200B;

[DF After Scraping](https://preview.redd.it/geqsoxpi13z61.png?width=1668&format=png&auto=webp&s=d8d1d2ab8cc93ab31d050c0b4c900e5ab46f0132)

### Let's check some real data in scatter plots before we dive into ML model and predictions.

Note that some values are normalized in order for clear reading.

#### Norm. Tupras vs USD/EUR and USD/TRY Currency

https://preview.redd.it/wrl3gn2n13z61.png?width=1504&format=png&auto=webp&s=777eece23e58a74d997a4b56abaaf4f48b78bb2e

### Tupras vs Crude Oil Prices in TRY

https://preview.redd.it/zcu6is3p13z61.png?width=1506&format=png&auto=webp&s=ea643020903cc45dffa8a344db77f91b92c3c062

### Tupras vs Crude Oil Prices in USD

https://preview.redd.it/gfexeofr13z61.png?width=1470&format=png&auto=webp&s=c3b9f7e6f3d795ba0dbed4807d4837525387f9d7

### Norm. Tupras vs TRY Inflation Rates

https://preview.redd.it/v7vc5v9t13z61.png?width=1488&format=png&auto=webp&s=213f87fb8c0d72ef9a06288f871ec570c6203686

## Machine Learning Model and Predictions for Different Variables

Since the data frame is really complicated, and as you know stock values actually depends on millions of stuff. I've chosen to use poly features in my model. Also after using poly features, values are scaled using StandardScaler for fast computation(almost 20 times faster).

https://preview.redd.it/y068jnpu13z61.png?width=1086&format=png&auto=webp&s=da683ba062d2c0d07114703ffc56a69cee08c48f

### Elastic Net Regularization

[With train\_test\_split, 10&#37; of the data is chosen for final test and models were created to find best \\""alpha\\"" for Lambda in the ElasticNet equation above and \\""l1\_ratio\\"" which is the alpha which arranges the weight of LASSO and Ridge Regressions.](https://preview.redd.it/e5csgr7y13z61.png?width=1736&format=png&auto=webp&s=71e5de9802300613767768baf99309bcb00c929f)

&#x200B;

https://preview.redd.it/2c40mazz13z61.png?width=1362&format=png&auto=webp&s=80d1a2f88e063089a928c26fa7b4595a3d1fe03f

After fitting the model to training set, RMSE(Root Mean Squared Error) and MAE(Mean Absolute Error) are calculated accordingly. 

https://preview.redd.it/ahpxsz4123z61.png?width=732&format=png&auto=webp&s=e007752cdf0c638f79ab011d137ac29109885b3a

Values were not suprising for the model; ElasticNet(alpha=0.01, l1\_ratio=1, max\_iter=100000). Basically saying LASSO Regression was way better than using Ridge.

The final results with std. scaler + poly\_features; #Root Mean Squared Error: 8.89, Mean Absolute Error: 6.91 with standard scaling. #Root Mean Squared Error: 8.97, Mean Absolute Error: 7.04 without std. scaling.

### In short; our ML model is working around 7-10% error for predicting TUPRS.IS stock prices depending on other parameters. BTW, we should definitely not put any money based on this model which has 7-10% error. It would be really naive.

As a quick note; I've also tried ElasticNetCV, LASSO and Ridge Regressions on the dataframe with different scaling options. RMSE.mean() were around 25%, way too high; so I've continued with GridSearchCV + ElasticNet which is around 10%, seemed nice.

## Effects of Other Variables on Stock Prices

We created our model with an acceptable error(accepted by me), let's find out what variables are affecting the stock prices. These graphs are created by keeping all parameters stable and only changing one in order to observe clear effects.

**This is where we will have really interesting information about the effects of other parameters on stock prices.**

### Crude Oil Price [USD]

Interesting observation; it has a peak and optimum value around 75 USD but converging down for too high and too low. 

&#x200B;

https://preview.redd.it/zoi9t5v223z61.png?width=998&format=png&auto=webp&s=2b6aa96aa2d29d1b48112d2c6ff9cba6bc3b0baa

### TUPRS.IS Stock and Crude Oil Volume in Stock Market

Both volume increases have linear effect on stock prices. For TÃ¼praÅŸ volume, it is easy to guess; if it's bought more, it will increase. However, for the crude oil volume it didn't make sense to me. Maybe someone who knows can explain better. 

&#x200B;

https://preview.redd.it/fo0kfms823z61.png?width=1006&format=png&auto=webp&s=0d9752071f81ca7df5fa575a899a4aecb1222e84

https://preview.redd.it/8n1yxb3423z61.png?width=946&format=png&auto=webp&s=90e2ad4fbc012128c50748487201e915f388a5ba

### TRY Inflation Rate

Inflation rate has positive effect on stock prices. However, as you may guess inflation also means value loss on currency(in this case TRY). So this parameter actually should be deeply analysed by someone who can understand finance. 

https://preview.redd.it/l2brf4va23z61.png?width=954&format=png&auto=webp&s=2541984fb389dbe6c4883aad8e3a4ac716e31256

### USD/TRY Currency

This is where it gets really interesting. TUPRS.IS stock values actually really dependent on USD/TRY currency and according to our model it has an optimum value around 1 USD = 5.5 TRY. **If USD/TRY goes above 11 TRY, TUPRS.IS stocks losing all of its value and becomes 0 TRY directly. (maybe not possible in real world, but can say something for the future if USD/TRY goes up like that.)** 

https://preview.redd.it/hzcdl1mc23z61.png?width=986&format=png&auto=webp&s=5c470443ba1982b95c7017f79430841db7cba033

### USD/EUR Currency

This graph actually explains what happens if USD loses or earns money compared to EUR. According to our ML model, it has the lowest stock price value around 0.7. If USD earns more value and goes up to 0.9, TUPRS.IS also increases it's price. But same situation also goes on for the complete opposite scenario. I didn't find this graph meaningful, but added anyways. 

https://preview.redd.it/xarxsrzd23z61.png?width=1014&format=png&auto=webp&s=8b97039339c7bd5f1c3dc39abbefa24a25fc0ffc

In conclusion, stock prices depends on millions of parameters. Maybe it can be modeled up to some degree, but in real world it is almost impossible to come up with a future value just like that.

In this sample I've tried to analyse one of the biggest company of Turkey, without it's financials and find some useful data as well as useless ones.

If you came this far, thank you for your interest. Have a great day ahead!"
341,Python," Sample Dockerized flask app deployed on Kubernetes on Azure using AKS 

[https://github.com/ahmedkhemiri95/flask-app-kubernetes](https://github.com/ahmedkhemiri95/flask-app-kubernetes)"
342,Python,"Hello folks,

&#x200B;

I wrote an all python imessage scheduling app!

&#x200B;

[https://github.com/anthonybajoua/ischeduler](https://github.com/anthonybajoua/ischeduler)

&#x200B;

Let me know your thoughts or improvements (first time using TK)"
343,Python,"Found a neat resource related to Python over the past week? Looking for a resource to explain a certain topic?

Use this thread to chat about and share Python resources!"
344,Python,"The cut-out-cookies package (available on pypi) adds the ability to mark files and folders for optional inclusion in a [cookiecutter](https://cookiecutter.readthedocs.io/en/1.7.3/) template.

* [Github](https://github.com/dusktreader/cut-out-cookies)
* [pypi](https://pypi.org/project/cut-out-cookies/)

Since [2016](https://github.com/cookiecutter/cookiecutter/issues/723), folks have been asking about how to do optional file and directory inclusion in cookiecutter. There have been various solutions, but usually the best guidance provided is to roll-your-own.

The cut-out-cookies package adds this functionality to cookie cutter via a new jinja2 extension which allows you to ""stencil"" files, directories, or just text within a file. See the project home-page for complete examples."
345,Python,"Pandas provides so many options of reading data into a DataFrame, here's our short guide to ones that we found most useful. [https://gretel.ai/blog/a-guide-to-load-almost-anything-into-a-dataframe](https://gretel.ai/blog/a-guide-to-load-almost-anything-into-a-dataframe)"
346,Python," [s8007/Dashboard at v1.1 (github.com)](https://github.com/s8007/Dashboard/tree/v1.1) This shows your PC's stats, like RAM, battery, etc, and has a clock. It has an option to keep on top."
347,Python,"There is a very simple PR suggested for Flit which would add Fossil support to Flit.  


Any Fossil fans willing to test it and to comment in favor so it gets merged?  


[https://github.com/takluyver/flit/pull/224](https://github.com/takluyver/flit/pull/224)"
348,Python,"Hi guys!

I made a mini framework in Python that makes it easy to create state machines: [StateEngine](https://github.com/aymanimtyaz/StateEngine)

Anyone who has used Flask before will find it very easy to use. State handlers are assigned to states in the same way routes are assigned to view functions in Flask.

I was working on a project earlier that included building a conversational chatbot. The code I'd written for the chatbot's logic was very convoluted and confusing, with if-else statements nested 6 levels in some cases before I decided to use a state machine and the framework that I created. 

Using StateEngine. I was able to refactor the entire code base in an hour and in vastly fewer lines of code.

Please check it out and let me know what you think!"
349,Python,"Antivirus programs detect viruses by generating a hash of a file and comparing them with one of the hashes already known to the antivirus. If the image generates the same has as the virus it should flag the image as a virus. This would be possible since an image or file goes from a high entropy state to a lower one. Of course, anti-virus software uses multiple ways to create signatures of a single file. But maybe this script could generate some false positives.

I'm not sure if this could work, since I have no success yet. But in theory, this should be possible.

The main purpose of this was to compare the speed between PyPy & the normal python interpreter. This was done by adding a logging line to the infinite while loop. After a while running the script in PyPy you see a considerable speed-up in generation speed.

I would love to hear suggestions or things I should consider to improve this script & if it is even possible.

Project: [https://github.com/Vepnar/ImageClasher](https://github.com/Vepnar/ImageClasher)"
350,Python,"&#x200B;

[demo video](https://reddit.com/link/nbceid/video/r734gomdtuy61/player)

It could also be set to type at any fixed WPM.

Source code: [https://github.com/yashrathi-git/10fastfingers-bot](https://github.com/yashrathi-git/10fastfingers-bot)"
351,Python,"So, I've coded for 1.5 years subliminally assuming that in something like this

    list1 = [1,2,3]
    def remove_two(lst):
        lst.remove(2)
        return lst
    list2 = remove_two(list1)

the original list doesn't get mutated.

\\\*facepalm\\\*"
352,Python," 

https://preview.redd.it/f8dfq677f2z61.png?width=4001&format=png&auto=webp&s=f57c49f623e80136bc1c1cf187e17e91f8c426aa

Hi,

This is a cool project of controlling Atari 2600 Pole position race game using the hands.

The hands â€œcreatesâ€ an invisible virtual car wheel that controls the race game. Very cool

The project is based on Python, OpenCV , and Mediapipe

The goal is to create a functionality that replaces the traditional Atari paddle with our hands pose

The code estimate the position of each hands , and calculate the X,Y axis to simulate Left and Right directions ,

That transforms to an action keyboard keys

I added a link for the code in the video description, so you can download and enjoy

There is step by step tutorial how can we detect the hands and extract a specific landmarks in the video description.

If you would like that I would produce a specific video tutorial for this cool demo , please comment the Youtube video. If there will be a demand , I will create one.

You are most welcome to subscribe for more videos to come

The link for the video is : [https://youtu.be/jciZ2LAFOR4](https://youtu.be/jciZ2LAFOR4)

The link for the code is : [https://github.com/feitgemel/BodyPos/tree/master/MediaPipe/Holistic](https://github.com/feitgemel/BodyPos/tree/master/MediaPipe/Holistic)

Enjoy

Eran"
353,Python,"Hi everybody

This post is halfway between a flare and a cry for help

I started coding in Python 5 years ago, after leaving the academic world were I was proficient with MATLAB and I discovered that the industry world is not too happy of paying thousands of euros every year for the licences. Since then I become quite proficient with python up to the point that I think I can call myself an expert.

However one thing in python always made me cry: plotting.

As an engineering consultant, half of the times I handle calculations were the outputs are hundreds or thousands of numbers (just think to the result of the structural analysis of a building), so to present the results - and perform visual checks - visualizing the data is a fundamental part of the job.

I'm quite sure that if you ask to 100 python developers which library is the most ""standard"" plotting library in python, 99 of them will answer **matplotlib**.

However, in 2021, the limitations of matplotlib are absolutely stunning (considering it's ""standard"" status). Just to list a fews:

* you can't (easily) select data from a plot, reimport the data into python, modify them or delete them
* you can't (easily) copy-paste plots from one axis to another
* you can't (easily) save a figure to be opened interactively again (yes, you can pickle them, but you can't do it from the plot interface and there are very little mentions to this in the documentation just to confirm that this is not ""readily available"")
* now - last but not least - **I just discovered that if you use a 3d plot you can't zoom!!**

I tried other packages such as plotly or bokeh. On one side they are much more versatile, on the other they are way more complicated, requiring tens of rows to perform the most basic plots.

Is it possible that in 2021 python is still lacking a real interactive and easy to use library; at least on the same level of MATLAB's regarding ease of use and features?

What do you usually use to visualize your data? Do you have any suggestion?"
354,Python,"Hey all, I posted our previous Python book CodeWithReplit a while back and y'all gave us some great feedback.

We are now working on [a second book](https://learnpythontherightway.com), based on ""How to Think Like a Computer Scientist"", but using Replit too.

It's still a work in progress - we are converting each chapter to use [Replit.com](https://Replit.com) instead of a local set up, but it's already usable. You can view each chapter online or download a PDF of the whole book at

[https://learnpythontherightway.com](https://learnpythontherightway.com)

https://preview.redd.it/oqx77ubw33z61.png?width=1275&format=png&auto=webp&s=50be29febc0ad7747c2e44e69d86f72164f60ba8"
355,Python,"Especially the \`aenum\` namespace, which seems to have had changes that aren't even documented but are in the code (\`\_missing\_value\_\` being used instead of the apparently deprecated \`\_missing\_\`), documentation on what the parameters in functions like \`\_generate\_next\_value\_\` mean, as well methods not passing a \`self\` when called on the class, it's all very confusing and difficult to work around."
356,Python,"I am making Python 101: 2nd Edition free during PyCon 2021. This sale will end, **Monday, May 17th, 2021.** You can get the book free using the following links:  


* Leanpub - [https://leanpub.com/py101/c/pycon](https://leanpub.com/py101/c/pycon)
* Gumroad - [https://gumroad.com/l/pypy101/pycon](https://gumroad.com/l/pypy101/pycon)
* Or **pay what you want** starting at $5 using this link: [https://gumroad.com/l/pypy101](https://gumroad.com/l/pypy101)

If you like the eBook and you'd like to get a paperback version, you can get it on [Amazon](https://amzn.to/2Zo1ARG).

I have written [several other books](https://gumroad.com/driscollis) too. You can take **$10 off** any of them using this code on Gumroad: **pycon2021**

&#x200B;

[Python 101: 2nd Edition](https://preview.redd.it/ecyiecuc4wy61.jpg?width=1500&format=pjpg&auto=webp&s=13b9aafafad24d7a364ffcd92a6d29b9c79a3fb3)"
357,Python,"I wrote a python script that will take your pandas dataframe and upload it to a database. But this script will automatically update existing records and append new rows to the database whenever you update the pandas dataframe.

I wrote the script to handle any scalability issues in case you have millions of rows that would cause memory or resource issues.

The real life use case for this script would be if you had a data pipeline that was continuously being updated and refreshed.

[Video of me creating script with explanation of concepts](https://www.youtube.com/watch?v=77IVf0zgmwI)

[github](https://github.com/Strata-Scratch/api-youtube)"
358,Python,"[pykokkos-base](https://github.com/kokkos/pykokkos-base) provides the ability to pass Kokkos data structures (View, DynRankView -- which are similar to NumPy's ndarray) between Python and C++ and interoperability with NumPy and CuPy arrays.

[Kokkos](https://github.com/kokkos/kokkos) implements a programming model in C++ for writing performance portable applications targeting all major HPC platforms. It provides abstractions for both parallel execution of code and data management with a variety of backends including, but not limited to: CUDA, HIP, OpenMP, HPX, and Pthreads, with backends for OpenMPTarget and SYCL currently under development. 

Making these bindings available was a critical step in the progress toward writing Kokkos in native Python via [pykokkos](https://github.com/kokkos/pykokkos), which is currently available for Linux + Python 3.8 + GCC 7.5 + CUDA 10.2 toolchains."
359,Python,"[This post](https://pknerd.medium.com/getting-started-with-protobuffer-and-python-2ea749924412?source=friends_link&sk=fe062263bd46bd103d94ecd576244357) describes howÂ [Proto Buffers](https://developers.google.com/protocol-buffers)Â can be used in Python for passing messages across networks. Protocol Buffers orÂ PorobufÂ in short, are used for data serialization and deserialization. It also briefly discusses data serialization and serialization in the beginning."
360,Python,"Hello All,

I am new here. So I am not sure where to ask the right questions, but I want to know about anaconda vs Spyder. What all libraries are there in anaconda and are missing in standalone Spyder?

Reason I am asking is that I updated Spyder (to 5.0.0) inside anaconda-3 and it messed up the UI of Spyder (multiple times, same result), the icons are interacting with the texts, making it difficult to work. This is not happening with standalone Spyder.

&#x200B;

&#x200B;

[Here is the image of messed up text and icons in the lists when I upgrade Spyder in Anaconda.](https://preview.redd.it/x31pxrzhz2z61.png?width=306&format=png&auto=webp&s=b9716967a4332cf4a46bf597219e6f05955194af)"
361,Python,"Python context managers are a nifty resource management tool that provides a simple syntax for a powerful construct. When working with threads, database connections, files, or any limited resources, itâ€™s essential to release them after use. 

Read more: [https://analyticsindiamag.com/guide-to-python-context-managers-beyond-files/](https://analyticsindiamag.com/guide-to-python-context-managers-beyond-files/)"
362,Python,"Use this thread to talk about anything Python related! Questions, news, projects and any relevant discussion around Python is permitted!"
363,Python,"Full tutorial is [available on Hackster](https://www.hackster.io/rob-lauer/solar-powered-crypto-mining-with-raspberry-pi-64adee).

So this project was a blast, if not incredibly impractical.

[My Raspberry Pi 4 + PiJuice HAT + Notecarrier\/Notecard HAT](https://preview.redd.it/ldm619u9toy61.jpg?width=800&format=pjpg&auto=webp&s=dcd16db23b566fd3e8038ddbbc6d8b2f3aa55686)

tl;dr - don't expect a Raspberry Pi to generate you more than a few pennies (even on solar!).

I took existing OSS tools for CPU mining of Monero and wrote a Python script that would regularly scrape the log file generated...then report data from that log file to a cloud dashboard using cellular (making this nearly an off-grid solution as well)."
364,Python,"I decided I should practice my Python skills some more, and since I just set up a Minecraft server for my friends and I using Ubuntu Server, what better way to compliment it!

[Cutercon on GitHub](https://github.com/Karsteski/Cutercon)

[Cutercon](https://imgur.com/GoZWUNn)

I'd appreciate any feedback on how I can improve the code as well :)"
365,Python,"Hello Redditors, iâ€™m new to python and have been loving things you can automate with python, so i was curious what did you guys automates in your job and made it easy?"
366,Python,"Discussion of using Python in a professional environment, getting jobs in Python as well as ask questions about courses to further your python education!

**This thread is not for recruitment, please see** r/PythonJobs **or the thread in the sidebar for that.**"
